"""
JARVIS Client-Side Data Collector
ë¡œì»¬ì—ì„œ íŒŒì¼ì„ ìŠ¤ìº”í•˜ê³  íŒŒì‹±í•œ í›„ ë°±ì—”ë“œë¡œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.

ì›ê²© ì„œë²„ í™˜ê²½ì—ì„œ ì‚¬ìš©ìì˜ ë¡œì»¬ íŒŒì¼ì„ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ í´ë¼ì´ì–¸íŠ¸ ì¸¡ êµ¬í˜„.
"""

import os
import hashlib
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from threading import Thread, Event

import requests
from PyQt6.QtCore import QObject, pyqtSignal, QThread

try:
    from config import API_BASE_URL
except ImportError:
    API_BASE_URL = "http://localhost:8000"

logger = logging.getLogger(__name__)


class ClientDataCollector(QThread):
    """
    í´ë¼ì´ì–¸íŠ¸ ì¸¡ ë°ì´í„° ìˆ˜ì§‘ ì›Œì»¤.
    
    ë¡œì»¬ì—ì„œ íŒŒì¼ì„ ìŠ¤ìº”í•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•œ í›„ ë°±ì—”ë“œë¡œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    
    Signals:
        progress_updated: (progress: float, message: str) ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸
        file_processed: (file_name: str) íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ
        collection_completed: ìˆ˜ì§‘ ì™„ë£Œ
        collection_error: (error_msg: str) ì˜¤ë¥˜ ë°œìƒ
    """
    
    progress_updated = pyqtSignal(float, str)
    file_processed = pyqtSignal(str)
    collection_completed = pyqtSignal()
    collection_error = pyqtSignal(str)
    
    # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì
    SUPPORTED_EXTENSIONS = {
        'document': ['.txt', '.md', '.rtf'],
        'code': ['.py', '.js', '.ts', '.jsx', '.tsx', '.html', '.css', '.scss', 
                 '.java', '.cpp', '.c', '.h', '.cs', '.php', '.rb', '.go', '.rs', 
                 '.swift', '.kt', '.r', '.sh', '.bat', '.ps1', '.sql', '.json', 
                 '.xml', '.yaml', '.yml', '.toml', '.ini', '.cfg', '.conf'],
    }
    
    # ìŠ¤í‚µí•  ë””ë ‰í† ë¦¬ íŒ¨í„´
    SKIP_PATTERNS = [
        'Windows', 'Program Files', 'Program Files (x86)', '$Recycle.Bin', 
        '.git', 'node_modules', '__pycache__', 'AppData', '.venv', 'venv',
        'site-packages', '.idea', '.vscode', 'build', 'dist', '.cache',
        'Library', 'Applications', 'System'
    ]
    
    def __init__(
        self,
        user_id: int,
        token: str,
        selected_folders: List[str],
        parent=None
    ):
        super().__init__(parent)
        
        self.user_id = user_id
        self.token = token
        self.selected_folders = selected_folders
        self._stop_event = Event()
        
        # ì§€ì›í•˜ëŠ” í™•ì¥ì ì§‘í•©
        self.allowed_extensions = set()
        for exts in self.SUPPORTED_EXTENSIONS.values():
            self.allowed_extensions.update(exts)
    
    def stop(self):
        """ìˆ˜ì§‘ ì¤‘ì§€"""
        self._stop_event.set()
    
    def run(self):
        """ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰"""
        try:
            self.progress_updated.emit(0.0, "ğŸ“ íŒŒì¼ ìŠ¤ìº” ì‹œì‘...")
            
            # 1. íŒŒì¼ ìŠ¤ìº”
            files_to_process = self._scan_files()
            
            if self._stop_event.is_set():
                return
            
            if not files_to_process:
                self.progress_updated.emit(100.0, "âš ï¸ ìˆ˜ì§‘í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                self._notify_completion()
                self.collection_completed.emit()
                return
            
            total_files = len(files_to_process)
            self.progress_updated.emit(10.0, f"ğŸ“„ {total_files}ê°œ íŒŒì¼ ë°œê²¬")
            
            # 2. íŒŒì¼ íŒŒì‹± ë° ì—…ë¡œë“œ (ë°°ì¹˜ ì²˜ë¦¬)
            batch_size = 10
            processed_count = 0
            
            for i in range(0, total_files, batch_size):
                if self._stop_event.is_set():
                    return
                
                batch = files_to_process[i:i + batch_size]
                batch_data = []
                
                for file_path in batch:
                    if self._stop_event.is_set():
                        return
                    
                    file_data = self._process_file(file_path)
                    if file_data:
                        batch_data.append(file_data)
                        self.file_processed.emit(file_data['file_name'])
                    
                    processed_count += 1
                    progress = 10.0 + (processed_count / total_files) * 70.0
                    self.progress_updated.emit(
                        progress, 
                        f"ğŸ“„ ì²˜ë¦¬ ì¤‘... ({processed_count}/{total_files})"
                    )
                
                # ë°°ì¹˜ ì—…ë¡œë“œ
                if batch_data:
                    self._upload_batch(batch_data)
            
            # 3. ì™„ë£Œ ì•Œë¦¼
            self.progress_updated.emit(95.0, "ğŸ“¤ ì„œë²„ì— ì™„ë£Œ ì•Œë¦¼...")
            self._notify_completion()
            
            self.progress_updated.emit(100.0, "âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
            self.collection_completed.emit()
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}", exc_info=True)
            self.collection_error.emit(f"ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
    
    def _scan_files(self) -> List[str]:
        """ì„ íƒëœ í´ë”ì—ì„œ íŒŒì¼ ëª©ë¡ ìŠ¤ìº”"""
        files = []
        
        for folder in self.selected_folders:
            if self._stop_event.is_set():
                break
            
            folder_path = Path(folder)
            if not folder_path.exists() or not folder_path.is_dir():
                continue
            
            try:
                for root, dirs, filenames in os.walk(folder_path):
                    if self._stop_event.is_set():
                        break
                    
                    # ìŠ¤í‚µí•  ë””ë ‰í† ë¦¬ í•„í„°ë§
                    dirs[:] = [
                        d for d in dirs 
                        if not any(skip in d for skip in self.SKIP_PATTERNS)
                        and not d.startswith('.')
                    ]
                    
                    for filename in filenames:
                        if self._stop_event.is_set():
                            break
                        
                        # ì„ì‹œ íŒŒì¼ ìŠ¤í‚µ
                        if filename.startswith('~$') or filename.startswith('.'):
                            continue
                        
                        file_path = os.path.join(root, filename)
                        ext = Path(file_path).suffix.lower()
                        
                        if ext in self.allowed_extensions:
                            files.append(file_path)
                            
            except PermissionError:
                continue
            except Exception as e:
                logger.warning(f"í´ë” ìŠ¤ìº” ì˜¤ë¥˜ ({folder}): {e}")
                continue
        
        logger.info(f"ìŠ¤ìº” ì™„ë£Œ: {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
        return files
    
    def _process_file(self, file_path: str) -> Optional[Dict[str, Any]]:
        """íŒŒì¼ì„ íŒŒì‹±í•˜ê³  ì²­í¬ë¡œ ë¶„í• """
        try:
            # íŒŒì¼ í•´ì‹œ ê³„ì‚°
            with open(file_path, 'rb') as f:
                file_hash = hashlib.md5(f.read()).hexdigest()
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = self._extract_text(file_path)
            if not text or len(text.strip()) < 50:
                return None
            
            # ì²­í¬ ë¶„í• 
            chunks = self._chunk_text(text)
            if not chunks:
                return None
            
            # íŒŒì¼ ì¹´í…Œê³ ë¦¬ ê²°ì •
            ext = Path(file_path).suffix.lower()
            category = 'document'
            for cat, exts in self.SUPPORTED_EXTENSIONS.items():
                if ext in exts:
                    category = cat
                    break
            
            return {
                'file_path': file_path,
                'file_name': Path(file_path).name,
                'file_category': category,
                'file_hash': file_hash,
                'chunks': [
                    {'text': chunk, 'snippet': chunk[:200]}
                    for chunk in chunks
                ]
            }
            
        except Exception as e:
            logger.debug(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({file_path}): {e}")
            return None
    
    def _extract_text(self, file_path: str) -> Optional[str]:
        """íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°„ë‹¨í•œ êµ¬í˜„)"""
        try:
            ext = Path(file_path).suffix.lower()
            
            # í…ìŠ¤íŠ¸ íŒŒì¼
            if ext in ['.txt', '.md', '.py', '.js', '.ts', '.jsx', '.tsx', 
                      '.html', '.css', '.scss', '.java', '.cpp', '.c', '.h',
                      '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt',
                      '.r', '.sh', '.bat', '.ps1', '.sql', '.json', '.xml',
                      '.yaml', '.yml', '.toml', '.ini', '.cfg', '.conf', '.rtf']:
                
                # ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
                for encoding in ['utf-8', 'utf-16', 'cp949', 'euc-kr', 'latin-1']:
                    try:
                        with open(file_path, 'r', encoding=encoding) as f:
                            content = f.read()
                            # RTFì˜ ê²½ìš° ê¸°ë³¸ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
                            if ext == '.rtf':
                                content = self._strip_rtf(content)
                            return content
                    except UnicodeDecodeError:
                        continue
                
            return None
            
        except Exception as e:
            logger.debug(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜ ({file_path}): {e}")
            return None
    
    def _strip_rtf(self, rtf_text: str) -> str:
        """ê°„ë‹¨í•œ RTF íƒœê·¸ ì œê±°"""
        import re
        # RTF ì»¨íŠ¸ë¡¤ ì›Œë“œ ë° ê·¸ë£¹ ì œê±°
        text = re.sub(r'\\[a-z]+\d*\s?', '', rtf_text)
        text = re.sub(r'[{}]', '', text)
        return text
    
    def _chunk_text(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        if not text:
            return []
        
        text = text.strip()
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            if end < len(text):
                # ë¬¸ì¥ ê²½ê³„ì—ì„œ ë¶„í•  ì‹œë„
                boundary = text.rfind('.', start + chunk_size - 100, end)
                if boundary == -1:
                    boundary = text.rfind(' ', start + chunk_size - 100, end)
                if boundary > start:
                    end = boundary + 1
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            start = end - overlap
        
        return chunks
    
    def _upload_batch(self, batch_data: List[Dict[str, Any]]) -> bool:
        """ë°°ì¹˜ ë°ì´í„°ë¥¼ ì„œë²„ì— ì—…ë¡œë“œ"""
        try:
            response = requests.post(
                f"{API_BASE_URL}/api/v2/data-collection/client-upload/{self.user_id}",
                headers={
                    "Authorization": f"Bearer {self.token}",
                    "Content-Type": "application/json"
                },
                json={"files": batch_data},
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info(f"ë°°ì¹˜ ì—…ë¡œë“œ ì„±ê³µ: {result.get('processed_files', 0)}ê°œ íŒŒì¼")
                return True
            else:
                logger.warning(f"ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def _update_server_status(self, progress: float, message: str, is_done: bool = False):
        """ì„œë²„ì— ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        try:
            requests.post(
                f"{API_BASE_URL}/api/v2/data-collection/client-status/{self.user_id}",
                headers={
                    "Authorization": f"Bearer {self.token}",
                    "Content-Type": "application/json"
                },
                json={
                    "progress": progress,
                    "message": message,
                    "is_done": is_done
                },
                timeout=10
            )
        except Exception:
            pass  # ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
    
    def _notify_completion(self):
        """ì„œë²„ì— ìˆ˜ì§‘ ì™„ë£Œ ì•Œë¦¼"""
        try:
            response = requests.post(
                f"{API_BASE_URL}/api/v2/data-collection/client-complete/{self.user_id}",
                headers={
                    "Authorization": f"Bearer {self.token}",
                    "Content-Type": "application/json"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                logger.info("ì„œë²„ì— ìˆ˜ì§‘ ì™„ë£Œ ì•Œë¦¼ ì „ì†¡ë¨")
            else:
                logger.warning(f"ìˆ˜ì§‘ ì™„ë£Œ ì•Œë¦¼ ì‹¤íŒ¨: {response.status_code}")
                
        except Exception as e:
            logger.error(f"ìˆ˜ì§‘ ì™„ë£Œ ì•Œë¦¼ ì˜¤ë¥˜: {e}")

