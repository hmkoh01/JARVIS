"""
Docling ê¸°ë°˜ ë¬¸ì„œ íŒŒì„œ
ë‹¤ì–‘í•œ ë¬¸ì„œ í˜•ì‹ì„ íŒŒì‹±í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ê³ ,
ì¬ê·€ì  ë¬¸ì ë¶„í• (Recursive Character Splitting)ì„ í†µí•´ ë¬¸ë§¥ì„ ë³´ì¡´í•˜ë©° ì²­í‚¹í•©ë‹ˆë‹¤.
"""

import os
import yaml
import re
import warnings
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging

PROJECT_ROOT = Path(__file__).parent.parent.parent

# PyTorch CUDA ê´€ë ¨ ê²½ê³  ì–µì œ (Docling ëª¨ë¸ ë¡œë”© ì‹œ ë°œìƒ)
warnings.filterwarnings(
    'ignore', 
    message='.*Attempting to deserialize object on.*CUDA.*',
    category=UserWarning
)

try:
    from docling.document_converter import DocumentConverter
    DOCLING_AVAILABLE = True
except ImportError:
    DOCLING_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning("Doclingì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ í…ìŠ¤íŠ¸ íŒŒì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

logger = logging.getLogger(__name__)


class DocumentParser:
    """Docling ê¸°ë°˜ ë¬¸ì„œ íŒŒì„œ ë° ìŠ¤ë§ˆíŠ¸ ì²­ì»¤"""
    
    def __init__(self, config_path: str = "configs.yaml"):
        absolute_config_path = PROJECT_ROOT / config_path
        self.config = self._load_config(absolute_config_path)
        self.docling_config = self.config.get('docling', {})
        self.export_type = self.docling_config.get('export_type', 'markdown')
        
        # ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • ë¡œë“œ
        self.use_cpu_only = self.docling_config.get('use_cpu_only', True)
        self.max_parallel_workers = self.docling_config.get('max_parallel_workers', 2)
        
        # GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë°©ì§€: CPU ëª¨ë“œ ê°•ì œ
        if self.use_cpu_only:
            os.environ['CUDA_VISIBLE_DEVICES'] = ''  # GPU ë¹„í™œì„±í™”
            logger.info("ğŸ”§ Docling CPU ëª¨ë“œ í™œì„±í™” (GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë°©ì§€)")
        
        # Docling ì»¨ë²„í„° ì´ˆê¸°í™”
        if DOCLING_AVAILABLE:
            converter_kwargs = self._build_converter_kwargs()
            self.converter = DocumentConverter(**converter_kwargs)
            logger.info("âœ… Docling ë¬¸ì„œ íŒŒì„œ ì´ˆê¸°í™” ì™„ë£Œ (ì»¤ìŠ¤í…€ ì„¤ì • ì ìš©)")
        else:
            self.converter = None
            logger.warning("âš ï¸ Doclingì´ ì—†ì–´ ê¸°ë³¸ íŒŒì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤")
        
        # ì§€ì› íŒŒì¼ í™•ì¥ì
        self.supported_extensions = {
            # ë¬¸ì„œ
            '.pdf', '.docx', '.doc', '.pptx', '.ppt',
            '.xlsx', '.xls', '.html', '.htm',
            '.txt', '.md', '.rst', '.rtf', '.odt',
            # ì½”ë“œ ë° ì„¤ì • íŒŒì¼
            '.py', '.js', '.ts', '.jsx', '.tsx',
            '.java', '.cpp', '.c', '.h', '.cs',
            '.php', '.rb', '.go', '.rs', '.swift', '.kt',
            '.sh', '.bat', '.ps1',
            '.json', '.xml', '.yaml', '.yml', '.toml', '.ini', '.cfg', '.conf',
            '.css', '.scss', '.sql',
            # ë°ì´í„°
            '.csv', '.tsv'
        }
    
    def _load_config(self, config_path: str) -> dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            if os.path.exists(config_path):
                with open(config_path, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
            return {}
        except Exception as e:
            logger.error(f"ì„¤ì • ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {}

    def _build_converter_kwargs(self) -> Dict[str, Any]:
        """Docling ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ DocumentConverter ì´ˆê¸°í™” íŒŒë¼ë¯¸í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        kwargs: Dict[str, Any] = {}

        pdf_config: Dict[str, Any] = self.docling_config.get('pdf', {}) if isinstance(self.docling_config, dict) else {}

        if pdf_config:
            try:
                from docling.datamodel.base_models import InputFormat
                from docling.datamodel.pipeline_options import PdfPipelineOptions
                from docling.document_converter import PdfFormatOption
            except ImportError:
                logger.warning("Docling PDF ì„¤ì •ì„ ì ìš©í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (í•„ìš”í•œ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŒ).")
            else:
                pdf_options = PdfPipelineOptions()

                if 'ocr_enabled' in pdf_config:
                    pdf_options.do_ocr = bool(pdf_config['ocr_enabled'])

                kwargs['format_options'] = {
                    InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_options)
                }

        return kwargs
    
    def parse_document(self, file_path: str) -> Optional[str]:
        """
        ë¬¸ì„œë¥¼ íŒŒì‹±í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            file_path: íŒŒì‹±í•  ë¬¸ì„œ ê²½ë¡œ
        
        Returns:
            ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ í…ìŠ¤íŠ¸ ë˜ëŠ” None
        """
        try:
            file_ext = Path(file_path).suffix.lower()
            
            # ì§€ì›í•˜ì§€ ì•ŠëŠ” í™•ì¥ì
            if file_ext not in self.supported_extensions:
                logger.debug(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
                return None
            
            # Doclingìœ¼ë¡œ íŒŒì‹±
            if self.converter and DOCLING_AVAILABLE:
                return self._parse_with_docling(file_path)
            else:
                # Fallback: ê¸°ë³¸ í…ìŠ¤íŠ¸ íŒŒì„œ
                return self._parse_basic(file_path)
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ íŒŒì‹± ì˜¤ë¥˜ {file_path}: {e}")
            return None
    
    def _parse_with_docling(self, file_path: str) -> Optional[str]:
        """Doclingì„ ì‚¬ìš©í•œ ë¬¸ì„œ íŒŒì‹±"""
        try:
            # Doclingìœ¼ë¡œ ë¬¸ì„œ ë³€í™˜
            result = self.converter.convert(file_path)
            
            # ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ export
            if self.export_type == 'markdown':
                return result.document.export_to_markdown()
            elif self.export_type == 'text':
                return result.document.export_to_text()
            else:
                # JSON í˜•ì‹ì€ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜
                return result.document.export_to_markdown()
                
        except Exception as e:
            logger.warning(f"Docling íŒŒì‹± ì˜¤ë¥˜(fallback ì‹œë„) {file_path}: {e}")
            # Fallback
            return self._parse_basic(file_path)
    
    def _parse_basic(self, file_path: str) -> Optional[str]:
        """ê¸°ë³¸ í…ìŠ¤íŠ¸ íŒŒì„œ (Docling ì—†ì„ ë•Œ)"""
        try:
            file_ext = Path(file_path).suffix.lower()
            
            # í…ìŠ¤íŠ¸ ê¸°ë°˜ íŒŒì¼ (ì¼ë°˜ í…ìŠ¤íŠ¸, ë§ˆí¬ë‹¤ìš´, ì½”ë“œ íŒŒì¼ ë“±)
            text_extensions = {
                '.txt', '.md', '.rst', '.csv', '.tsv',
                # ì½”ë“œ íŒŒì¼
                '.py', '.js', '.ts', '.jsx', '.tsx',
                '.java', '.cpp', '.c', '.h', '.cs',
                '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.r', '.m',
                '.sh', '.bat', '.ps1',
                # ì„¤ì • ë° ë°ì´í„° íŒŒì¼
                '.json', '.xml', '.yaml', '.yml', '.toml', '.ini', '.cfg', '.conf',
                '.css', '.scss', '.sql', '.html', '.htm'
            }
            
            if file_ext in text_extensions:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    return f.read()
            
            # PDF íŒŒì¼
            elif file_ext == '.pdf':
                try:
                    import PyPDF2
                    with open(file_path, 'rb') as f:
                        pdf_reader = PyPDF2.PdfReader(f)
                        text = ""
                        for page in pdf_reader.pages:
                            text += page.extract_text() + "\n"
                        return text
                except ImportError:
                    logger.warning("PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    return None
            
            # Word ë¬¸ì„œ
            elif file_ext in ['.docx', '.doc']:
                try:
                    from docx import Document
                    doc = Document(file_path)
                    text = ""
                    for paragraph in doc.paragraphs:
                        text += paragraph.text + "\n"
                    return text
                except ImportError:
                    logger.warning("python-docxê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    return None
            
            # Excel íŒŒì¼
            elif file_ext in ['.xlsx', '.xls']:
                try:
                    import pandas as pd
                    df = pd.read_excel(file_path)
                    return df.to_markdown()
                except ImportError:
                    logger.warning("pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    return None
            
            return None
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ íŒŒì„œ ì˜¤ë¥˜ {file_path}: {e}")
            return None
    
    def chunk_text(self, text: str, chunk_size: int = None, chunk_overlap: int = None) -> List[str]:
        """
        [ê°œì„ ë¨] ì¬ê·€ì  ë¶„í•  ë°©ì‹ (Recursive Character Splitting)
        ë¬¸ë‹¨ -> ì¤„ë°”ê¿ˆ -> ë¬¸ì¥ -> ë‹¨ì–´ ìˆœìœ¼ë¡œ ì˜ë¯¸ ë‹¨ìœ„ë¥¼ ìœ ì§€í•˜ë©° ë¶„í• í•©ë‹ˆë‹¤.
        
        Args:
            text: ë¶„í• í•  í…ìŠ¤íŠ¸
            chunk_size: ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜, ê¸°ë³¸ê°’: ì„¤ì •íŒŒì¼ ë˜ëŠ” 1000)
            chunk_overlap: ì²­í¬ ì˜¤ë²„ë© (ë¬¸ì ìˆ˜, ê¸°ë³¸ê°’: ì„¤ì •íŒŒì¼ ë˜ëŠ” 200)
        
        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        # ì„¤ì •ê°’ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        if chunk_size is None:
            chunk_size = self.docling_config.get('chunking', {}).get('chunk_size', 1000)
        if chunk_overlap is None:
            chunk_overlap = self.docling_config.get('chunking', {}).get('chunk_overlap', 200)
        
        if not text:
            return []

        # 1. êµ¬ë¶„ì ìš°ì„ ìˆœìœ„ ì •ì˜ (ë¬¸ë‹¨ > ì¤„ë°”ê¿ˆ > ë¬¸ì¥ > ë‹¨ì–´ > ë¬¸ì)
        # "\n\n": ë¬¸ë‹¨ êµ¬ë¶„
        # "\n": ì¤„ë°”ê¿ˆ
        # ". ": ë¬¸ì¥ ë§ˆì¹¨í‘œ (ë’¤ì— ê³µë°± í¬í•¨)
        # " ": ë‹¨ì–´ ê³µë°±
        # "": ê¸€ì ë‹¨ìœ„ (ìµœí›„ì˜ ìˆ˜ë‹¨)
        separators = ["\n\n", "\n", ". ", " ", ""]
        
        return self._recursive_split(text, separators, chunk_size, chunk_overlap)

    def _recursive_split(self, text: str, separators: List[str], chunk_size: int, chunk_overlap: int) -> List[str]:
        """
        ì¬ê·€ì ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•˜ê³  ë³‘í•©í•˜ëŠ” ë‚´ë¶€ ë¡œì§
        """
        final_chunks = []
        
        # í˜„ì¬ ì‚¬ìš©í•  êµ¬ë¶„ì ì„ íƒ
        separator = separators[-1]
        new_separators = []
        
        for i, sep in enumerate(separators):
            if sep == "": # ë§ˆì§€ë§‰ ë‹¨ê³„ (ê¸€ì ë‹¨ìœ„)
                separator = ""
                break
            if sep in text:
                separator = sep
                new_separators = separators[i + 1:]
                break
        
        # êµ¬ë¶„ìë¡œ í…ìŠ¤íŠ¸ 1ì°¨ ë¶„í• 
        if separator:
            splits = text.split(separator)
        else:
            splits = list(text) # ê¸€ì ë‹¨ìœ„ ë¶„ë¦¬

        # ë³‘í•©ì„ ìœ„í•œ ë²„í¼
        current_chunk = []
        current_length = 0
        separator_len = len(separator)
        
        for split in splits:
            split_len = len(split)
            
            # í˜„ì¬ ì¡°ê°ì„ ë”í–ˆì„ ë•Œ chunk_sizeë¥¼ ì´ˆê³¼í•˜ëŠ”ì§€ í™•ì¸
            if current_length + split_len + (separator_len if current_chunk else 0) > chunk_size:
                
                # 1. í˜„ì¬ê¹Œì§€ ëª¨ì€ ì²­í¬ ì €ì¥
                if current_chunk:
                    doc = separator.join(current_chunk)
                    if doc.strip():
                        final_chunks.append(doc)
                    
                    # 2. ì˜¤ë²„ë© ì²˜ë¦¬: ë’¤ì—ì„œë¶€í„° overlap í¬ê¸° ë‚´ì— ë“¤ì–´ì˜¤ëŠ” ìš”ì†Œë§Œ ë‚¨ê¸°ê³  ë²„ë¦¼
                    # (ë‹¨ìˆœí™”ë¥¼ ìœ„í•´, ì˜¤ë²„ë© í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ëŠ” ì•ë¶€ë¶„ì„ ì œê±°)
                    while current_length > chunk_overlap and current_chunk:
                        removed = current_chunk.pop(0)
                        current_length -= (len(removed) + separator_len)
                        # ì²« ìš”ì†Œ ì œê±° ì‹œ separator ê¸¸ì´ëŠ” ëº„ í•„ìš”ê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë‚˜ ê·¼ì‚¬ì¹˜ë¡œ ê³„ì‚°
                        if current_length < 0: current_length = 0

                # 3. í˜„ì¬ ì¡°ê°ì´ chunk_sizeë³´ë‹¤ í¬ë©´ ì¬ê·€ì ìœ¼ë¡œ ë” ì˜ê²Œ ìª¼ê°¬
                if split_len > chunk_size and new_separators:
                    sub_chunks = self._recursive_split(split, new_separators, chunk_size, chunk_overlap)
                    final_chunks.extend(sub_chunks)
                    # ì¬ê·€ ë¶„í• ëœ ì¡°ê°ë“¤ì€ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìœ¼ë¯€ë¡œ í˜„ì¬ ë²„í¼ì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                    # ë‹¨, ë§ˆì§€ë§‰ ì„œë¸Œì²­í¬ê°€ ì˜¤ë²„ë©ì„ ìœ„í•´ ì¼ë¶€ í•„ìš”í•  ìˆ˜ë„ ìˆìœ¼ë‚˜ ë³µì¡ë„ ê°ì†Œë¥¼ ìœ„í•´ ìƒëµ
                else:
                    # chunk_sizeë³´ë‹¤ëŠ” ì‘ê±°ë‚˜ ë” ì´ìƒ ìª¼ê°¤ ìˆ˜ ì—†ëŠ” ê²½ìš°
                    current_chunk.append(split)
                    current_length += split_len + separator_len
            else:
                # ë²„í¼ì— ì¶”ê°€ ê°€ëŠ¥
                current_chunk.append(split)
                current_length += split_len + (separator_len if current_chunk else 0)
        
        # ë‚¨ì€ ë²„í¼ ì²˜ë¦¬
        if current_chunk:
            doc = separator.join(current_chunk)
            if doc.strip():
                final_chunks.append(doc)
                
        return final_chunks
    
    def parse_and_chunk(self, file_path: str) -> List[Dict[str, Any]]:
        """
        ë¬¸ì„œë¥¼ íŒŒì‹±í•˜ê³  ì²­í¬ë¡œ ë¶„í• 
        
        Args:
            file_path: ë¬¸ì„œ ê²½ë¡œ
        
        Returns:
            ì²­í¬ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{'text': str, 'chunk_id': int, 'path': str}, ...]
        """
        try:
            # ë¬¸ì„œ íŒŒì‹±
            content = self.parse_document(file_path)
            if not content:
                return []
            
            # ì²­í¬ ë¶„í•  (ê°œì„ ëœ ë°©ì‹ ì‚¬ìš©)
            chunks = self.chunk_text(content)
            
            # ì²­í¬ ì •ë³´ ìƒì„±
            chunk_infos = []
            for i, chunk in enumerate(chunks):
                chunk_infos.append({
                    'text': chunk,
                    'chunk_id': i,
                    'path': file_path,
                    'snippet': chunk[:200] + "..." if len(chunk) > 200 else chunk
                })
            
            return chunk_infos
            
        except Exception as e:
            logger.error(f"íŒŒì‹± ë° ì²­í¬ ë¶„í•  ì˜¤ë¥˜ {file_path}: {e}")
            return []