import os
import sys
from pathlib import Path
from dotenv import load_dotenv
load_dotenv()
from logging import getLogger
logger = getLogger(__name__)

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬(backend)ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
backend_dir = Path(__file__).parent.parent.absolute()
if str(backend_dir) not in sys.path:
    sys.path.insert(0, str(backend_dir))

from fastapi import APIRouter, HTTPException, Depends, Request, BackgroundTasks, UploadFile, File, Form
from fastapi.responses import StreamingResponse, FileResponse
from typing import List, Dict, Any, Optional
import tempfile
import hashlib
from datetime import datetime
import asyncio
import aiohttp
import threading # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì„ ìœ„í•´ ì¶”ê°€

from config.settings import settings
from .schemas import UserIntent, ChatRequest, ChatResponse, MessageRequest, MessageResponse
from core.supervisor import get_supervisor, UserIntent as SupervisorUserIntent
from core.agent_registry import agent_registry

from database.data_collector import get_manager, data_collection_managers
from database.repository import Repository
from agents.chatbot_agent.rag.models.bge_m3_embedder import BGEM3Embedder
from database.sqlite import SQLite
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from jose import JWTError, jwt

# KeywordExtractor ì‹±ê¸€í†¤ (ì±„íŒ… í‚¤ì›Œë“œ ì¶”ì¶œìš©)
try:
    from utils.keyword_extractor import get_keyword_extractor
    _keyword_extractor = get_keyword_extractor()
except Exception as e:
    logger.warning(f"KeywordExtractor ì´ˆê¸°í™” ì‹¤íŒ¨, í‚¤ì›Œë“œ ì¶”ì¶œ ë¹„í™œì„±í™”: {e}")
    _keyword_extractor = None

router = APIRouter()
security = HTTPBearer()

def get_current_user_id(credentials: HTTPAuthorizationCredentials = Depends(security)) -> int:
    """JWTì—ì„œ user_id ì¶”ì¶œ"""
    token = credentials.credentials
    try:
        payload = jwt.decode(token, settings.JWT_SECRET_KEY, algorithms=[settings.JWT_ALGORITHM])
        user_id = payload.get("user_id")
        if not user_id:
            raise HTTPException(status_code=401, detail="Invalid token payload")
        return user_id
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid or expired token")

# =============================================================================
# í†µí•© ë©”ì‹œì§€ ì—”ë“œí¬ì¸íŠ¸ (ê¶Œì¥)
# =============================================================================

@router.post("/message")
async def unified_message(message_request: MessageRequest, request: Request):
    """
    í†µí•© ë©”ì‹œì§€ ì²˜ë¦¬ ì—”ë“œí¬ì¸íŠ¸ (ë©€í‹°ì—ì´ì „íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)
    
    ëª¨ë“  ì±„íŒ… ìš”ì²­ì´ ì´ ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•´ Supervisorë¡œ ë¼ìš°íŒ…ë©ë‹ˆë‹¤.
    - ì˜ë„ ë¶„ì„ (LLM ê¸°ë°˜)
    - ì—ì´ì „íŠ¸ ì„ íƒ ë° ìŠ¤ì¼€ì¤„ë§
    - ë‹¨ê³„ë³„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (ì‹¤í–‰ ê³„íš â†’ ì—ì´ì „íŠ¸ ì‹¤í–‰ â†’ ê²°ê³¼)
    
    ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í˜•ì‹:
    - ---PLAN---: ì‹¤í–‰ ê³„íš (JSON)
    - ---START---: ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘
    - ---RESULT---: ì—ì´ì „íŠ¸ ê²°ê³¼
    - ---ERROR---: ì—ì´ì „íŠ¸ ì˜¤ë¥˜
    - ---COMPLETE---: ì „ì²´ ì™„ë£Œ
    - ---METADATA---: ë©”íƒ€ë°ì´í„° (ë²„íŠ¼ í‘œì‹œìš©)
    """
    import json as json_module
    
    try:
        message = message_request.message
        user_id = message_request.user_id
        stream_requested = message_request.stream
        
        # Accept í—¤ë”ë¡œ ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ í™•ì¸ (ì˜¤ë²„ë¼ì´ë“œ)
        accept_header = request.headers.get("accept", "")
        if "text/event-stream" in accept_header:
            stream_requested = True
        
        # ì±„íŒ… ë©”ì‹œì§€ ë¡œê¹… (ì‚¬ìš©ì ë©”ì‹œì§€)
        db = SQLite()
        user_message_id = -1
        if message.strip():
            user_message_id = db.log_chat_message(
                user_id=user_id,
                role='user',
                content=message,
                metadata={"type": "user"}
            )
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (10ì ì´ìƒì¸ ê²½ìš°ë§Œ)
            if user_message_id > 0 and len(message.strip()) >= 10:
                asyncio.create_task(_extract_and_store_keywords(user_id, message, user_message_id))
        
        # Supervisorë¥¼ í†µí•œ ì²˜ë¦¬
        supervisor_instance = get_supervisor()
        user_intent = SupervisorUserIntent(message=message, user_id=user_id)
        
        # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ - ë©€í‹°ì—ì´ì „íŠ¸ ë‹¨ê³„ë³„ ìŠ¤íŠ¸ë¦¬ë°
        if stream_requested:
            async def generate_multi_agent_stream():
                """ë©€í‹°ì—ì´ì „íŠ¸ ë‹¨ê³„ë³„ ìŠ¤íŠ¸ë¦¬ë° - ì‚¬ìš©ì ì¹œí™”ì  ìƒíƒœ ë©”ì‹œì§€"""
                full_content_parts = []
                final_metadata = {}
                
                # ì—ì´ì „íŠ¸ë³„ ì¹œê·¼í•œ ì´ë¦„ ë§¤í•‘
                agent_friendly_names = {
                    "chatbot": ("ğŸ’¬", "ë‹µë³€ì„ ì¤€ë¹„"),
                    "coding": ("ğŸ’»", "ì½”ë“œë¥¼ ì‘ì„±"),
                    "report": ("ğŸ“", "ë³´ê³ ì„œë¥¼ ì‘ì„±"),
                    "recommendation": ("ğŸ¯", "ì¶”ì²œì„ ë¶„ì„"),
                    "dashboard": ("ğŸ“Š", "ë°ì´í„°ë¥¼ ë¶„ì„"),
                }
                
                try:
                    async for event in supervisor_instance.process_user_intent_streaming(user_intent):
                        event_type = event.get("type", "")
                        
                        if event_type == "analyzing":
                            # ë¶„ì„ ì‹œì‘ - ì¹œê·¼í•œ ë©”ì‹œì§€
                            yield "ğŸ” ì˜ë„ë¥¼ ë¶„ì„í•˜ê³  ìˆì–´ìš”...\n\n"
                        
                        elif event_type == "analyzed":
                            # ë¶„ì„ ì™„ë£Œ - ì„œë¡  í…ìŠ¤íŠ¸
                            intro_text = event.get("intro_text", "")
                            if intro_text:
                                yield f"{intro_text} âœ¨\n\n"
                        
                        elif event_type == "plan":
                            # ì‹¤í–‰ ê³„íš - ìƒíƒœ ë©”ì‹œì§€ë§Œ (JSON ì œê±°)
                            pass
                        
                        elif event_type == "start":
                            # ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘ - ì¹œê·¼í•œ ìƒíƒœ ë©”ì‹œì§€
                            agent = event.get("agent", "")
                            order = event.get("order", 1)
                            total = event.get("total", 1)
                            
                            emoji, action = agent_friendly_names.get(agent, ("ğŸ¤–", "ì‘ì—…ì„ ì²˜ë¦¬"))
                            
                            if total > 1:
                                yield f"{emoji} [{order}/{total}] {agent} ì—ì´ì „íŠ¸ê°€ {action}í•˜ê³  ìˆì–´ìš”...\n\n"
                            else:
                                yield f"{emoji} {action}í•˜ê³  ìˆì–´ìš”...\n\n"
                        
                        elif event_type == "result":
                            # ì—ì´ì „íŠ¸ ê²°ê³¼ - ì‹¤ì œ ë‹µë³€ë§Œ ìŠ¤íŠ¸ë¦¬ë° (JSON ë©”íƒ€ë°ì´í„° ì—†ì´!)
                            content = event.get("content", "")
                            metadata = event.get("metadata", {})
                            
                            # ì‹¤ì œ ë‚´ìš©ë§Œ ìŠ¤íŠ¸ë¦¬ë°
                            if content:
                                chunk_size = 80
                                for i in range(0, len(content), chunk_size):
                                    chunk = content[i:i + chunk_size]
                                    yield chunk
                                    await asyncio.sleep(0.01)
                                yield "\n\n"
                                full_content_parts.append(content)
                            
                            # ë©”íƒ€ë°ì´í„°ëŠ” ì €ì¥ë§Œ (ë‚˜ì¤‘ì— í•„ìš”ì‹œ ì „ì†¡)
                            if metadata and metadata.get("action"):
                                final_metadata = metadata
                        
                        elif event_type == "error":
                            # ì—ì´ì „íŠ¸ ì˜¤ë¥˜ - ì¹œê·¼í•œ ë©”ì‹œì§€
                            agent = event.get("agent", "")
                            yield f"âŒ {agent} ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ë¥¸ ë°©ë²•ì„ ì‹œë„í• ê²Œìš”.\n\n"
                        
                        elif event_type == "cancelled":
                            # ì·¨ì†Œë¨
                            yield "âš ï¸ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆì–´ìš”.\n\n"
                            break
                        
                        elif event_type == "waiting_confirmation":
                            # í™•ì¸ ëŒ€ê¸° - ë©”íƒ€ë°ì´í„°ì— ë‚¨ì€ ì—ì´ì „íŠ¸ ì •ë³´ ì¶”ê°€
                            metadata = event.get("metadata", {})
                            remaining_agents = event.get("remaining_agents", [])
                            sub_tasks = event.get("sub_tasks", {})
                            original_message = event.get("original_message", "")
                            previous_results = event.get("previous_results", [])
                            
                            if metadata:
                                final_metadata = metadata.copy()
                                # ë‚¨ì€ ì—ì´ì „íŠ¸ ì •ë³´ ì¶”ê°€ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ continue-agents í˜¸ì¶œì— í•„ìš”)
                                if remaining_agents:
                                    final_metadata["remaining_agents"] = remaining_agents
                                    final_metadata["sub_tasks"] = sub_tasks
                                    final_metadata["original_message"] = original_message
                                    final_metadata["previous_results"] = previous_results
                                    logger.info(f"[MAS] ë‚¨ì€ ì—ì´ì „íŠ¸ ì •ë³´ í¬í•¨: {remaining_agents}")
                        
                        elif event_type == "complete":
                            # ì™„ë£Œ - ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ë©”ì‹œì§€ í‘œì‹œ
                            failed = event.get("failed", 0)
                            if failed > 0:
                                yield "âš ï¸ ì¼ë¶€ ì‘ì—…ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ì–´ìš”.\n\n"
                        
                        elif event_type == "fatal_error":
                            # ì¹˜ëª…ì  ì˜¤ë¥˜
                            yield f"ğŸ˜¥ ì£„ì†¡í•´ìš”, ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {event.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\n\n"
                            break
                    
                    # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ë¡œê¹…
                    full_content = "\n\n".join(full_content_parts)
                    if len(full_content.strip()) >= 10:
                        db.log_chat_message(
                            user_id=user_id,
                            role='assistant',
                            content=full_content,
                            metadata={"multi_agent": True, "streaming": True}
                        )
                    
                    # ë©”íƒ€ë°ì´í„° ì „ì†¡ (ë²„íŠ¼ í‘œì‹œìš© - í•„ìš”í•œ ê²½ìš°ë§Œ)
                    action = final_metadata.get("action", "")
                    if action in ("open_file", "confirm_report", "request_topic", "confirm_analysis"):
                        # JSONì„ í•œ ì¤„ë¡œ ì§ë ¬í™” (ì¤„ë°”ê¿ˆ ì—†ì´)
                        metadata_json = json_module.dumps(final_metadata, ensure_ascii=False, separators=(',', ':'))
                        # ëª…í™•í•œ ì‹œì‘/ë ë§ˆì»¤ ì‚¬ìš©
                        yield f"\n---METADATA_START---{metadata_json}---METADATA_END---\n"
                        logger.info(f"[MAS] ë©”íƒ€ë°ì´í„° ì „ì†¡: action={action}")
                        
                except Exception as e:
                    logger.error(f"ë©€í‹°ì—ì´ì „íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                    yield f"ğŸ˜¥ ì£„ì†¡í•´ìš”, ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.\n"
            
            return StreamingResponse(generate_multi_agent_stream(), media_type="text/plain")
        
        # ë¹„ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
        else:
            supervisor_response = await asyncio.wait_for(
                supervisor_instance.process_user_intent(user_intent, stream=False),
                timeout=settings.REQUEST_TIMEOUT
            )
            
            content = supervisor_response.response.content or ""
            agent_type = supervisor_response.response.agent_type
            
            # Assistant ì‘ë‹µ ë¡œê¹…
            if len(content.strip()) >= 10:
                db.log_chat_message(
                    user_id=user_id,
                    role='assistant',
                    content=content,
                    metadata={"agent_type": agent_type, "success": supervisor_response.success}
                )
            
            return MessageResponse(
                success=supervisor_response.success,
                content=content,
                agent_type=agent_type,
                metadata=supervisor_response.response.metadata or {}
            )
            
    except asyncio.TimeoutError:
        logger.error("ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼")
        return MessageResponse(
            success=False,
            content="ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            agent_type="error",
            metadata={}
        )
    except Exception as e:
        logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return MessageResponse(
            success=False,
            content=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            agent_type="error",
            metadata={}
        )


# =============================================================================
# ë‚¨ì€ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì—”ë“œí¬ì¸íŠ¸ (ë©€í‹°ì—ì´ì „íŠ¸ continuation)
# =============================================================================

@router.post("/continue-agents")
async def continue_agents(request_data: dict, request: Request):
    """
    ë‚¨ì€ ì—ì´ì „íŠ¸ë“¤ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    ì´ì „ ì—ì´ì „íŠ¸(ì˜ˆ: report)ê°€ í™•ì¸ì„ ë°›ì€ í›„ í˜¸ì¶œë˜ì–´
    ë‚¨ì€ ì—ì´ì „íŠ¸ë“¤(ì˜ˆ: coding)ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    ìš”ì²­ JSON:
        {
            "message": "ì›ë³¸ ì‚¬ìš©ì ë©”ì‹œì§€",
            "user_id": 1,
            "remaining_agents": ["coding"],
            "sub_tasks": {
                "coding": {"task": "...", "focus": "..."}
            },
            "previous_results": [...]
        }
    
    ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í˜•ì‹ (ë©€í‹°ì—ì´ì „íŠ¸ì™€ ë™ì¼):
        ---PLAN---, ---START---, ---RESULT---, ---COMPLETE--- ë“±
    """
    import json as json_module
    
    try:
        message = request_data.get("message", "")
        user_id = request_data.get("user_id", 1)
        remaining_agents = request_data.get("remaining_agents", [])
        sub_tasks = request_data.get("sub_tasks", {})
        previous_results = request_data.get("previous_results", [])
        
        if not remaining_agents:
            return {
                "success": False,
                "content": "ì‹¤í–‰í•  ì—ì´ì „íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "agent_type": "error",
                "metadata": {}
            }
        
        logger.info(f"[MAS-CONTINUE] ë‚¨ì€ ì—ì´ì „íŠ¸ ì‹¤í–‰ ìš”ì²­: {remaining_agents}")
        
        # Supervisorë¥¼ í†µí•œ ì²˜ë¦¬
        supervisor_instance = get_supervisor()
        user_intent = SupervisorUserIntent(message=message, user_id=user_id)
        
        # í•­ìƒ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ì‘ë‹µ
        async def generate_continuation_stream():
            """ë‚¨ì€ ì—ì´ì „íŠ¸ ìŠ¤íŠ¸ë¦¬ë° - ì‚¬ìš©ì ì¹œí™”ì  ìƒíƒœ ë©”ì‹œì§€"""
            full_content_parts = []
            final_metadata = {}
            
            # ì—ì´ì „íŠ¸ë³„ ì¹œê·¼í•œ ì´ë¦„ ë§¤í•‘
            agent_friendly_names = {
                "chatbot": ("ğŸ’¬", "ë‹µë³€ì„ ì¤€ë¹„"),
                "coding": ("ğŸ’»", "ì½”ë“œë¥¼ ì‘ì„±"),
                "report": ("ğŸ“", "ë³´ê³ ì„œë¥¼ ì‘ì„±"),
                "recommendation": ("ğŸ¯", "ì¶”ì²œì„ ë¶„ì„"),
                "dashboard": ("ğŸ“Š", "ë°ì´í„°ë¥¼ ë¶„ì„"),
            }
            
            try:
                async for event in supervisor_instance.process_remaining_agents_streaming(
                    user_intent, remaining_agents, sub_tasks, previous_results
                ):
                    event_type = event.get("type", "")
                    
                    if event_type == "plan":
                        # ì‹¤í–‰ ê³„íš - ì¹œê·¼í•œ ë©”ì‹œì§€
                        yield "âœ¨ ì´ì–´ì„œ ì‘ì—…ì„ ì§„í–‰í• ê²Œìš”!\n\n"
                    
                    elif event_type == "start":
                        # ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹œì‘ - ì¹œê·¼í•œ ìƒíƒœ ë©”ì‹œì§€
                        agent = event.get("agent", "")
                        order = event.get("order", 1)
                        total = event.get("total", 1)
                        
                        emoji, action = agent_friendly_names.get(agent, ("ğŸ¤–", "ì‘ì—…ì„ ì²˜ë¦¬"))
                        
                        if total > 1:
                            yield f"{emoji} [{order}/{total}] {agent} ì—ì´ì „íŠ¸ê°€ {action}í•˜ê³  ìˆì–´ìš”...\n\n"
                        else:
                            yield f"{emoji} {action}í•˜ê³  ìˆì–´ìš”...\n\n"
                    
                    elif event_type == "result":
                        # ì—ì´ì „íŠ¸ ê²°ê³¼ - ì‹¤ì œ ë‹µë³€ë§Œ ìŠ¤íŠ¸ë¦¬ë° (JSON ì—†ì´!)
                        content = event.get("content", "")
                        metadata = event.get("metadata", {})
                        
                        # ì‹¤ì œ ë‚´ìš©ë§Œ ìŠ¤íŠ¸ë¦¬ë°
                        if content:
                            chunk_size = 80
                            for i in range(0, len(content), chunk_size):
                                chunk = content[i:i + chunk_size]
                                yield chunk
                                await asyncio.sleep(0.01)
                            yield "\n\n"
                            full_content_parts.append(content)
                        
                        # ë©”íƒ€ë°ì´í„°ëŠ” ì €ì¥ë§Œ
                        if metadata and metadata.get("action"):
                            final_metadata = metadata
                    
                    elif event_type == "error":
                        # ì—ì´ì „íŠ¸ ì˜¤ë¥˜ - ì¹œê·¼í•œ ë©”ì‹œì§€
                        agent = event.get("agent", "")
                        yield f"âŒ {agent} ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”.\n\n"
                    
                    elif event_type == "complete":
                        # ì™„ë£Œ - ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ë©”ì‹œì§€ í‘œì‹œ
                        failed = event.get("failed", 0)
                        if failed > 0:
                            yield "âš ï¸ ì¼ë¶€ ì‘ì—…ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ì–´ìš”.\n\n"
                    
                    elif event_type == "fatal_error":
                        yield f"ğŸ˜¥ ì£„ì†¡í•´ìš”, ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {event.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\n\n"
                        break
                
                # ë©”íƒ€ë°ì´í„° ì „ì†¡ (ë²„íŠ¼ í‘œì‹œìš© - í•„ìš”í•œ ê²½ìš°ë§Œ)
                action = final_metadata.get("action", "")
                if action in ("open_file", "confirm_report", "request_topic", "confirm_analysis"):
                    # JSONì„ í•œ ì¤„ë¡œ ì§ë ¬í™” (ì¤„ë°”ê¿ˆ ì—†ì´)
                    metadata_json = json_module.dumps(final_metadata, ensure_ascii=False, separators=(',', ':'))
                    # ëª…í™•í•œ ì‹œì‘/ë ë§ˆì»¤ ì‚¬ìš©
                    yield f"\n---METADATA_START---{metadata_json}---METADATA_END---\n"
                    logger.info(f"[MAS-CONTINUE] ë©”íƒ€ë°ì´í„° ì „ì†¡: action={action}")
                    
            except Exception as e:
                logger.error(f"ë‚¨ì€ ì—ì´ì „íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                yield f"ğŸ˜¥ ì£„ì†¡í•´ìš”, ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.\n"
        
        return StreamingResponse(generate_continuation_stream(), media_type="text/plain")
        
    except Exception as e:
        logger.error(f"ë‚¨ì€ ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return {
            "success": False,
            "content": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "agent_type": "error",
            "metadata": {}
        }


# =============================================================================
# ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ (deprecated - /message ì‚¬ìš© ê¶Œì¥)
# =============================================================================

@router.post("/chat", deprecated=True)
async def chat_with_agent(chat_request: ChatRequest, request: Request):
    """[DEPRECATED] /message ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤."""
    try:
        # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ í™•ì¸ (Accept í—¤ë” ë˜ëŠ” stream íŒŒë¼ë¯¸í„°)
        accept_header = request.headers.get("accept", "")
        stream_requested = "text/event-stream" in accept_header or "stream" in str(request.query_params)
        
        # ì±—ë´‡ ì—ì´ì „íŠ¸ì¸ ê²½ìš° ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
        # ë¨¼ì € supervisorë¥¼ í†µí•´ ì—ì´ì „íŠ¸ íƒ€ì… í™•ì¸
        user_intent = UserIntent(message=chat_request.message, user_id=chat_request.user_id)
        
        # ì±—ë´‡ ì—ì´ì „íŠ¸ë¡œ ì§ì ‘ ë¼ìš°íŒ…í•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
        if stream_requested:
            # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: compose_answerë¥¼ ì§ì ‘ í˜¸ì¶œ
            from agents.chatbot_agent.rag.react_agent import process as react_process
            from agents.chatbot_agent.rag.answerer import compose_answer
            
            # RAG ì—ì´ì „íŠ¸ì˜ process í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ evidences ê°€ì ¸ì˜¤ê¸°
            state = {
                "question": chat_request.message,
                "user_id": chat_request.user_id,
                "filters": {}
            }
            
            # react_processë¥¼ í†µí•´ evidences ê°€ì ¸ì˜¤ê¸° (ë¹„ë™ê¸° ì²˜ë¦¬ í•„ìš”)
            def generate_stream():
                try:
                    # react_processë¥¼ í˜¸ì¶œí•˜ì—¬ evidences ê°€ì ¸ì˜¤ê¸°
                    result = react_process(state)
                    evidences = result.get("evidence", [])
                    
                    # compose_answerë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ìŠ¤íŠ¸ë¦¬ë°
                    for chunk in compose_answer(chat_request.message, evidences, chat_request.user_id):
                        yield chunk
                except Exception as e:
                    logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                    yield f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            
            return StreamingResponse(generate_stream(), media_type="text/plain")
        else:
            # ë¹„ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
            supervisor_instance = get_supervisor()
            supervisor_response = await asyncio.wait_for(
                supervisor_instance.process_user_intent(user_intent),
                timeout=settings.REQUEST_TIMEOUT
            )
            
            return ChatResponse(
                success=supervisor_response.success,
                message=supervisor_response.response.content if supervisor_response.success else supervisor_response.response,
                agent_type=supervisor_response.response.agent_type if supervisor_response.success else "unknown",
                metadata=supervisor_response.response.metadata if supervisor_response.success else {}
            )
    except asyncio.TimeoutError:
        raise HTTPException(status_code=408, detail=f"ì±„íŒ… ì²˜ë¦¬ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

async def _extract_and_store_keywords(user_id: int, message: str, message_id: int):
    """ì±„íŒ… ë©”ì‹œì§€ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  content_keywordsì— ì €ì¥ (ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬)"""
    if len(message.strip()) < 10:
        return  # ì§§ì€ ë©”ì‹œì§€ëŠ” ìŠ¤í‚µ
    
    try:
        db = SQLite()
        keywords = []
        
        if _keyword_extractor and _keyword_extractor.is_available():
            # KeyBERTë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ (asyncio.to_threadë¡œ ë¸”ë¡œí‚¹ ë°©ì§€)
            extracted = await asyncio.to_thread(
                _keyword_extractor.extract, 
                message, 
                5,  # top_n
                (1, 2)  # keyphrase_ngram_range
            )
            keywords = list(set([kw for kw, _ in extracted]))
        else:
            # Fallback: ë‹¨ìˆœ íœ´ë¦¬ìŠ¤í‹± (2ì ì´ìƒ í† í°)
            tokens = message.split()
            keywords = list(set([t for t in tokens if len(t) > 2]))[:5]
        
        # content_keywordsì— ì €ì¥
        for kw in keywords:
            db.insert_content_keyword(
                user_id=user_id,
                source_type='chat',
                source_id=f"chat:{message_id}",
                keyword=kw,
                original_text=message[:200] if len(message) > 200 else message
            )
        
        if keywords:
            logger.debug(f"ì±„íŒ… í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ: user_id={user_id}, keywords={keywords}")
    except Exception as e:
        logger.warning(f"ì±„íŒ… í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ (ë¬´ì‹œë¨): {e}")

@router.post("/process", deprecated=True)
async def process_message(request_data: dict, request: Request):
    """[DEPRECATED] /message ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤."""
    try:
        message = request_data.get("message", "")
        user_id = request_data.get("user_id", 1)
        
        # ì±„íŒ… ë©”ì‹œì§€ ë¡œê¹… (ì‚¬ìš©ì ë©”ì‹œì§€)
        db = SQLite()
        user_message_id = -1
        if message.strip():
            user_message_id = db.log_chat_message(
                user_id=user_id,
                role='user',
                content=message,
                metadata={"type": "user"}
            )
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (10ì ì´ìƒì¸ ê²½ìš°ë§Œ)
            if user_message_id > 0 and len(message.strip()) >= 10:
                asyncio.create_task(_extract_and_store_keywords(user_id, message, user_message_id))
        
        # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ í™•ì¸ (Accept í—¤ë”)
        accept_header = request.headers.get("accept", "")
        stream_requested = "text/event-stream" in accept_header
        
        user_intent = UserIntent(message=message, user_id=user_id)
        
        if stream_requested:
            # ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: supervisorë¥¼ í†µí•´ í•œ ë²ˆë§Œ ì²˜ë¦¬
            logger.info("ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: supervisorë¥¼ í†µí•œ ì²˜ë¦¬ ì‹œì‘")
            supervisor_instance = get_supervisor()
            supervisor_response = await asyncio.wait_for(
                supervisor_instance.process_user_intent(user_intent),
                timeout=settings.REQUEST_TIMEOUT
            )

            metadata = supervisor_response.metadata or {}
            agent_responses = metadata.get("agent_responses", [])

            if supervisor_response.success:
                content = supervisor_response.response.content or ""
                if not content.strip():
                    for agent_resp in agent_responses:
                        if agent_resp.get("success") and agent_resp.get("content"):
                            content = agent_resp["content"]
                            logger.warning("Supervisor ìµœì¢… ì‘ë‹µì´ ë¹„ì–´ ìˆì–´ ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤.")
                            break
                if not content.strip():
                    logger.error("Supervisor ì‘ë‹µì´ ì—¬ì „íˆ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
                    content = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                logger.info(f"Supervisor ì‘ë‹µ ì„±ê³µ, ê¸¸ì´: {len(content)} ê¸€ì")
            else:
                error_msg = str(supervisor_response.response)
                logger.error(f"Supervisor ì‘ë‹µ ì‹¤íŒ¨: {error_msg}")
                content = f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}"

            # Assistant ì‘ë‹µ ë¡œê¹… (ìŠ¤íŠ¸ë¦¬ë° ì „ì— ë¡œê¹…)
            agent_type = supervisor_response.response.agent_type if supervisor_response.success else "unknown"
            if len(content.strip()) >= 10:
                db.log_chat_message(
                    user_id=user_id,
                    role='assistant',
                    content=content,
                    metadata={"agent_type": agent_type, "success": supervisor_response.success}
                )

            # ì—ì´ì „íŠ¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (íŒŒì¼ ì—´ê¸° ì•¡ì…˜ ë“±)
            # ë¶€ë¶„ ì„±ê³µ(ì¼ë¶€ ì—ì´ì „íŠ¸ë§Œ ì„±ê³µ)ì¸ ê²½ìš°ì—ë„ ë©”íƒ€ë°ì´í„°ëŠ” ì¶”ì¶œí•´ì•¼ í•¨
            response_metadata = {}
            if hasattr(supervisor_response.response, 'metadata'):
                response_metadata = supervisor_response.response.metadata or {}
            
            # ë””ë²„ê·¸: ë©”íƒ€ë°ì´í„° ë¡œê¹…
            agent_type_debug = getattr(supervisor_response.response, 'agent_type', 'unknown')
            logger.info(f"[DEBUG] agent_type={agent_type_debug}")
            logger.info(f"[DEBUG] response_metadata={response_metadata}")
            
            async def generate_stream():
                try:
                    if not content:
                        yield "ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
                        return

                    chunk_size = 80
                    chunk_count = 0
                    total_length = len(content)
                    logger.info("ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì „ì†¡ ì‹œì‘ - ê¸¸ì´: %d", total_length)
                    for i in range(0, len(content), chunk_size):
                        chunk = content[i:i + chunk_size]
                        chunk_count += 1
                        chunk_preview = chunk.replace("\n", "\\n")
                        if len(chunk_preview) > 80:
                            chunk_preview = chunk_preview[:80] + "..."
                        logger.debug(
                            "ìŠ¤íŠ¸ë¦¼ ì²­í¬ #%d ì „ì†¡ (len=%d, preview='%s')",
                            chunk_count,
                            len(chunk),
                            chunk_preview
                        )
                        yield chunk
                        await asyncio.sleep(0.01)
                    
                    # ë©”íƒ€ë°ì´í„°ì— íŠ¹ì • actionì´ ìˆìœ¼ë©´ êµ¬ë¶„ìì™€ í•¨ê»˜ ì „ì†¡
                    action = response_metadata.get("action", "")
                    if action in ("open_file", "confirm_report", "request_topic", "confirm_analysis"):
                        import json as json_module
                        # JSONì„ í•œ ì¤„ë¡œ ì§ë ¬í™” (ì¤„ë°”ê¿ˆ ì—†ì´)
                        metadata_json = json_module.dumps(response_metadata, ensure_ascii=False, separators=(',', ':'))
                        # ëª…í™•í•œ ì‹œì‘/ë ë§ˆì»¤ ì‚¬ìš©
                        yield f"\n\n---METADATA_START---{metadata_json}---METADATA_END---"
                        logger.info(f"ìŠ¤íŠ¸ë¦¬ë° ë©”íƒ€ë°ì´í„° ì „ì†¡: action={action}")
                    
                    logger.info(
                        "ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì „ì†¡ ì™„ë£Œ - ì´ %dê°œ ì²­í¬",
                        chunk_count
                    )
                except Exception as e:
                    logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
                    yield f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

            return StreamingResponse(generate_stream(), media_type="text/plain")
        else:
            # ë¹„ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ: ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
            supervisor_instance = get_supervisor()
            supervisor_response = await asyncio.wait_for(
                supervisor_instance.process_user_intent(user_intent),
                timeout=settings.REQUEST_TIMEOUT
            )

            metadata = supervisor_response.metadata or {}
            agent_responses = metadata.get("agent_responses", [])

            if supervisor_response.success:
                content = supervisor_response.response.content or ""
                if not content.strip():
                    for agent_resp in agent_responses:
                        if agent_resp.get("success") and agent_resp.get("content"):
                            content = agent_resp["content"]
                            logger.warning("Supervisor ìµœì¢… ì‘ë‹µì´ ë¹„ì–´ ìˆì–´ ì²« ë²ˆì§¸ ì—ì´ì „íŠ¸ ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´í–ˆìŠµë‹ˆë‹¤.")
                            break
                if not content.strip():
                    logger.error("Supervisor ì‘ë‹µì´ ì—¬ì „íˆ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
                    content = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            else:
                content = str(supervisor_response.response)
                if not content.strip():
                    content = "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            
            # Assistant ì‘ë‹µ ë¡œê¹… (ë¹„ìŠ¤íŠ¸ë¦¬ë°)
            agent_type = supervisor_response.response.agent_type if supervisor_response.success else "unknown"
            if len(content.strip()) >= 10:
                db.log_chat_message(
                    user_id=user_id,
                    role='assistant',
                    content=content,
                    metadata={"agent_type": agent_type, "success": supervisor_response.success}
                )
            
            # í”„ë¡ íŠ¸ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
            return {
                "success": supervisor_response.success,
                "content": content,
                "agent_type": agent_type,
                "metadata": supervisor_response.response.metadata if supervisor_response.success else {}
            }
    except asyncio.TimeoutError:
        return {
            "success": False,
            "content": "ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "agent_type": "error",
            "metadata": {}
        }
    except Exception as e:
        logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return {
            "success": False,
            "content": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "agent_type": "error",
            "metadata": {}
        }

@router.get("/agents")
async def get_agents():
    """ë“±ë¡ëœ ëª¨ë“  ì—ì´ì „íŠ¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    agents = agent_registry.get_agent_descriptions()
    return {"agents": agents, "total_count": len(agents)}

@router.get("/health")
async def health_check():
    """System health check"""
    try:
        status = {
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "agents": {
                "total": len(agent_registry.get_agent_descriptions()),
            },
            # This part will now work
            "data_collection": {
                "active_managers": len(data_collection_managers),
                "user_ids": list(data_collection_managers.keys())
            }
        }
        return status
    except Exception as e:
        return {"status": "unhealthy", "error": str(e)}

# -----------------------------------------------------------------------------
# ë°ì´í„° ìˆ˜ì§‘ ì œì–´ ì—”ë“œí¬ì¸íŠ¸ë“¤
# -----------------------------------------------------------------------------

@router.get("/data-collection/folders")
async def get_user_folders_endpoint(request: Request):
    """ì‚¬ìš©ìì˜ ê¸°ë³¸ í´ë”(ë°”íƒ•í™”ë©´, ë¬¸ì„œ, ë‹¤ìš´ë¡œë“œ) ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        repository: Repository = getattr(request.app.state, "repository", None)
        embedder: BGEM3Embedder = getattr(request.app.state, "embedder", None)

        if repository is None or embedder is None:
            raise HTTPException(
                status_code=500,
                detail="Singleton resources are not initialised yet. Please retry shortly."
            )

        # TODO: ì‹¤ì œ ì¸ì¦ ë¡œì§ìœ¼ë¡œ ì‚¬ìš©ì IDë¥¼ ì¶”ì¶œí•˜ë„ë¡ êµì²´
        user_id = getattr(request.state, "user_id", 1)

        manager = get_manager(user_id=user_id, repository=repository, embedder=embedder)
        folders = manager.file_collector.get_user_folders(calculate_size=True)
        return {
            "success": True,
            "folders": folders,
            "total_count": len(folders),
            "timestamp": datetime.utcnow().isoformat()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error("í´ë” ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: %s", e, exc_info=True)
        return {
            "success": False,
            "message": f"í´ë” ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}",
            "folders": [],
            "timestamp": datetime.utcnow().isoformat()
        }

@router.post("/data-collection/start/{user_id}")
async def start_data_collection(user_id: int, payload: Dict[str, List[str]], request: Request):
    """Starts data collection for a specific user."""
    try:
        selected_folders = payload.get("selected_folders")
        if not selected_folders:
            raise HTTPException(status_code=400, detail="You must select folders to scan.")

        # app.stateì—ì„œ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        repository = request.app.state.repository
        embedder = request.app.state.embedder
        
        manager = get_manager(user_id, repository=repository, embedder=embedder)

        # ì´ˆê¸° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì´ˆê¸° ìˆ˜ì§‘ë§Œ ì‹¤í–‰ (ì¤‘ë³µ ë°©ì§€)
        if not manager.initial_collection_done:
            thread = threading.Thread(target=manager.perform_initial_collection, args=(selected_folders,), daemon=True)
            thread.start()
            # ì´ˆê¸° ìˆ˜ì§‘ ì¤‘ì—ëŠ” ë°±ê·¸ë¼ìš´ë“œ ìˆ˜ì§‘ì„ ì‹œì‘í•˜ì§€ ì•ŠìŒ (ì¤‘ë³µ íŒŒì‹± ë°©ì§€)
            return {
                "success": True,
                "message": f"Initial data collection started for user {user_id}. The scan is running in the background.",
            }
        
        # ì´ˆê¸° ìˆ˜ì§‘ì´ ì´ë¯¸ ì™„ë£Œëœ ê²½ìš°ì—ë§Œ ë°±ê·¸ë¼ìš´ë“œ ìˆ˜ì§‘ ì‹œì‘
        manager.start_collection(selected_folders)
        
        return {
            "success": True,
            "message": f"Background data collection started for user {user_id}.",
        }
    except Exception as e:
        logger.error(f"Error starting collection: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error starting collection: {str(e)}")

@router.post("/data-collection/stop/{user_id}")
async def stop_data_collection(user_id: int, request: Request):
    """Stops data collection for a specific user."""
    try:
        if user_id in data_collection_managers:
            # app.stateì—ì„œ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
            repository = request.app.state.repository
            embedder = request.app.state.embedder
            
            manager = get_manager(user_id, repository=repository, embedder=embedder)
            manager.stop_collection()
            del data_collection_managers[user_id]
            return {"message": f"Data collection stopped for user {user_id}."}
        else:
            return {"message": f"No active collection found for user {user_id}."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error stopping collection: {str(e)}")

@router.post("/data-collection/stop-all")
async def stop_all_collections():
    """Stops data collection for all users."""
    try:
        # (CORRECTED) Iterate through a copy of the dictionary keys and stop each manager
        for user_id in list(data_collection_managers.keys()):
            manager = data_collection_managers[user_id]
            manager.stop_collection()
            del data_collection_managers[user_id]
        return {"message": "All data collection has been stopped."}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error stopping all collections: {str(e)}")


@router.get("/data-collection/status/{user_id}")
async def get_data_collection_status(user_id: int, request: Request):
    """Checks the data collection status (progress) for a user."""
    try:
        if user_id not in data_collection_managers:
            raise HTTPException(status_code=404, detail="No collection manager found for this user.")

        repository: Repository = getattr(request.app.state, "repository", None)
        embedder: BGEM3Embedder = getattr(request.app.state, "embedder", None)

        if repository is None or embedder is None:
            raise HTTPException(
                status_code=500,
                detail="Singleton resources are not initialised yet. Please retry shortly."
            )

        manager = get_manager(user_id=user_id, repository=repository, embedder=embedder)

        return {
            "progress": manager.progress,
            "progress_message": manager.progress_message,
            "is_done": manager.initial_collection_done,
            "running": manager.running
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error("ë°ì´í„° ìˆ˜ì§‘ ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: %s", e, exc_info=True)
        raise HTTPException(status_code=500, detail=f"ë°ì´í„° ìˆ˜ì§‘ ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

# =============================================================================
# í´ë¼ì´ì–¸íŠ¸ ì¸¡ ë°ì´í„° ìˆ˜ì§‘ API (ì›ê²© ì„œë²„ìš©)
# =============================================================================

from pydantic import BaseModel
from typing import List, Dict, Any, Optional

class ClientFileData(BaseModel):
    """í´ë¼ì´ì–¸íŠ¸ì—ì„œ íŒŒì‹±ëœ íŒŒì¼ ë°ì´í„°"""
    file_path: str
    file_name: str
    file_category: str
    chunks: List[Dict[str, Any]]  # [{"text": "...", "snippet": "..."}, ...]
    file_hash: str
    
class ClientCollectionRequest(BaseModel):
    """í´ë¼ì´ì–¸íŠ¸ ìˆ˜ì§‘ ìš”ì²­"""
    files: List[ClientFileData]
    
class ClientCollectionProgress(BaseModel):
    """í´ë¼ì´ì–¸íŠ¸ ìˆ˜ì§‘ ì§„í–‰ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    progress: float
    message: str
    is_done: bool = False


@router.post("/data-collection/client-file-upload/{user_id}")
async def client_file_upload(
    user_id: int,
    request: Request,
    file: UploadFile = File(...),
    file_path: str = Form(...),
    file_category: str = Form("document")
):
    """
    í´ë¼ì´ì–¸íŠ¸ì—ì„œ íŒŒì¼ì„ ë°›ì•„ ë°±ì—”ë“œì—ì„œ DocumentParserë¡œ íŒŒì‹± í›„ ì¸ë±ì‹±í•©ë‹ˆë‹¤.
    
    ê¸°ì¡´ Docling ê¸°ë°˜ DocumentParserë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ PDF, DOCX ë“± ëª¨ë“  ë¬¸ì„œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    try:
        from database.document_parser import DocumentParser
        
        repository: Repository = getattr(request.app.state, "repository", None)
        embedder: BGEM3Embedder = getattr(request.app.state, "embedder", None)
        
        if repository is None or embedder is None:
            raise HTTPException(
                status_code=500,
                detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        db = SQLite()
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        file_content = await file.read()
        file_hash = hashlib.md5(file_content).hexdigest()
        doc_id = f"file_{file_hash}"
        
        # ì¤‘ë³µ ì²´í¬
        if db.is_file_exists(user_id, doc_id):
            return {
                "success": True,
                "skipped": True,
                "message": "ì´ë¯¸ ìˆ˜ì§‘ëœ íŒŒì¼ì…ë‹ˆë‹¤.",
                "chunks_count": 0
            }
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ í›„ DocumentParserë¡œ íŒŒì‹±
        ext = Path(file_path).suffix.lower()
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp_file:
            tmp_file.write(file_content)
            tmp_path = tmp_file.name
        
        try:
            # DocumentParserë¡œ íŒŒì‹± (Docling ì‚¬ìš©)
            parser = DocumentParser()
            chunks = parser.parse_and_chunk(tmp_path)
            
            if not chunks:
                return {
                    "success": True,
                    "skipped": True,
                    "message": "íŒŒì‹±ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.",
                    "chunks_count": 0
                }
            
            # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥
            file_info = {
                'user_id': user_id,
                'file_path': file_path,
                'file_category': file_category,
                'modified_date': datetime.utcnow()
            }
            db.insert_collected_file(file_info)
            
            # ì²­í¬ ì„ë² ë”© ë° ì¸ë±ì‹±
            all_texts = []
            all_metas = []
            
            for chunk in chunks:
                text = chunk.get('text', '') if isinstance(chunk, dict) else str(chunk)
                if not text or not text.strip():
                    continue
                
                snippet = chunk.get('snippet', text[:200]) if isinstance(chunk, dict) else text[:200]
                
                all_texts.append(text)
                all_metas.append({
                    'user_id': user_id,
                    'source': 'file',
                    'path': file_path,
                    'doc_id': doc_id,
                    'chunk_id': chunk.get('chunk_id', len(all_texts) - 1) if isinstance(chunk, dict) else len(all_texts) - 1,
                    'snippet': snippet,
                    'content': text
                })
            
            if all_texts:
                # ë°°ì¹˜ ì„ë² ë”©
                batch_size = 64
                for i in range(0, len(all_texts), batch_size):
                    batch_texts = all_texts[i:i + batch_size]
                    batch_metas = all_metas[i:i + batch_size]
                    
                    embeddings = embedder.encode_documents(batch_texts)
                    dense_vectors = embeddings['dense_vecs'].tolist()
                    sparse_vectors = [
                        embedder.convert_sparse_to_qdrant_format(lw)
                        for lw in embeddings['lexical_weights']
                    ]
                    repository.qdrant.upsert_vectors(batch_metas, dense_vectors, sparse_vectors)
            
            logger.info(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file_path} ({len(all_texts)}ê°œ ì²­í¬)")
            
            return {
                "success": True,
                "skipped": False,
                "message": f"íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ",
                "chunks_count": len(all_texts)
            }
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            try:
                os.unlink(tmp_path)
            except:
                pass
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")


@router.post("/data-collection/client-upload/{user_id}")
async def client_upload_data(
    user_id: int,
    payload: ClientCollectionRequest,
    request: Request
):
    """
    í´ë¼ì´ì–¸íŠ¸ì—ì„œ íŒŒì‹±ëœ ë°ì´í„°ë¥¼ ë°›ì•„ ì¸ë±ì‹±í•©ë‹ˆë‹¤.
    (í…ìŠ¤íŠ¸ íŒŒì¼ìš© - ë¡œì»¬ì—ì„œ íŒŒì‹±í•œ ê²½ìš°)
    """
    try:
        repository: Repository = getattr(request.app.state, "repository", None)
        embedder: BGEM3Embedder = getattr(request.app.state, "embedder", None)
        
        if repository is None or embedder is None:
            raise HTTPException(
                status_code=500,
                detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        db = SQLite()
        processed_count = 0
        skipped_count = 0
        total_chunks = 0
        
        all_texts = []
        all_metas = []
        
        for file_data in payload.files:
            doc_id = f"file_{file_data.file_hash}"
            
            # ì¤‘ë³µ ì²´í¬
            if db.is_file_exists(user_id, doc_id):
                skipped_count += 1
                continue
            
            # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥
            file_info = {
                'user_id': user_id,
                'file_path': file_data.file_path,
                'file_category': file_data.file_category,
                'modified_date': datetime.utcnow()
            }
            db.insert_collected_file(file_info)
            
            # ì²­í¬ ìˆ˜ì§‘
            for i, chunk in enumerate(file_data.chunks):
                text = chunk.get('text', '')
                snippet = chunk.get('snippet', text[:200] if text else '')
                
                if not text.strip():
                    continue
                
                all_texts.append(text)
                all_metas.append({
                    'user_id': user_id,
                    'source': 'file',
                    'path': file_data.file_path,
                    'doc_id': doc_id,
                    'chunk_id': i,
                    'snippet': snippet,
                    'content': text
                })
                total_chunks += 1
            
            processed_count += 1
        
        # ì„ë² ë”© ë° Qdrant ì¸ë±ì‹± (ë°°ì¹˜ ì²˜ë¦¬)
        if all_texts:
            logger.info(f"í´ë¼ì´ì–¸íŠ¸ ì—…ë¡œë“œ: {len(all_texts)}ê°œ ì²­í¬ ì„ë² ë”© ì¤‘...")
            
            # ë°°ì¹˜ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ìµœì í™”)
            batch_size = 64
            for i in range(0, len(all_texts), batch_size):
                batch_texts = all_texts[i:i + batch_size]
                batch_metas = all_metas[i:i + batch_size]
                
                embeddings = embedder.encode_documents(batch_texts)
                dense_vectors = embeddings['dense_vecs'].tolist()
                sparse_vectors = [
                    embedder.convert_sparse_to_qdrant_format(lw)
                    for lw in embeddings['lexical_weights']
                ]
                repository.qdrant.upsert_vectors(batch_metas, dense_vectors, sparse_vectors)
            
            logger.info(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—…ë¡œë“œ ì™„ë£Œ: {processed_count}ê°œ íŒŒì¼, {total_chunks}ê°œ ì²­í¬")
        
        return {
            "success": True,
            "processed_files": processed_count,
            "skipped_files": skipped_count,
            "total_chunks": total_chunks,
            "message": f"{processed_count}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ ({skipped_count}ê°œ ìŠ¤í‚µ)"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ì—…ë¡œë“œ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")


@router.post("/data-collection/client-status/{user_id}")
async def update_client_collection_status(
    user_id: int,
    payload: ClientCollectionProgress,
    request: Request
):
    """í´ë¼ì´ì–¸íŠ¸ ì¸¡ ìˆ˜ì§‘ ì§„í–‰ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    try:
        repository: Repository = getattr(request.app.state, "repository", None)
        embedder: BGEM3Embedder = getattr(request.app.state, "embedder", None)
        
        if repository is None or embedder is None:
            return {"success": True}  # ì•„ì§ ì´ˆê¸°í™” ì•ˆë¨ - ë¬´ì‹œ
        
        # ë§¤ë‹ˆì €ê°€ ìˆìœ¼ë©´ ìƒíƒœ ì—…ë°ì´íŠ¸
        if user_id in data_collection_managers:
            manager = data_collection_managers[user_id]
            manager.progress = payload.progress
            manager.progress_message = payload.message
            if payload.is_done:
                manager.initial_collection_done = True
        else:
            # ë§¤ë‹ˆì € ìƒì„± ë° ìƒíƒœ ì„¤ì •
            manager = get_manager(user_id, repository=repository, embedder=embedder)
            manager.progress = payload.progress
            manager.progress_message = payload.message
            if payload.is_done:
                manager.initial_collection_done = True
        
        return {"success": True}
        
    except Exception as e:
        logger.error(f"í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}


class ClientBrowserHistoryRequest(BaseModel):
    """í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì „ì†¡í•˜ëŠ” ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ë°ì´í„°"""
    history: List[Dict[str, Any]]


@router.post("/data-collection/client-browser-history/{user_id}")
async def client_browser_history_upload(
    user_id: int,
    payload: ClientBrowserHistoryRequest,
    request: Request,
    background_tasks: BackgroundTasks
):
    """
    í´ë¼ì´ì–¸íŠ¸ì—ì„œ ìˆ˜ì§‘í•œ ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ë¥¼ ë°›ì•„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    íˆìŠ¤í† ë¦¬ ë°ì´í„°ë¥¼ SQLiteì— ì €ì¥í•˜ê³ , ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì›¹ í¬ë¡¤ë§ ë° ì¸ë±ì‹±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    try:
        repository: Repository = getattr(request.app.state, "repository", None)
        embedder: BGEM3Embedder = getattr(request.app.state, "embedder", None)
        
        if repository is None or embedder is None:
            raise HTTPException(
                status_code=500,
                detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        db = SQLite()
        saved_count = 0
        skipped_count = 0
        history_items_for_indexing = []
        
        for item in payload.history:
            url = item.get('url', '')
            title = item.get('title', '')
            visit_time_str = item.get('visit_time', '')
            browser_name = item.get('browser_name', 'unknown')
            
            if not url:
                continue
            
            # visit_time íŒŒì‹±
            try:
                visit_time = datetime.fromisoformat(visit_time_str)
            except:
                visit_time = datetime.utcnow()
            
            # ì¤‘ë³µ ì²´í¬
            if db.is_browser_log_duplicate(user_id, url, visit_time):
                skipped_count += 1
                continue
            
            # SQLiteì— ì €ì¥
            history_data = {
                'user_id': user_id,
                'browser_name': browser_name,
                'url': url,
                'title': title,
                'visit_time': visit_time
            }
            
            log_id = db.insert_collected_browser_history(history_data)
            if log_id:
                saved_count += 1
                history_items_for_indexing.append({
                    'log_id': log_id,
                    'url': url,
                    'title': title,
                    'visit_time': visit_time
                })
        
        logger.info(f"âœ… ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ì €ì¥: {saved_count}ê°œ ì €ì¥, {skipped_count}ê°œ ìŠ¤í‚µ")
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì›¹ í¬ë¡¤ë§ ë° ì¸ë±ì‹± ìˆ˜í–‰
        if history_items_for_indexing:
            background_tasks.add_task(
                _index_browser_history_background,
                user_id,
                history_items_for_indexing,
                repository,
                embedder
            )
        
        return {
            "success": True,
            "saved_count": saved_count,
            "skipped_count": skipped_count,
            "message": f"{saved_count}ê°œ íˆìŠ¤í† ë¦¬ ì €ì¥ ì™„ë£Œ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}")


async def _index_browser_history_background(
    user_id: int,
    history_items: List[Dict[str, Any]],
    repository: Repository,
    embedder: BGEM3Embedder
):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ì˜ ì›¹ ì½˜í…ì¸ ë¥¼ í¬ë¡¤ë§í•˜ê³  ì¸ë±ì‹±í•©ë‹ˆë‹¤."""
    import aiohttp
    from database.document_parser import DocumentParser
    
    logger.info(f"ğŸŒ ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ ì¸ë±ì‹± ì‹œì‘: {len(history_items)}ê°œ URL")
    
    parser = DocumentParser()
    db = SQLite()
    
    all_texts = []
    all_metas = []
    
    async with aiohttp.ClientSession() as session:
        for item in history_items:
            url = item['url']
            title = item['title']
            log_id = item['log_id']
            visit_time = item['visit_time']
            
            try:
                # ì›¹ ì½˜í…ì¸  í¬ë¡¤ë§
                content = await _crawl_url(session, url)
                
                if not content or len(content.strip()) < 100:
                    continue
                
                # ì²­í¬ ë¶„í• 
                chunks = parser.chunk_text(content)
                doc_id = f"web_{hashlib.md5(url.encode()).hexdigest()}"
                
                for i, chunk in enumerate(chunks):
                    all_texts.append(chunk)
                    all_metas.append({
                        'user_id': user_id,
                        'source': 'web',
                        'url': url,
                        'title': title,
                        'doc_id': doc_id,
                        'chunk_id': i,
                        'timestamp': int(visit_time.timestamp()),
                        'snippet': chunk[:200],
                        'content': chunk
                    })
                
            except Exception as e:
                logger.debug(f"URL í¬ë¡¤ë§ ì‹¤íŒ¨ ({url}): {e}")
                continue
    
    # ì„ë² ë”© ë° Qdrant ì¸ë±ì‹±
    if all_texts:
        logger.info(f"ğŸ§  {len(all_texts)}ê°œ ì›¹ ì²­í¬ ì„ë² ë”© ìƒì„± ì¤‘...")
        
        batch_size = 64
        for i in range(0, len(all_texts), batch_size):
            batch_texts = all_texts[i:i + batch_size]
            batch_metas = all_metas[i:i + batch_size]
            
            try:
                embeddings = embedder.encode_documents(batch_texts)
                dense_vectors = embeddings['dense_vecs'].tolist()
                sparse_vectors = [
                    embedder.convert_sparse_to_qdrant_format(lw)
                    for lw in embeddings['lexical_weights']
                ]
                repository.qdrant.upsert_vectors(batch_metas, dense_vectors, sparse_vectors)
            except Exception as e:
                logger.error(f"ì›¹ ì²­í¬ ì„ë² ë”© ì˜¤ë¥˜: {e}")
        
        logger.info(f"âœ… ì›¹ ì½˜í…ì¸  ì¸ë±ì‹± ì™„ë£Œ: {len(all_texts)}ê°œ ì²­í¬")


async def _crawl_url(session: aiohttp.ClientSession, url: str) -> Optional[str]:
    """URLì—ì„œ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=10), headers=headers) as response:
            if response.status != 200:
                return None
            
            content_type = response.headers.get('Content-Type', '')
            if 'text/html' not in content_type:
                return None
            
            html = await response.text()
            
            if len(html) < 500:
                return None
            
            # trafilaturaë¡œ ë³¸ë¬¸ ì¶”ì¶œ ì‹œë„
            try:
                import trafilatura
                extracted = trafilatura.extract(
                    html,
                    include_comments=False,
                    include_tables=False,
                    include_links=False,
                    favor_recall=False
                )
                if extracted and len(extracted.strip()) >= 100:
                    return extracted
            except ImportError:
                pass
            
            # BeautifulSoup í´ë°±
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html, 'lxml')
            
            for tag in soup(['script', 'style', 'nav', 'footer', 'aside', 'header', 'noscript']):
                tag.decompose()
            
            text = soup.get_text(separator='\n', strip=True)
            
            if len(text.strip()) >= 100:
                return text
            
    except Exception:
        pass
    
    return None


@router.post("/data-collection/client-complete/{user_id}")
async def complete_client_collection(user_id: int, request: Request):
    """í´ë¼ì´ì–¸íŠ¸ ì¸¡ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œë¥¼ ì•Œë¦½ë‹ˆë‹¤."""
    try:
        repository: Repository = getattr(request.app.state, "repository", None)
        embedder: BGEM3Embedder = getattr(request.app.state, "embedder", None)
        
        if repository is None or embedder is None:
            raise HTTPException(status_code=500, detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ ë¯¸ì´ˆê¸°í™”")
        
        # ë§¤ë‹ˆì € ìƒíƒœ ì—…ë°ì´íŠ¸
        if user_id in data_collection_managers:
            manager = data_collection_managers[user_id]
        else:
            manager = get_manager(user_id, repository=repository, embedder=embedder)
        
        manager.progress = 100.0
        manager.progress_message = "âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ"
        manager.initial_collection_done = True
        
        # ì¶”ì²œ ë¶„ì„ íŠ¸ë¦¬ê±°
        try:
            from main import trigger_recommendation_analysis
            asyncio.create_task(trigger_recommendation_analysis(force_recommend=True))
            logger.info(f"ğŸ¯ ì‚¬ìš©ì {user_id} ì´ˆê¸° ì¶”ì²œ ë¶„ì„ íŠ¸ë¦¬ê±°ë¨")
        except Exception as e:
            logger.warning(f"ì¶”ì²œ ë¶„ì„ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
        
        return {
            "success": True,
            "message": "ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìˆ˜ì§‘ ì™„ë£Œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/data-collection/stats")
async def get_data_collection_stats():
    """ë°ì´í„° ìˆ˜ì§‘ í†µê³„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        from database.sqlite import SQLite
        
        db = SQLite()
        
        # ê° í…Œì´ë¸”ì˜ ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
        stats = db.get_collection_stats()
        file_count = stats.get('files', 0)
        browser_count = stats.get('browser_logs', 0)
        keyword_count = stats.get('content_keywords', 0)
        
        # ìµœê·¼ 24ì‹œê°„ ë‚´ ë°ì´í„° ìˆ˜ (ì „ì²´ ë°ì´í„°ì˜ ì•½ 1/7ì„ ìµœê·¼ 24ì‹œê°„ìœ¼ë¡œ ì¶”ì •)
        from datetime import datetime, timedelta
        yesterday = datetime.utcnow() - timedelta(days=1)
        
        recent_files = file_count // 7
        recent_browser = browser_count // 7
        recent_keywords = keyword_count // 7
        
        return {
            "total_records": {
                "files": file_count,
                "browser_history": browser_count,
                "content_keywords": keyword_count
            },
            "last_24_hours": {
                "files": recent_files,
                "browser_history": recent_browser,
                "content_keywords": recent_keywords
            },
            "active_collectors": len(data_collection_managers),
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")


# =========================================================================
# íŒŒì¼ ì—…ë¡œë“œ API (exe í´ë¼ì´ì–¸íŠ¸ìš©)
# =========================================================================

@router.post("/files/upload/{user_id}")
async def upload_file_for_processing(
    user_id: int,
    request: Request,
    file: UploadFile = File(...),
    original_path: str = Form(...),
    file_category: str = Form("document")
):
    """
    í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì—…ë¡œë“œí•œ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. (exe í™˜ê²½ìš©)
    
    - íŒŒì¼ì„ ì„ì‹œ ì €ì¥
    - íŒŒì‹± ë° ì²­í¬ ë¶„í• 
    - Qdrantì— ì¸ë±ì‹±
    - SQLiteì— ë©”íƒ€ë°ì´í„° ì €ì¥
    """
    try:
        repository: Repository = getattr(request.app.state, "repository", None)
        embedder: BGEM3Embedder = getattr(request.app.state, "embedder", None)
        
        if repository is None or embedder is None:
            raise HTTPException(
                status_code=500,
                detail="ì„œë²„ ë¦¬ì†ŒìŠ¤ê°€ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸°
        content = await file.read()
        file_size = len(content)
        
        # íŒŒì¼ í¬ê¸° ì œí•œ (50MB)
        if file_size > 50 * 1024 * 1024:
            raise HTTPException(status_code=413, detail="íŒŒì¼ í¬ê¸°ê°€ 50MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (íŒŒì„œê°€ íŒŒì¼ ê²½ë¡œë¥¼ í•„ìš”ë¡œ í•¨)
        import os
        from pathlib import Path as PathLib
        
        file_ext = PathLib(file.filename).suffix.lower()
        temp_dir = tempfile.mkdtemp(prefix="jarvis_upload_")
        temp_path = os.path.join(temp_dir, file.filename)
        
        try:
            with open(temp_path, 'wb') as f:
                f.write(content)
            
            # íŒŒì¼ í•´ì‹œ ê³„ì‚° (ì¤‘ë³µ ì²´í¬ìš©)
            file_hash = hashlib.md5(content).hexdigest()
            
            # SQLiteì— íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥
            db = SQLite()
            file_info = {
                'user_id': user_id,
                'file_path': original_path,  # ì›ë³¸ ê²½ë¡œ ì €ì¥
                'file_name': file.filename,
                'file_size': file_size,
                'file_category': file_category,
                'file_hash': file_hash,
                'modified_date': datetime.utcnow()
            }
            
            # ì¤‘ë³µ ì²´í¬
            if db.is_file_already_collected(user_id, original_path, file_hash):
                logger.info(f"íŒŒì¼ ì´ë¯¸ ìˆ˜ì§‘ë¨, ìŠ¤í‚µ: {file.filename}")
                return {
                    "success": True,
                    "message": f"íŒŒì¼ì´ ì´ë¯¸ ìˆ˜ì§‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {file.filename}",
                    "skipped": True
                }
            
            # ë¬¸ì„œ íŒŒì‹± ë° ì²­í¬ ë¶„í• 
            from database.document_parser import DocumentParser
            parser = DocumentParser()
            
            try:
                chunk_infos = parser.parse_and_chunk(temp_path)
            except Exception as e:
                logger.warning(f"íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨ ({file.filename}): {e}")
                return {
                    "success": False,
                    "message": f"íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}",
                    "filename": file.filename
                }
            
            if not chunk_infos:
                logger.warning(f"ì²­í¬ ì—†ìŒ: {file.filename}")
                return {
                    "success": True,
                    "message": f"íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file.filename}",
                    "chunks": 0
                }
            
            # ì²­í¬ë¥¼ Qdrantì— ì¸ë±ì‹±
            doc_id = f"file_{file_hash}"
            texts = []
            metas = []
            
            for chunk in chunk_infos:
                texts.append(chunk['text'])
                metas.append({
                    'user_id': user_id,
                    'source': 'file',
                    'path': original_path,
                    'doc_id': doc_id,
                    'chunk_id': chunk['chunk_id'],
                    'snippet': chunk['snippet'],
                    'content': chunk['text']
                })
            
            # ì„ë² ë”© ë° Qdrant ì—…ë¡œë“œ
            embeddings = embedder.encode_documents(texts)  # encode -> encode_documents
            dense_vectors = embeddings['dense_vecs'].tolist()
            sparse_vectors = [
                embedder.convert_sparse_to_qdrant_format(lw)
                for lw in embeddings['lexical_weights']
            ]
            repository.qdrant.upsert_vectors(metas, dense_vectors, sparse_vectors)
            
            # SQLiteì— íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥
            db.insert_collected_file(file_info)
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì €ì¥
            from database.data_collector import extract_keywords_from_text, create_snippet
            combined_text = '\n'.join(texts)
            
            if len(combined_text.strip()) >= 50:
                keywords = extract_keywords_from_text(combined_text, top_n=10)
                if keywords:
                    snippet = create_snippet(combined_text, max_length=200)
                    keyword_entries = []
                    for keyword, score in keywords:
                        keyword_entries.append({
                            'user_id': user_id,
                            'source_type': 'file',
                            'source_id': doc_id,
                            'keyword': keyword,
                            'original_text': snippet
                        })
                    db.insert_content_keywords_batch(user_id, keyword_entries)
            
            logger.info(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ ì™„ë£Œ: {file.filename} ({len(chunk_infos)}ê°œ ì²­í¬)")
            
            return {
                "success": True,
                "message": f"íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {file.filename}",
                "filename": file.filename,
                "chunks": len(chunk_infos),
                "doc_id": doc_id
            }
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            try:
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)
            except:
                pass
                
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")


@router.post("/files/upload-batch/{user_id}")
async def upload_files_batch(
    user_id: int,
    request: Request,
    files: List[UploadFile] = File(...),
    original_paths: str = Form(...)  # JSON ë°°ì—´ë¡œ ì „ë‹¬
):
    """
    ì—¬ëŸ¬ íŒŒì¼ì„ ì¼ê´„ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    original_pathsëŠ” JSON ë°°ì—´ ë¬¸ìì—´ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.
    """
    import json
    
    try:
        paths = json.loads(original_paths)
    except:
        raise HTTPException(status_code=400, detail="original_pathsëŠ” JSON ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
    
    if len(files) != len(paths):
        raise HTTPException(
            status_code=400, 
            detail=f"íŒŒì¼ ìˆ˜({len(files)})ì™€ ê²½ë¡œ ìˆ˜({len(paths)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )
    
    results = []
    success_count = 0
    
    for file, path in zip(files, paths):
        try:
            # ê°œë³„ íŒŒì¼ ì²˜ë¦¬ (ë‹¨ì¼ ì—…ë¡œë“œ API í˜¸ì¶œê³¼ ë™ì¼í•œ ë¡œì§)
            result = await upload_file_for_processing(
                user_id=user_id,
                request=request,
                file=file,
                original_path=path,
                file_category="document"
            )
            results.append(result)
            if result.get("success"):
                success_count += 1
        except Exception as e:
            results.append({
                "success": False,
                "filename": file.filename,
                "error": str(e)
            })
    
    return {
        "success": True,
        "total": len(files),
        "success_count": success_count,
        "results": results
    }


@router.get("/user-survey/{user_id}")
async def get_user_survey(user_id: int):
    """ì‚¬ìš©ì ì„¤ë¬¸ì§€ ì‘ë‹µì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        db = SQLite()
        survey_data = db.get_user_survey_response(user_id)
        
        if survey_data:
            return {
                "success": True,
                "survey_data": survey_data,
                "timestamp": datetime.utcnow().isoformat()
            }
        else:
            return {
                "success": False,
                "message": "ì„¤ë¬¸ì§€ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "timestamp": datetime.utcnow().isoformat()
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„¤ë¬¸ì§€ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@router.get("/user-survey/{user_id}/completed")
async def check_survey_completed(user_id: int):
    """ì‚¬ìš©ìê°€ ì„¤ë¬¸ì§€ë¥¼ ì™„ë£Œí–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        db = SQLite()
        completed = db.has_user_completed_survey(user_id)
        
        return {
            "success": True,
            "completed": completed,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„¤ë¬¸ì§€ ì™„ë£Œ ì—¬ë¶€ í™•ì¸ ì˜¤ë¥˜: {str(e)}")

@router.post("/user-profile/{user_id}/index")
async def index_user_profile(user_id: int, request: Request):
    """ì‚¬ìš©ì í”„ë¡œí•„ì„ Qdrantì— ì¸ë±ì‹±í•©ë‹ˆë‹¤."""
    try:
        from database.user_profile_indexer import UserProfileIndexer
        
        # ì „ì—­ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        indexer: UserProfileIndexer = request.app.state.profile_indexer
        success = indexer.index_user_profile(user_id)
        
        if success:
            return {
                "success": True,
                "message": f"ì‚¬ìš©ì {user_id}ì˜ í”„ë¡œí•„ì´ ì„±ê³µì ìœ¼ë¡œ ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "timestamp": datetime.utcnow().isoformat()
            }
        else:
            return {
                "success": False,
                "message": "í”„ë¡œí•„ ì¸ë±ì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "timestamp": datetime.utcnow().isoformat()
            }
    except Exception as e:
        logger.error(f"í”„ë¡œí•„ ì¸ë±ì‹± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í”„ë¡œí•„ ì¸ë±ì‹± ì˜¤ë¥˜: {str(e)}")

@router.post("/user-profile/{user_id}/update")
async def update_user_profile(user_id: int, survey_data: dict, request: Request):
    """ì‚¬ìš©ì ì„¤ë¬¸ì¡°ì‚¬ë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  í”„ë¡œí•„ì„ ì¬ì¸ë±ì‹±í•©ë‹ˆë‹¤."""
    try:
        from database.user_profile_indexer import UserProfileIndexer
        
        # SQLiteì— ì„¤ë¬¸ì¡°ì‚¬ ì—…ë°ì´íŠ¸
        db = SQLite()
        success = db.insert_survey_response(user_id, survey_data)
        
        if not success:
            return {
                "success": False,
                "message": "ì„¤ë¬¸ì¡°ì‚¬ ë°ì´í„° ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                "timestamp": datetime.utcnow().isoformat()
            }
        
        # ì „ì—­ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        indexer: UserProfileIndexer = request.app.state.profile_indexer
        index_success = indexer.update_user_profile(user_id)
        
        return {
            "success": True,
            "message": f"ì‚¬ìš©ì {user_id}ì˜ í”„ë¡œí•„ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "indexed": index_success,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"í”„ë¡œí•„ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í”„ë¡œí•„ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")

@router.get("/user-profile/{user_id}")
async def get_user_profile_context(user_id: int, request: Request):
    """ì‚¬ìš©ì í”„ë¡œí•„ì„ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        from database.user_profile_indexer import UserProfileIndexer
        
        # ì „ì—­ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        indexer: UserProfileIndexer = request.app.state.profile_indexer
        profile_text = indexer.get_profile_as_context(user_id)
        
        if profile_text:
            return {
                "success": True,
                "profile": profile_text,
                "timestamp": datetime.utcnow().isoformat()
            }
        else:
            return {
                "success": False,
                "message": "í”„ë¡œí•„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "timestamp": datetime.utcnow().isoformat()
            }
    except Exception as e:
        logger.error(f"í”„ë¡œí•„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í”„ë¡œí•„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}") 

# ============================================================================
# ì¶”ì²œ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

@router.get("/recommendations")
async def get_recommendations(user_id: int = Depends(get_current_user_id)):
    """í˜„ì¬ ì‚¬ìš©ìì˜ ì½ì§€ ì•Šì€ ì¶”ì²œ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        db = SQLite()
        recommendations = db.get_unread_recommendations(user_id)
        return {
            "success": True,
            "recommendations": recommendations
        }
    except Exception as e:
        logger.error(f"ì¶”ì²œ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/recommendations/history")
async def get_recommendation_history(user_id: int = Depends(get_current_user_id)):
    """í˜„ì¬ ì‚¬ìš©ìì˜ ëª¨ë“  ì¶”ì²œ ë‚´ì—­ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    try:
        db = SQLite()
        recommendations = db.get_all_recommendations(user_id)
        return {
            "success": True,
            "recommendations": recommendations
        }
    except Exception as e:
        logger.error(f"ì¶”ì²œ ë‚´ì—­ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/recommendations/{recommendation_id}/read")
async def mark_recommendation_read(
    recommendation_id: int,
    user_id: int = Depends(get_current_user_id)
):
    """ì¶”ì²œì„ ì½ìŒìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤."""
    try:
        db = SQLite()
        success = db.mark_recommendation_as_read(user_id, recommendation_id)
        if success:
            return {"success": True, "message": "Recommendation marked as read."}
        else:
            raise HTTPException(status_code=404, detail="Recommendation not found or failed to update.")
    except Exception as e:
        logger.error(f"ì¶”ì²œ ì½ìŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/recommendations/{recommendation_id}/respond")
async def respond_to_recommendation(
    recommendation_id: int,
    request_data: dict,
    user_id: int = Depends(get_current_user_id)
):
    """
    ì¶”ì²œì— ëŒ€í•œ ì‚¬ìš©ì ì‘ë‹µ(ìˆ˜ë½/ê±°ì ˆ)ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    - action='accept': ì¶”ì²œ ìˆ˜ë½ â†’ ë¦¬í¬íŠ¸ ìƒì„± í›„ ë°˜í™˜
    - action='reject': ì¶”ì²œ ê±°ì ˆ â†’ í‚¤ì›Œë“œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
    
    ì‘ë‹µ (accept ì‹œ):
        {
            "success": true,
            "action": "accept",
            "report_content": "...",
            "offer_deep_dive": true,  // ì‹¬ì¸µ ë³´ê³ ì„œ ì œì•ˆ ì—¬ë¶€
            "keyword": "Python",
            "recommendation_id": 123
        }
    """
    try:
        action = request_data.get("action")
        if action not in ["accept", "reject"]:
            raise HTTPException(status_code=400, detail="action must be 'accept' or 'reject'")
        
        # ì¶”ì²œ ì—ì´ì „íŠ¸ ê°€ì ¸ì˜¤ê¸°
        recommendation_agent = agent_registry.get_agent("recommendation")
        if not recommendation_agent:
            raise HTTPException(status_code=503, detail="ì¶”ì²œ ê¸°ëŠ¥ì´ í˜„ì¬ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # ì¶”ì²œ ì†Œìœ ê¶Œ í™•ì¸
        db = SQLite()
        recommendation = db.get_recommendation(user_id, recommendation_id)
        if not recommendation:
            raise HTTPException(status_code=404, detail="ì¶”ì²œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        keyword = recommendation.get("keyword", "")
        
        # handle_response í˜¸ì¶œ (ë¹„ë™ê¸°)
        success, result_message = await recommendation_agent.handle_response(user_id, recommendation_id, action)
        
        if action == "accept" and success:
            # ìˆ˜ë½ ì‹œ: ì‹¬ì¸µ ë³´ê³ ì„œ ì œì•ˆ í¬í•¨
            return {
                "success": success,
                "action": action,
                "report_content": result_message,
                "offer_deep_dive": True,  # ReportAgentë¥¼ í†µí•œ ì‹¬ì¸µ ë³´ê³ ì„œ ì œì•ˆ
                "keyword": keyword,
                "recommendation_id": recommendation_id
            }
        elif action == "reject":
            # ê±°ì ˆ ì‹œ
            return {
                "success": success,
                "action": action,
                "message": result_message,
                "keyword": keyword,
                "recommendation_id": recommendation_id
            }
        else:
            # ì‹¤íŒ¨ ì‹œ
            return {
                "success": success,
                "action": action,
                "message": result_message if not success else None,
                "keyword": keyword,
                "recommendation_id": recommendation_id
            }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì¶”ì²œ ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì¶”ì²œ ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# ============================================================================
# ì‚¬ìš©ì ì„¤ì • ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

@router.post("/settings/initial-setup")
async def initial_setup(
    request: dict,
    user_id: int = Depends(get_current_user_id)
):
    """ì´ˆê¸° ì„¤ì • ì™„ë£Œ - í´ë” ê²½ë¡œ ì €ì¥ ë° ì„¤ì • ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
    try:
        db = SQLite()
        folder_path = request.get("folder_path", "")
        
        # í´ë” ê²½ë¡œ ì—…ë°ì´íŠ¸
        success1 = db.update_user_folder(user_id, folder_path)
        
        # ì„¤ì • ì™„ë£Œ ìƒíƒœ ì—…ë°ì´íŠ¸
        success2 = db.update_user_setup_status(user_id, 1)
        
        if success1 and success2:
            return {
                "success": True,
                "message": "ì´ˆê¸° ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        else:
            raise HTTPException(status_code=500, detail="ì„¤ì • ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        logger.error(f"ì´ˆê¸° ì„¤ì • ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# ë³´ê³ ì„œ ìƒì„± ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
# ============================================================================

async def _create_report_background_task(
    user_id: int,
    keyword: str,
    recommendation_id: Optional[int] = None
):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ê³  ì™„ë£Œ ì‹œ WebSocketìœ¼ë¡œ ì•Œë¦¼ì„ ë³´ëƒ…ë‹ˆë‹¤.
    
    Args:
        user_id: ì‚¬ìš©ì ID
        keyword: ë³´ê³ ì„œ ì£¼ì œ í‚¤ì›Œë“œ
        recommendation_id: ì—°ê´€ëœ ì¶”ì²œ ID (ì„ íƒ)
    """
    from core.websocket_manager import get_websocket_manager
    from database.sqlite import SQLite
    
    logger.info(f"ğŸ“„ ë³´ê³ ì„œ ìƒì„± ì‹œì‘: user_id={user_id}, keyword='{keyword}'")
    
    try:
        # ReportAgent ê°€ì ¸ì˜¤ê¸°
        report_agent = agent_registry.get_agent("report")
        if not report_agent:
            logger.error("ReportAgentë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            ws_manager = get_websocket_manager()
            await ws_manager.broadcast_report_failed(
                user_id, keyword, "ReportAgentë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
            return
        
        # ë³´ê³ ì„œ ìƒì„± ì‹¤í–‰
        result = await report_agent.create_report(
            user_id=user_id,
            keyword=keyword,
            recommendation_id=recommendation_id
        )
        
        ws_manager = get_websocket_manager()
        
        if result.get("success"):
            # ì„±ê³µ: DB ì—…ë°ì´íŠ¸ ë° WebSocket ì•Œë¦¼
            logger.info(f"ğŸ“„ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {result.get('pdf_filename')}")
            
            pdf_path = result.get("pdf_path", "")
            
            # recommendation_idê°€ ìˆìœ¼ë©´ report_file_path ì—…ë°ì´íŠ¸
            if recommendation_id:
                db = SQLite()
                db.update_recommendation_report_path(
                    user_id,
                    recommendation_id, 
                    pdf_path
                )
            
            # 1. ë¨¼ì € WebSocket ì•Œë¦¼ ì „ì†¡ (ì‚¬ìš©ìì—ê²Œ ì™„ë£Œ ì•Œë¦¼)
            await ws_manager.broadcast_report_completed(
                user_id=user_id,
                keyword=keyword,
                file_path=pdf_path,
                file_name=result.get("pdf_filename", ""),
                sources=result.get("sources", [])
            )
            
            # 2. ê·¸ í›„ ë³´ê³ ì„œ íŒŒì¼ì„ SQLiteì™€ Qdrantì— ì¸ë±ì‹± (ì±„íŒ…ì—ì„œ ê²€ìƒ‰ ê°€ëŠ¥í•˜ë„ë¡)
            if pdf_path:
                try:
                    from utils.report_indexer import index_report_file_async
                    indexing_success = await index_report_file_async(
                        file_path=pdf_path,
                        user_id=user_id,
                        keyword=keyword
                    )
                    if indexing_success:
                        logger.info(f"ğŸ“„ ë³´ê³ ì„œ ì¸ë±ì‹± ì™„ë£Œ: {pdf_path}")
                    else:
                        logger.warning(f"ğŸ“„ ë³´ê³ ì„œ ì¸ë±ì‹± ì‹¤íŒ¨ (íŒŒì¼ì€ ìƒì„±ë¨): {pdf_path}")
                except Exception as e:
                    logger.warning(f"ğŸ“„ ë³´ê³ ì„œ ì¸ë±ì‹± ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")
        else:
            # ì‹¤íŒ¨: WebSocket ì•Œë¦¼
            error_message = result.get("message", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            logger.error(f"ğŸ“„ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {error_message}")
            
            await ws_manager.broadcast_report_failed(
                user_id=user_id,
                keyword=keyword,
                reason=error_message
            )
            
    except Exception as e:
        logger.exception(f"ğŸ“„ ë³´ê³ ì„œ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì˜¤ë¥˜: {e}")
        try:
            ws_manager = get_websocket_manager()
            await ws_manager.broadcast_report_failed(
                user_id=user_id,
                keyword=keyword,
                reason=str(e)
            )
        except Exception:
            pass


@router.post("/reports/create")
async def create_report(
    request_data: dict,
    background_tasks: BackgroundTasks,
    user_id: int = Depends(get_current_user_id)
):
    """
    ë³´ê³ ì„œ ìƒì„± ìš”ì²­ (ë¹„ë™ê¸° - ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)
    
    ìš”ì²­ JSON:
        {
            "keyword": "ë³´ê³ ì„œ ì£¼ì œ",
            "recommendation_id": 123  // ì„ íƒì 
        }
    
    ì‘ë‹µ:
        ì¦‰ì‹œ HTTP 202 ë°˜í™˜, ì™„ë£Œ ì‹œ WebSocketìœ¼ë¡œ ì•Œë¦¼
    """
    keyword = request_data.get("keyword", "").strip()
    recommendation_id = request_data.get("recommendation_id")
    
    if not keyword:
        raise HTTPException(status_code=400, detail="keywordëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
    
    logger.info(f"ğŸ“„ ë³´ê³ ì„œ ìƒì„± ìš”ì²­ ì ‘ìˆ˜: user_id={user_id}, keyword='{keyword}'")
    
    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ë³´ê³ ì„œ ìƒì„± ì‹œì‘
    background_tasks.add_task(
        _create_report_background_task,
        user_id=user_id,
        keyword=keyword,
        recommendation_id=recommendation_id
    )
    
    return {
        "success": True,
        "status": "queued",
        "message": f"'{keyword}' ë³´ê³ ì„œ ìƒì„±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì™„ë£Œë˜ë©´ ì•Œë¦¼ì„ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.",
        "keyword": keyword,
        "recommendation_id": recommendation_id
    }


@router.post("/settings/update-folder")
async def update_folder(
    request: dict,
    user_id: int = Depends(get_current_user_id)
):
    """
    ë°ì´í„° í´ë” ë³€ê²½ - ê¸°ì¡´ ë°ì´í„° ì™„ì „ ì‚­ì œ í›„ ì¬ìˆ˜ì§‘
    
    1. ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì§€
    2. SQLiteì—ì„œ user_id ê´€ë ¨ ë°ì´í„° ì‚­ì œ
    3. Qdrantì—ì„œ user_id ê´€ë ¨ ë²¡í„° ì‚­ì œ
    4. ìƒˆ í´ë” ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸
    5. ë°ì´í„° ìˆ˜ì§‘ ì¬ì‹œì‘
    """
    try:
        import os
        import sys
        from pathlib import Path
        
        db = SQLite()
        new_folder_path = request.get("new_folder_path", "")
        
        logger.info(f"ì‚¬ìš©ì {user_id}ì˜ ë°ì´í„° í´ë” ë³€ê²½ ì‹œì‘...")
        logger.info(f"ìƒˆ í´ë” ê²½ë¡œ: {new_folder_path}")
        
        # 1. ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì§€
        logger.info("ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì§€ ì¤‘...")
        from database.data_collector import get_manager
        # app.stateì—ì„œ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (FastAPI Request ê°ì²´ í•„ìš”)
        # ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” async í•¨ìˆ˜ì´ë¯€ë¡œ request_obj íŒŒë¼ë¯¸í„° ì¶”ê°€ í•„ìš”
        # ì„ì‹œë¡œ ê¸°ì¡´ ë§¤ë‹ˆì €ê°€ ìˆìœ¼ë©´ ì¤‘ì§€ë§Œ ìˆ˜í–‰
        from database.data_collector import data_collection_managers
        if user_id in data_collection_managers:
            manager = data_collection_managers[user_id]
            manager.stop_collection()
        
        # 2. SQLiteì—ì„œ user_id ê´€ë ¨ ë°ì´í„° ì‚­ì œ (ì‚¬ìš©ì DB íŒŒì¼)
        logger.info(f"SQLiteì—ì„œ ì‚¬ìš©ì {user_id}ì˜ ë°ì´í„° ì‚­ì œ ì¤‘...")
        try:
            # ì‚¬ìš©ìë³„ DB ì—°ê²°
            conn = db.get_user_connection(user_id)
            # files í…Œì´ë¸” ì‚­ì œ
            conn.execute("DELETE FROM files")
            # browser_logs í…Œì´ë¸” ì‚­ì œ
            conn.execute("DELETE FROM browser_logs")
            # content_keywords í…Œì´ë¸” ì‚­ì œ
            conn.execute("DELETE FROM content_keywords")
            # chat_messages í…Œì´ë¸” ì‚­ì œ
            conn.execute("DELETE FROM chat_messages")
            conn.commit()
            logger.info("SQLite ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"SQLite ë°ì´í„° ì‚­ì œ ì˜¤ë¥˜: {e}")
            conn = db.get_user_connection(user_id)
            if conn:
                conn.rollback()
        
        # 3. Qdrantì—ì„œ user_id ê´€ë ¨ ë²¡í„° ì‚­ì œ
        logger.info(f"Qdrantì—ì„œ ì‚¬ìš©ì {user_id}ì˜ ë²¡í„° ì‚­ì œ ì¤‘...")
        try:
            from database.qdrant_client import QdrantManager
            from qdrant_client import models
            
            qdrant = QdrantManager()
            
            # user_id í•„í„°ë¡œ ëª¨ë“  ë²¡í„° ê²€ìƒ‰
            from qdrant_client.http import models as qdrant_models
            
            # í¬ì¸íŠ¸ë¥¼ ìŠ¤í¬ë¡¤í•˜ì—¬ user_idë¡œ í•„í„°ë§
            scroll_result = qdrant.client.scroll(
                collection_name=qdrant.collection_name,
                scroll_filter=models.Filter(
                    must=[
                        models.FieldCondition(
                            key="user_id",
                            match=models.MatchValue(value=user_id)
                        )
                    ]
                ),
                limit=10000,
                with_payload=True
            )
            
            # ì‚­ì œí•  í¬ì¸íŠ¸ ID ìˆ˜ì§‘
            point_ids_to_delete = []
            for point in scroll_result[0]:
                if point.payload.get("user_id") == user_id:
                    point_ids_to_delete.append(point.id)
            
            # ë²¡í„° ì‚­ì œ
            if point_ids_to_delete:
                qdrant.client.delete(
                    collection_name=qdrant.collection_name,
                    points_selector=models.PointIdsList(points=point_ids_to_delete)
                )
                logger.info(f"Qdrantì—ì„œ {len(point_ids_to_delete)}ê°œ ë²¡í„° ì‚­ì œ ì™„ë£Œ")
            else:
                logger.info("ì‚­ì œí•  Qdrant ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"Qdrant ë²¡í„° ì‚­ì œ ì˜¤ë¥˜: {e}")
            # Qdrant ì‚­ì œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        
        # 4. ìƒˆ í´ë” ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸
        logger.info("ìƒˆ í´ë” ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸ ì¤‘...")
        success = db.update_user_folder(user_id, new_folder_path)
        
        if not success:
            raise HTTPException(status_code=500, detail="í´ë” ê²½ë¡œ ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # 5. ë°ì´í„° ìˆ˜ì§‘ ì¬ì‹œì‘
        logger.info("ë°ì´í„° ìˆ˜ì§‘ ì¬ì‹œì‘ ì¤‘...")
        try:
            # í´ë” ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„
            selected_folders = [new_folder_path] if new_folder_path else None
            
            # ìƒˆ ìŠ¤ë ˆë“œì—ì„œ ì´ˆê¸° ìˆ˜ì§‘ ì‹œì‘
            import threading
            collection_thread = threading.Thread(
                target=manager.perform_initial_collection,
                args=(selected_folders,),
                daemon=True
            )
            collection_thread.start()
            
            logger.info("ë°ì´í„° ìˆ˜ì§‘ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¬ì‹œì‘ ì˜¤ë¥˜: {e}")
            # ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨í•´ë„ ì„±ê³µ ë©”ì‹œì§€ ë°˜í™˜ (í´ë”ëŠ” ì—…ë°ì´íŠ¸ë¨)
        
        return {
            "success": True,
            "message": "ë°ì´í„° í´ë”ê°€ ì„±ê³µì ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆ ë°ì´í„°ê°€ ìˆ˜ì§‘ë˜ê³  ìˆìŠµë‹ˆë‹¤."
        }
    
    except Exception as e:
        logger.error(f"í´ë” ê²½ë¡œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# Dashboard API Endpoints
# =============================================================================

@router.get("/dashboard/summary")
async def get_dashboard_summary(user_id: int = Depends(get_current_user_id)):
    """ëŒ€ì‹œë³´ë“œ ì „ì²´ ìš”ì•½ ë°ì´í„° ì¡°íšŒ"""
    try:
        db = SQLite()
        
        # ì‚¬ìš©ì ì •ë³´
        user_info = db.get_user_by_id(user_id)
        if not user_info:
            raise HTTPException(status_code=404, detail="ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê´€ì‹¬ì‚¬ ìš”ì•½
        interest_summary = db.get_interest_summary(user_id)
        
        # í™œë™ ìš”ì•½
        activity_summary = db.get_activity_summary(user_id)
        
        return {
            "success": True,
            "data": {
                "user": {
                    "user_id": user_info.get("user_id"),
                    "email": user_info.get("email"),
                    "selected_folder": user_info.get("selected_root_folder"),
                    "has_completed_setup": user_info.get("has_completed_setup", False),
                    "created_at": user_info.get("created_at")
                },
                "interests": interest_summary,
                "activity": activity_summary
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ëŒ€ì‹œë³´ë“œ ìš”ì•½ ì¡°íšŒ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/dashboard/interests")
async def get_dashboard_interests(
    user_id: int = Depends(get_current_user_id),
    days: int = 30,
    limit: int = 20
):
    """ê´€ì‹¬ì‚¬ ëª©ë¡ ë° íŠ¸ë Œë“œ ì¡°íšŒ"""
    try:
        db = SQLite()
        
        # í˜„ì¬ ê´€ì‹¬ì‚¬ ëª©ë¡
        interests = db.get_user_interests(user_id, limit=limit)
        
        # ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ
        trend = db.get_interest_trend(user_id, days=days)
        
        return {
            "success": True,
            "data": {
                "interests": interests,
                "trend": trend
            }
        }
    except Exception as e:
        logger.error(f"ê´€ì‹¬ì‚¬ ì¡°íšŒ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/dashboard/notes")
async def get_dashboard_notes(
    user_id: int = Depends(get_current_user_id),
    limit: int = 50
):
    """ë…¸íŠ¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        db = SQLite()
        notes = db.get_notes(user_id, limit=limit)
        
        return {
            "success": True,
            "data": {"notes": notes}
        }
    except Exception as e:
        logger.error(f"ë…¸íŠ¸ ì¡°íšŒ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/dashboard/notes")
async def create_dashboard_note(
    request: Dict[str, Any],
    user_id: int = Depends(get_current_user_id)
):
    """ìƒˆ ë…¸íŠ¸ ìƒì„±"""
    try:
        db = SQLite()
        
        content = request.get("content", "")
        title = request.get("title", "")
        pinned = request.get("pinned", False)
        tags = request.get("tags")
        
        if not content.strip():
            raise HTTPException(status_code=400, detail="ë…¸íŠ¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        note_id = db.create_note(user_id, content, title, pinned, tags)
        
        if note_id:
            note = db.get_note_by_id(user_id, note_id)
            return {
                "success": True,
                "data": {"note": note}
            }
        else:
            raise HTTPException(status_code=500, detail="ë…¸íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë…¸íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.put("/dashboard/notes/{note_id}")
async def update_dashboard_note(
    note_id: int,
    request: Dict[str, Any],
    user_id: int = Depends(get_current_user_id)
):
    """ë…¸íŠ¸ ì—…ë°ì´íŠ¸"""
    try:
        db = SQLite()
        
        content = request.get("content")
        title = request.get("title")
        pinned = request.get("pinned")
        tags = request.get("tags")
        
        success = db.update_note(user_id, note_id, content, title, pinned, tags)
        
        if success:
            note = db.get_note_by_id(user_id, note_id)
            return {
                "success": True,
                "data": {"note": note}
            }
        else:
            raise HTTPException(status_code=500, detail="ë…¸íŠ¸ ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë…¸íŠ¸ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/dashboard/notes/{note_id}")
async def delete_dashboard_note(
    note_id: int,
    user_id: int = Depends(get_current_user_id)
):
    """ë…¸íŠ¸ ì‚­ì œ"""
    try:
        db = SQLite()
        success = db.delete_note(user_id, note_id)
        
        if success:
            return {"success": True, "message": "ë…¸íŠ¸ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}
        else:
            raise HTTPException(status_code=500, detail="ë…¸íŠ¸ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë…¸íŠ¸ ì‚­ì œ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/dashboard/activity")
async def get_dashboard_activity(
    user_id: int = Depends(get_current_user_id),
    days: int = 7
):
    """í™œë™ ìš”ì•½ ì¡°íšŒ"""
    try:
        db = SQLite()
        activity = db.get_activity_summary(user_id, days=days)
        
        return {
            "success": True,
            "data": {"activity": activity}
        }
    except Exception as e:
        logger.error(f"í™œë™ ìš”ì•½ ì¡°íšŒ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# Dashboard AI Analysis Endpoints
# =============================================================================

@router.post("/dashboard/analyses/create")
async def create_dashboard_analysis(
    request: Dict[str, Any],
    background_tasks: BackgroundTasks,
    user_id: int = Depends(get_current_user_id)
):
    """AI ë¶„ì„ ìƒì„± ìš”ì²­"""
    try:
        from agents.dashboard_agent.dashboard_agent import DashboardAgent
        from core.websocket_manager import get_websocket_manager
        
        analysis_type = request.get("analysis_type", "custom")
        query = request.get("query", "")
        title = request.get("title", "ë°ì´í„° ë¶„ì„")
        
        if not query:
            raise HTTPException(status_code=400, detail="ë¶„ì„ ì§ˆë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¶„ì„ ì‹¤í–‰
        async def run_analysis():
            ws_manager = get_websocket_manager()
            try:
                agent = DashboardAgent()
                result = await agent.create_analysis(user_id, analysis_type, query)
                logger.info(f"ë¶„ì„ ì™„ë£Œ: user_id={user_id}, success={result.get('success')}")
                
                # WebSocketìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡
                if result.get('success'):
                    await ws_manager.broadcast_analysis_completed(
                        user_id=user_id,
                        analysis_type=analysis_type,
                        title=title,
                        analysis_id=result.get('analysis_id')
                    )
                else:
                    await ws_manager.broadcast_analysis_failed(
                        user_id=user_id,
                        analysis_type=analysis_type,
                        title=title,
                        reason=result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                    )
            except Exception as e:
                logger.error(f"ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì˜¤ë¥˜: {e}", exc_info=True)
                await ws_manager.broadcast_analysis_failed(
                    user_id=user_id,
                    analysis_type=analysis_type,
                    title=title,
                    reason=str(e)
                )
        
        # ë™ê¸° ë˜í¼ë¡œ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì¶”ê°€
        def sync_run_analysis():
            import asyncio
            asyncio.run(run_analysis())
        
        background_tasks.add_task(sync_run_analysis)
        
        return {
            "success": True,
            "message": "ë¶„ì„ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ì™„ë£Œë˜ë©´ ì•Œë¦¼ì„ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.",
            "data": {
                "analysis_type": analysis_type,
                "query": query,
                "title": title,
                "status": "processing"
            }
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¶„ì„ ìƒì„± ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/dashboard/analyses/latest")
async def get_latest_analysis(user_id: int = Depends(get_current_user_id)):
    """ìµœì‹  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ëŒ€ì‹œë³´ë“œ UIìš©)"""
    try:
        db = SQLite()
        analysis = db.get_latest_analysis(user_id)
        
        return {
            "success": True,
            "data": {"analysis": analysis}
        }
    except Exception as e:
        logger.error(f"ìµœì‹  ë¶„ì„ ì¡°íšŒ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/dashboard/analyses")
async def get_all_analyses(
    user_id: int = Depends(get_current_user_id),
    limit: int = 50
):
    """ëª¨ë“  ë¶„ì„ ê²°ê³¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        db = SQLite()
        analyses = db.get_all_analyses(user_id, limit=limit)
        
        return {
            "success": True,
            "data": {"analyses": analyses, "count": len(analyses)}
        }
    except Exception as e:
        logger.error(f"ë¶„ì„ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/dashboard/analyses/{analysis_id}")
async def get_analysis_by_id(
    analysis_id: int,
    user_id: int = Depends(get_current_user_id)
):
    """íŠ¹ì • ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
    try:
        db = SQLite()
        analysis = db.get_analysis_by_id(user_id, analysis_id)
        
        if not analysis:
            raise HTTPException(status_code=404, detail="ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return {
            "success": True,
            "data": {"analysis": analysis}
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¶„ì„ ì¡°íšŒ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/dashboard/analyses/{analysis_id}")
async def delete_analysis(
    analysis_id: int,
    user_id: int = Depends(get_current_user_id)
):
    """ë¶„ì„ ê²°ê³¼ ì‚­ì œ"""
    try:
        db = SQLite()
        success = db.delete_analysis(user_id, analysis_id)
        
        if success:
            return {"success": True, "message": "ë¶„ì„ ê²°ê³¼ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}
        else:
            raise HTTPException(status_code=500, detail="ë¶„ì„ ê²°ê³¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¶„ì„ ì‚­ì œ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ API
# ============================================================================

@router.get("/reports/download")
async def download_report(
    file_path: str,
    user_id: int = Depends(get_current_user_id)
):
    """
    ì„œë²„ì—ì„œ ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        file_path: ì„œë²„ìƒì˜ ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ (WebSocket ì•Œë¦¼ì—ì„œ ë°›ì€ ê²½ë¡œ)
    
    Returns:
        FileResponse: ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ ì‘ë‹µ
    """
    import os
    from pathlib import Path as PathLib
    
    logger.info(f"ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ ìš”ì²­: user_id={user_id}, file_path={file_path}")
    
    # ë³´ì•ˆ: ê²½ë¡œ ê²€ì¦ - reports ë””ë ‰í„°ë¦¬ ë‚´ íŒŒì¼ë§Œ í—ˆìš©
    try:
        # ì„œë²„ì˜ reports ë””ë ‰í„°ë¦¬ ê²½ë¡œ
        reports_base = PathLib(settings.REPORTS_DIR).resolve()
        requested_path = PathLib(file_path).resolve()
        
        # ê²½ë¡œê°€ reports ë””ë ‰í„°ë¦¬ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        if not str(requested_path).startswith(str(reports_base)):
            logger.warning(f"ë³´ì•ˆ ê²½ê³ : í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ë¡œ ì ‘ê·¼ ì‹œë„: {file_path}")
            raise HTTPException(status_code=403, detail="í—ˆìš©ë˜ì§€ ì•Šì€ íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤.")
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not requested_path.exists():
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
            raise HTTPException(status_code=404, detail="ë³´ê³ ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ì´ë¦„ ì¶”ì¶œ
        file_name = requested_path.name
        
        # Content-Disposition í—¤ë”ë¥¼ ìœ„í•œ íŒŒì¼ëª… ì¸ì½”ë”©
        from urllib.parse import quote
        encoded_filename = quote(file_name)
        
        logger.info(f"ğŸ“¥ ë³´ê³ ì„œ íŒŒì¼ ì „ì†¡: {file_name}")
        
        return FileResponse(
            path=str(requested_path),
            filename=file_name,
            media_type="application/pdf" if file_name.endswith(".pdf") else "application/octet-stream",
            headers={
                "Content-Disposition": f"attachment; filename*=UTF-8''{encoded_filename}"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@router.get("/code/download")
async def download_code_file(
    file_path: str,
    user_id: int = Depends(get_current_user_id)
):
    """
    ì„œë²„ì—ì„œ ìƒì„±ëœ ì½”ë“œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        file_path: ì„œë²„ìƒì˜ ì½”ë“œ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        FileResponse: ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ ì‘ë‹µ
    """
    import os
    from pathlib import Path as PathLib
    
    logger.info(f"ğŸ“¥ ì½”ë“œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ìš”ì²­: user_id={user_id}, file_path={file_path}")
    
    # ë³´ì•ˆ: ê²½ë¡œ ê²€ì¦ - code ë””ë ‰í„°ë¦¬ ë‚´ íŒŒì¼ë§Œ í—ˆìš©
    try:
        # ì„œë²„ì˜ code ë””ë ‰í„°ë¦¬ ê²½ë¡œ
        home = os.path.expanduser("~")
        code_base = PathLib(home) / "Documents" / "JARVIS" / "code"
        code_base = code_base.resolve()
        requested_path = PathLib(file_path).resolve()
        
        # ê²½ë¡œê°€ code ë””ë ‰í„°ë¦¬ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        if not str(requested_path).startswith(str(code_base)):
            logger.warning(f"ë³´ì•ˆ ê²½ê³ : í—ˆìš©ë˜ì§€ ì•Šì€ ê²½ë¡œ ì ‘ê·¼ ì‹œë„: {file_path}")
            raise HTTPException(status_code=403, detail="í—ˆìš©ë˜ì§€ ì•Šì€ íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤.")
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not requested_path.exists():
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
            raise HTTPException(status_code=404, detail="ì½”ë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ì´ë¦„ ì¶”ì¶œ
        file_name = requested_path.name
        
        # Content-Disposition í—¤ë”ë¥¼ ìœ„í•œ íŒŒì¼ëª… ì¸ì½”ë”©
        from urllib.parse import quote
        encoded_filename = quote(file_name)
        
        logger.info(f"ğŸ“¥ ì½”ë“œ íŒŒì¼ ì „ì†¡: {file_name}")
        
        return FileResponse(
            path=str(requested_path),
            filename=file_name,
            media_type="text/x-python" if file_name.endswith(".py") else "application/octet-stream",
            headers={
                "Content-Disposition": f"attachment; filename*=UTF-8''{encoded_filename}"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì½”ë“œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")