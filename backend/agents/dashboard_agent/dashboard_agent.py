"""
DashboardAgent - AI ê¸°ë°˜ ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸

ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬:
1. ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ ë¶„ì„
2. í™œë™ íŒ¨í„´ ë¶„ì„
3. ê¸°ê°„ë³„ ë¹„êµ ë¶„ì„
4. ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
5. ì¶”ì²œ íˆìŠ¤í† ë¦¬ ë¶„ì„
6. ì‚¬ìš©ì ì •ì˜ ë¶„ì„

ì„ ìˆ˜í–‰í•˜ê³  ì‹œê°í™”(ì°¨íŠ¸)ì™€ í•¨ê»˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

ì±„íŒ…ì—ì„œ ì§ì ‘ í˜¸ì¶œ ì‹œ:
1. ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë¶„ì„ ìœ í˜• ì¶”ì¶œ
2. í™•ì¸ ë©”ì‹œì§€ ë°˜í™˜ ("~ë¥¼ ë¶„ì„í•´ë“œë¦´ê¹Œìš”?")
3. í”„ë¡ íŠ¸ì—”ë“œê°€ í™•ì¸ í›„ /dashboard/analyses/create API í˜¸ì¶œ
4. ë¶„ì„ ì™„ë£Œ í›„ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸ ê°€ëŠ¥

ì‚¬ìš© ëª¨ë¸: Gemini 2.5 Pro
ì €ì¥: SQLite dashboard_analyses í…Œì´ë¸”
"""

import json
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field

import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import google.generativeai as genai

from ..base_agent import BaseAgent, AgentResponse
from config.settings import settings
from database.sqlite import SQLite

logger = logging.getLogger(__name__)


@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    success: bool
    analysis_type: str = ""
    title: str = ""
    content: str = ""
    chart_data: Dict[str, Any] = field(default_factory=dict)
    insights: List[str] = field(default_factory=list)
    message: str = ""


class DashboardAgent(BaseAgent):
    """
    AI ê¸°ë°˜ ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸
    
    ì§€ì› ë¶„ì„ ìœ í˜•:
        - interest_trend: ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ ë¶„ì„
        - activity_pattern: í™œë™ íŒ¨í„´ ë¶„ì„
        - period_comparison: ê¸°ê°„ë³„ ë¹„êµ ë¶„ì„
        - category_analysis: ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
        - recommendation_stats: ì¶”ì²œ íˆìŠ¤í† ë¦¬ ë¶„ì„
        - custom: ì‚¬ìš©ì ì •ì˜ ë¶„ì„
    
    ì±„íŒ… ì—°ë™:
        - Supervisorì—ì„œ "ë¶„ì„", "íŠ¸ë Œë“œ", "í†µê³„" ë“±ì˜ í‚¤ì›Œë“œ ê°ì§€ ì‹œ í˜¸ì¶œ
        - ë¶„ì„ ìœ í˜• íŒŒì•… í›„ í™•ì¸ ë©”ì‹œì§€ ë°˜í™˜
        - í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í™•ì¸ í›„ /dashboard/analyses/create APIë¡œ ì‹¤ì œ ë¶„ì„
    """
    
    # ë¶„ì„ ìœ í˜• ì •ì˜
    ANALYSIS_TYPES = {
        "interest_trend": {
            "name": "ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ ë¶„ì„",
            "description": "ì‹œê°„ì— ë”°ë¥¸ ê´€ì‹¬ì‚¬ ë³€í™”ì™€ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.",
            "keywords": ["ê´€ì‹¬ì‚¬", "íŠ¸ë Œë“œ", "ë³€í™”", "ì¶”ì´", "í‚¤ì›Œë“œ"]
        },
        "activity_pattern": {
            "name": "í™œë™ íŒ¨í„´ ë¶„ì„",
            "description": "ì±„íŒ…, ì›¹ ë°©ë¬¸, íŒŒì¼ ì‘ì—… ë“±ì˜ í™œë™ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.",
            "keywords": ["í™œë™", "íŒ¨í„´", "ì‚¬ìš©ëŸ‰", "ì–¼ë§ˆë‚˜", "ìì£¼"]
        },
        "period_comparison": {
            "name": "ê¸°ê°„ë³„ ë¹„êµ ë¶„ì„",
            "description": "íŠ¹ì • ê¸°ê°„ ê°„ì˜ í™œë™ê³¼ ê´€ì‹¬ì‚¬ë¥¼ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.",
            "keywords": ["ë¹„êµ", "vs", "ëŒ€ë¹„", "ì €ë²ˆ", "ì´ë²ˆ", "ì „ì£¼", "ì „ì›”"]
        },
        "category_analysis": {
            "name": "ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„",
            "description": "íŠ¹ì • ì£¼ì œë‚˜ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
            "keywords": ["ì¹´í…Œê³ ë¦¬", "ë¶„ì•¼", "ì£¼ì œ", "ê´€ë ¨", "ì— ëŒ€í•œ"]
        },
        "recommendation_stats": {
            "name": "ì¶”ì²œ íˆìŠ¤í† ë¦¬ ë¶„ì„",
            "description": "ì¶”ì²œ ìˆ˜ë½ë¥ , ì„ í˜¸ ì£¼ì œ ë“±ì„ ë¶„ì„í•©ë‹ˆë‹¤.",
            "keywords": ["ì¶”ì²œ", "ìˆ˜ë½", "ê±°ì ˆ", "ì„ í˜¸", "ì œì•ˆ"]
        },
        "custom": {
            "name": "ì¢…í•© ë¶„ì„",
            "description": "ìš”ì²­ì— ë§ëŠ” ë§ì¶¤í˜• ì¢…í•© ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
            "keywords": []
        }
    }
    
    def __init__(self):
        super().__init__(
            agent_type="dashboard",
            description="ë°ì´í„° ë¶„ì„, ì‹œê°í™”, íŠ¸ë Œë“œ, í†µê³„ ê´€ë ¨ ì§ˆë¬¸ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. 'ë‚´ í™œë™ ë¶„ì„í•´ì¤˜', 'ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ ë³´ì—¬ì¤˜'ì™€ ê°™ì´ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        self.sqlite = SQLite()
        self._init_llm()
    
    def _init_llm(self):
        """Gemini LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.llm_available = False
        
        if not settings.GEMINI_API_KEY:
            logger.warning("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ DashboardAgent LLM ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        try:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            
            # Safety settings
            self.safety_settings = [
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "block_none"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "block_none"},
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "block_none"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "block_none"},
            ]
            
            # JSON ì¶œë ¥ìš© ëª¨ë¸ (ë¶„ì„ ìœ í˜• íŒŒì•… ë“±)
            self.llm_model_json = genai.GenerativeModel(
                model_name="gemini-2.5-pro",
                generation_config={
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "top_k": 40,
                    "max_output_tokens": 2048,
                    "response_mime_type": "application/json",
                },
                safety_settings=self.safety_settings,
            )
            
            # í…ìŠ¤íŠ¸ ì¶œë ¥ìš© ëª¨ë¸ (ë¶„ì„ ê²°ê³¼ ìƒì„±)
            self.llm_model_text = genai.GenerativeModel(
                model_name="gemini-2.5-pro",
                generation_config={
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "max_output_tokens": 4096,
                    "response_mime_type": "text/plain",
                },
                safety_settings=self.safety_settings,
            )
            
            self.llm_available = True
            logger.info("DashboardAgent: Gemini LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"DashboardAgent: Gemini LLM ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    
    # ============================================================
    # BaseAgent Interface Implementation
    # ============================================================
    
    def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        ë™ê¸° ì²˜ë¦¬ ë©”ì„œë“œ (langgraph í˜¸í™˜)
        
        ì±„íŒ…ì—ì„œ ë¶„ì„ ìš”ì²­ ì‹œ:
        1. ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë¶„ì„ ìœ í˜• ì¶”ì¶œ
        2. í™•ì¸ ë©”ì‹œì§€ ë°˜í™˜ (í”„ë¡ íŠ¸ì—”ë“œê°€ í™•ì¸ í›„ /dashboard/analyses/create í˜¸ì¶œ)
        """
        question = state.get("question", "")
        user_id = state.get("user_id")
        
        if not question:
            return {
                **state,
                "answer": "ë¶„ì„í•  ë‚´ìš©ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "success": False,
                "agent_type": self.agent_type
            }
        
        # ë¹„ë™ê¸° í•¨ìˆ˜ë¥¼ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(
                        asyncio.run,
                        self._process_analysis_request(user_id, question)
                    )
                    result = future.result(timeout=60)
            else:
                result = loop.run_until_complete(
                    self._process_analysis_request(user_id, question)
                )
        except Exception as e:
            logger.exception(f"DashboardAgent process ì˜¤ë¥˜: {e}")
            result = {
                "success": False,
                "answer": f"ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "metadata": {}
            }
        
        return {
            **state,
            "answer": result.get("answer", "ë¶„ì„ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
            "success": result.get("success", False),
            "agent_type": self.agent_type,
            "metadata": result.get("metadata", {})
        }
    
    async def _process_analysis_request(self, user_id: Optional[int], question: str) -> Dict[str, Any]:
        """
        ë¶„ì„ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        
        1. ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë¶„ì„ ìœ í˜• ì¶”ì¶œ
        2. ë¶„ì„ ê³„íš ìˆ˜ë¦½
        3. í™•ì¸ ë©”ì‹œì§€ ë°˜í™˜
        """
        if not self.llm_available:
            return {
                "success": False,
                "answer": "LLM ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ë¶„ì„ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "metadata": {}
            }
        
        # ë¶„ì„ ìœ í˜• ë° ê³„íš ì¶”ì¶œ
        analysis_plan = await self._extract_analysis_plan(question, user_id)
        
        if not analysis_plan or analysis_plan.get("analysis_type") == "unknown":
            return {
                "success": True,
                "answer": "ì–´ë–¤ ë¶„ì„ì„ ì›í•˜ì‹œë‚˜ìš”? ì˜ˆë¥¼ ë“¤ì–´:\n\n"
                         "â€¢ ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ ë¶„ì„\n"
                         "â€¢ í™œë™ íŒ¨í„´ ë¶„ì„\n"
                         "â€¢ ê¸°ê°„ë³„ ë¹„êµ ë¶„ì„\n"
                         "â€¢ ì¶”ì²œ íˆìŠ¤í† ë¦¬ ë¶„ì„\n\n"
                         "êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”!",
                "metadata": {
                    "action": "request_clarification",
                    "message": "ë¶„ì„ ìœ í˜•ì´ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                }
            }
        
        analysis_type = analysis_plan.get("analysis_type", "custom")
        analysis_title = analysis_plan.get("title", "ë°ì´í„° ë¶„ì„")
        analysis_description = analysis_plan.get("description", "")
        analysis_items = analysis_plan.get("analysis_items", [])
        
        # ë¶„ì„ ìœ í˜• ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        type_info = self.ANALYSIS_TYPES.get(analysis_type, self.ANALYSIS_TYPES["custom"])
        
        # í™•ì¸ ë©”ì‹œì§€ ìƒì„±
        confirm_message = f"**{analysis_title}**ì„(ë¥¼) ì›í•˜ì‹œëŠ”êµ°ìš”!\n\n"
        confirm_message += f"{analysis_description}\n\n"
        confirm_message += "ğŸ“Š **ë¶„ì„ í•­ëª©:**\n"
        for item in analysis_items[:5]:
            confirm_message += f"â€¢ {item}\n"
        confirm_message += "\në¶„ì„ì—ëŠ” ì•½ 30ì´ˆ~1ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤.\n"
        confirm_message += "ë¶„ì„ì„ ì§„í–‰í• ê¹Œìš”?"
        
        return {
            "success": True,
            "answer": confirm_message,
            "metadata": {
                "action": "confirm_analysis",
                "analysis_type": analysis_type,
                "title": analysis_title,
                "description": analysis_description,
                "analysis_items": analysis_items,
                "query": question,
                "requires_confirmation": True
            }
        }
    
    async def _extract_analysis_plan(self, user_input: str, user_id: Optional[int]) -> Optional[Dict[str, Any]]:
        """
        ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë¶„ì„ ìœ í˜•ê³¼ ê³„íšì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        # ë¶„ì„ ìœ í˜• ì„¤ëª… ìƒì„±
        types_description = "\n".join([
            f"- {key}: {info['name']} - {info['description']}"
            for key, info in self.ANALYSIS_TYPES.items()
        ])
        
        prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë°ì´í„° ë¶„ì„ ìš”ì²­ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì‚¬ìš©ì ìš”ì²­
"{user_input}"

## ì§€ì›í•˜ëŠ” ë¶„ì„ ìœ í˜•
{types_description}

## ì‘ì—…
1. ì‚¬ìš©ì ìš”ì²­ì—ì„œ ì ì ˆí•œ ë¶„ì„ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”.
2. ë¶„ì„ ì œëª©ê³¼ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”.
3. êµ¬ì²´ì ì¸ ë¶„ì„ í•­ëª© ëª©ë¡ì„ ìƒì„±í•˜ì„¸ìš”.
4. ë¶„ì„ ìœ í˜•ì„ íŒë‹¨í•  ìˆ˜ ì—†ìœ¼ë©´ "unknown"ì„ ë°˜í™˜í•˜ì„¸ìš”.

## ì¶œë ¥ í˜•ì‹ (JSON)
{{
    "analysis_type": "ë¶„ì„ ìœ í˜• (interest_trend, activity_pattern, period_comparison, category_analysis, recommendation_stats, custom, unknown ì¤‘ í•˜ë‚˜)",
    "title": "ë¶„ì„ ì œëª© (í•œêµ­ì–´, ì¹œê·¼í•œ í†¤)",
    "description": "ë¶„ì„ ë‚´ìš© ì„¤ëª… (1-2ë¬¸ì¥)",
    "analysis_items": ["ë¶„ì„ í•­ëª©1", "ë¶„ì„ í•­ëª©2", "ë¶„ì„ í•­ëª©3", "ë¶„ì„ í•­ëª©4", "ë¶„ì„ í•­ëª©5"],
    "confidence": 0.0~1.0,
    "reasoning": "ë¶„ì„ ìœ í˜• ì„ íƒ ê·¼ê±°"
}}
"""
        
        try:
            response = self.llm_model_json.generate_content(
                prompt,
                request_options={"timeout": 30}
            )
            
            response_text = self._extract_llm_response(response)
            if not response_text:
                return None
            
            result = json.loads(response_text)
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"DashboardAgent: ë¶„ì„ ê³„íš JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
        except Exception as e:
            logger.error(f"DashboardAgent: ë¶„ì„ ê³„íš ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    async def process_async(self, user_input: str, user_id: Optional[int] = None) -> AgentResponse:
        """ë¹„ë™ê¸° ì²˜ë¦¬ ë©”ì„œë“œ"""
        result = await self._process_analysis_request(user_id, user_input)
        
        return AgentResponse(
            success=result.get("success", False),
            content=result.get("answer", ""),
            agent_type=self.agent_type,
            metadata=result.get("metadata", {})
        )
    
    # ============================================================
    # Main Analysis Method
    # ============================================================
    
    async def create_analysis(
        self,
        user_id: int,
        analysis_type: str,
        query: str
    ) -> Dict[str, Any]:
        """
        ë¶„ì„ ì‹¤í–‰ ë©”ì¸ ë©”ì„œë“œ
        
        Args:
            user_id: ì‚¬ìš©ì ID
            analysis_type: ë¶„ì„ ìœ í˜•
            query: ì›ë³¸ ì§ˆë¬¸
        
        Returns:
            {
                "success": bool,
                "analysis_id": int,
                "title": str,
                "content": str,
                "chart_data": dict,
                "insights": list,
                "message": str
            }
        """
        logger.info(f"DashboardAgent: ë¶„ì„ ì‹œì‘ - type='{analysis_type}', user_id={user_id}")
        
        try:
            if not self.llm_available:
                return {
                    "success": False,
                    "message": "LLM ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # ==============================
            # Step 1: ë°ì´í„° ìˆ˜ì§‘
            # ==============================
            logger.info("DashboardAgent: Step 1 - ë°ì´í„° ìˆ˜ì§‘")
            raw_data = await self._collect_data(user_id, analysis_type)
            
            if not raw_data:
                return {
                    "success": False,
                    "message": "ë¶„ì„í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                }
            
            # ==============================
            # Step 2: ë°ì´í„° ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸ ìƒì„±
            # ==============================
            logger.info("DashboardAgent: Step 2 - ë°ì´í„° ë¶„ì„")
            analysis_result = await self._analyze_data(user_id, analysis_type, query, raw_data)
            
            if not analysis_result:
                return {
                    "success": False,
                    "message": "ë¶„ì„ ê²°ê³¼ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }
            
            # ==============================
            # Step 3: ì°¨íŠ¸ ìƒì„± (ì—¬ëŸ¬ ê°œ)
            # ==============================
            logger.info("DashboardAgent: Step 3 - ì°¨íŠ¸ ìƒì„±")
            charts = await self._generate_charts(analysis_type, raw_data, analysis_result)
            
            # ==============================
            # Step 4: DB ì €ì¥
            # ==============================
            logger.info("DashboardAgent: Step 4 - DB ì €ì¥")
            # chart_dataëŠ” ì´ì œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥ ({"charts": [...]})
            chart_data = {"charts": charts} if charts else None
            analysis_id = self.sqlite.create_analysis(
                user_id=user_id,
                analysis_type=analysis_type,
                title=analysis_result.get("title", "ë°ì´í„° ë¶„ì„"),
                content=analysis_result.get("content", ""),
                chart_data=chart_data,
                insights=analysis_result.get("insights", []),
                query=query
            )
            
            if not analysis_id:
                return {
                    "success": False,
                    "message": "ë¶„ì„ ê²°ê³¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }
            
            logger.info(f"DashboardAgent: ë¶„ì„ ì™„ë£Œ - analysis_id={analysis_id}")
            
            return {
                "success": True,
                "analysis_id": analysis_id,
                "title": analysis_result.get("title", ""),
                "content": analysis_result.get("content", ""),
                "chart_data": chart_data,  # {"charts": [...]} í˜•íƒœ
                "charts": charts,  # í¸ì˜ë¥¼ ìœ„í•œ ì§ì ‘ ë¦¬ìŠ¤íŠ¸
                "insights": analysis_result.get("insights", []),
                "message": ""
            }
            
        except Exception as e:
            logger.exception(f"DashboardAgent: ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "message": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
    
    # ============================================================
    # Data Collection
    # ============================================================
    
    async def _collect_data(self, user_id: int, analysis_type: str) -> Dict[str, Any]:
        """ë¶„ì„ì— í•„ìš”í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        data = {}
        
        try:
            # ê³µí†µ ë°ì´í„°
            data["interest_summary"] = self.sqlite.get_interest_summary(user_id)
            data["activity_summary"] = self.sqlite.get_activity_summary(user_id)
            data["interests"] = self.sqlite.get_user_interests(user_id, limit=50)
            
            # ë¶„ì„ ìœ í˜•ë³„ ì¶”ê°€ ë°ì´í„°
            if analysis_type == "interest_trend":
                data["interest_trend"] = self.sqlite.get_interest_trend(user_id, days=30)
                data["keyword_frequency"] = self.sqlite.get_keyword_frequency(user_id, limit=30)
                
            elif analysis_type == "activity_pattern":
                data["chat_messages"] = self.sqlite.get_recent_chat_messages(user_id, limit=100)
                data["browser_logs"] = self.sqlite.get_browser_logs(user_id, limit=100)
                data["activity_7d"] = self.sqlite.get_activity_summary(user_id, days=7)
                data["activity_30d"] = self.sqlite.get_activity_summary(user_id, days=30)
                
            elif analysis_type == "period_comparison":
                data["activity_7d"] = self.sqlite.get_activity_summary(user_id, days=7)
                data["activity_14d"] = self.sqlite.get_activity_summary(user_id, days=14)
                data["activity_30d"] = self.sqlite.get_activity_summary(user_id, days=30)
                data["interest_trend"] = self.sqlite.get_interest_trend(user_id, days=30)
                
            elif analysis_type == "recommendation_stats":
                data["recommendations"] = self.sqlite.get_all_recommendations(user_id, limit=100)
                
            elif analysis_type == "category_analysis":
                data["keyword_frequency"] = self.sqlite.get_keyword_frequency(user_id, limit=50)
                data["content_keywords"] = self.sqlite.get_content_keywords(user_id, limit=100)
            
            # custom ë˜ëŠ” ê¸°íƒ€: ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘
            else:
                data["interest_trend"] = self.sqlite.get_interest_trend(user_id, days=30)
                data["keyword_frequency"] = self.sqlite.get_keyword_frequency(user_id, limit=30)
                data["recommendations"] = self.sqlite.get_all_recommendations(user_id, limit=50)
                data["chat_messages"] = self.sqlite.get_recent_chat_messages(user_id, limit=50)
            
            return data
            
        except Exception as e:
            logger.error(f"DashboardAgent: ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {}
    
    # ============================================================
    # Data Analysis
    # ============================================================
    
    async def _analyze_data(
        self,
        user_id: int,
        analysis_type: str,
        query: str,
        raw_data: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        
        # ë°ì´í„° ìš”ì•½ ìƒì„±
        data_summary = self._create_data_summary(raw_data)
        
        type_info = self.ANALYSIS_TYPES.get(analysis_type, self.ANALYSIS_TYPES["custom"])
        
        prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë§íˆ¬ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

## ë¶„ì„ ìœ í˜•
{type_info['name']}: {type_info['description']}

## ì‚¬ìš©ì ì›ë³¸ ì§ˆë¬¸
"{query}"

## ìˆ˜ì§‘ëœ ë°ì´í„°
{data_summary}

## ì‘ì—…
1. ë°ì´í„°ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ì„¸ìš”.
2. ì£¼ìš” ë°œê²¬ì‚¬í•­ê³¼ íŒ¨í„´ì„ íŒŒì•…í•˜ì„¸ìš”.
3. ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ì„¸ìš”.
4. ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

## ë¶„ì„ ë³´ê³ ì„œ í˜•ì‹
ë‹¤ìŒ êµ¬ì¡°ë¡œ Markdown í˜•ì‹ì˜ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:

### ğŸ“Š ë¶„ì„ ìš”ì•½
(ì „ì²´ ë¶„ì„ ê²°ê³¼ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½)

### ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­
(ë°ì´í„°ì—ì„œ ë°œê²¬ëœ ì£¼ìš” íŒ¨í„´ì´ë‚˜ íŠ¹ì§•ì„ ë¶ˆë¦¿ í¬ì¸íŠ¸ë¡œ ì •ë¦¬)

### ğŸ’¡ ì¸ì‚¬ì´íŠ¸
(ë¶„ì„ì„ í†µí•´ ë„ì¶œëœ ì¸ì‚¬ì´íŠ¸ì™€ ì˜ë¯¸ í•´ì„)

### ğŸ¯ ì¶”ì²œ ì•¡ì…˜
(ì‚¬ìš©ìì—ê²Œ ì œì•ˆí•˜ëŠ” ë‹¤ìŒ í–‰ë™ì´ë‚˜ ê°œì„ ì )

## ì¶œë ¥
Markdown í˜•ì‹ì˜ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
"""

        try:
            response = self.llm_model_text.generate_content(
                prompt,
                request_options={"timeout": 120}
            )
            
            content = self._extract_llm_response(response)
            
            if not content:
                return None
            
            # ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
            insights = await self._extract_insights(content, query)
            
            # ì œëª© ìƒì„±
            title = await self._generate_title(analysis_type, query)
            
            return {
                "title": title,
                "content": content,
                "insights": insights
            }
            
        except Exception as e:
            logger.error(f"DashboardAgent: ë°ì´í„° ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None
    
    def _create_data_summary(self, raw_data: Dict[str, Any]) -> str:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ LLMì— ì „ë‹¬í•  í˜•íƒœë¡œ ìš”ì•½í•©ë‹ˆë‹¤."""
        summary_parts = []
        
        # ê´€ì‹¬ì‚¬ ìš”ì•½
        if "interest_summary" in raw_data:
            interest = raw_data["interest_summary"]
            summary_parts.append(f"""
### ê´€ì‹¬ì‚¬ ìš”ì•½
- ì´ ê´€ì‹¬ì‚¬ ìˆ˜: {interest.get('total_count', 0)}ê°œ
- ìƒìœ„ ê´€ì‹¬ì‚¬: {', '.join([i['keyword'] for i in interest.get('top_interests', [])[:5]])}
- ìµœê·¼ ì¶”ê°€ëœ ê´€ì‹¬ì‚¬: {', '.join([i['keyword'] for i in interest.get('recent_interests', [])[:3]])}
""")
        
        # í™œë™ ìš”ì•½
        if "activity_summary" in raw_data:
            activity = raw_data["activity_summary"]
            summary_parts.append(f"""
### í™œë™ ìš”ì•½ (ìµœê·¼ {activity.get('period_days', 7)}ì¼)
- ì±„íŒ… ë©”ì‹œì§€: {activity.get('chat_messages', 0)}ê±´
- ì›¹ ë°©ë¬¸: {activity.get('browser_visits', 0)}ê±´
- íŒŒì¼ ì²˜ë¦¬: {activity.get('files_processed', 0)}ê±´
- ì¶”ì²œ: ì´ {activity.get('recommendations', {}).get('total', 0)}ê±´ (ìˆ˜ë½ {activity.get('recommendations', {}).get('accepted', 0)} / ê±°ì ˆ {activity.get('recommendations', {}).get('rejected', 0)})
""")
        
        # ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ
        if "interest_trend" in raw_data and raw_data["interest_trend"]:
            trend_data = raw_data["interest_trend"][:20]  # ìµœê·¼ 20ê°œë§Œ
            if trend_data:
                summary_parts.append(f"""
### ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ (ìµœê·¼ ë°ì´í„°)
{json.dumps(trend_data, ensure_ascii=False, indent=2)[:1500]}
""")
        
        # í‚¤ì›Œë“œ ë¹ˆë„
        if "keyword_frequency" in raw_data and raw_data["keyword_frequency"]:
            freq_data = raw_data["keyword_frequency"][:15]
            summary_parts.append(f"""
### í‚¤ì›Œë“œ ë¹ˆë„ (ìƒìœ„ 15ê°œ)
{json.dumps(freq_data, ensure_ascii=False, indent=2)}
""")
        
        # ì¶”ì²œ í†µê³„
        if "recommendations" in raw_data and raw_data["recommendations"]:
            recs = raw_data["recommendations"]
            accepted = sum(1 for r in recs if r.get('status') == 'accepted')
            rejected = sum(1 for r in recs if r.get('status') == 'rejected')
            pending = sum(1 for r in recs if r.get('status') == 'pending')
            keywords = [r.get('keyword', '') for r in recs[:10] if r.get('keyword')]
            summary_parts.append(f"""
### ì¶”ì²œ íˆìŠ¤í† ë¦¬
- ì´ ì¶”ì²œ ìˆ˜: {len(recs)}
- ìˆ˜ë½: {accepted}, ê±°ì ˆ: {rejected}, ëŒ€ê¸°ì¤‘: {pending}
- ìµœê·¼ ì¶”ì²œ í‚¤ì›Œë“œ: {', '.join(keywords)}
""")
        
        # ê¸°ê°„ë³„ ë¹„êµ
        if "activity_7d" in raw_data and "activity_30d" in raw_data:
            a7 = raw_data["activity_7d"]
            a30 = raw_data["activity_30d"]
            summary_parts.append(f"""
### ê¸°ê°„ë³„ í™œë™ ë¹„êµ
- 7ì¼ê°„ ì±„íŒ…: {a7.get('chat_messages', 0)}ê±´ / 30ì¼ê°„: {a30.get('chat_messages', 0)}ê±´
- 7ì¼ê°„ ì›¹ ë°©ë¬¸: {a7.get('browser_visits', 0)}ê±´ / 30ì¼ê°„: {a30.get('browser_visits', 0)}ê±´
""")
        
        return "\n".join(summary_parts) if summary_parts else "ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    async def _extract_insights(self, content: str, query: str) -> List[str]:
        """ë¶„ì„ ë‚´ìš©ì—ì„œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        prompt = f"""ë‹¤ìŒ ë¶„ì„ ë‚´ìš©ì—ì„œ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3ê°œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
ê° ì¸ì‚¬ì´íŠ¸ëŠ” í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

ë¶„ì„ ë‚´ìš©:
{content[:1500]}

ë°˜ë“œì‹œ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´):
["ì²« ë²ˆì§¸ ì¸ì‚¬ì´íŠ¸", "ë‘ ë²ˆì§¸ ì¸ì‚¬ì´íŠ¸", "ì„¸ ë²ˆì§¸ ì¸ì‚¬ì´íŠ¸"]
"""
        
        try:
            response = self.llm_model_json.generate_content(
                prompt,
                request_options={"timeout": 30}
            )
            
            response_text = self._extract_llm_response(response)
            if response_text:
                # JSON ë°°ì—´ ì¶”ì¶œ ì‹œë„
                import re
                # JSON ë°°ì—´ íŒ¨í„´ ì°¾ê¸°
                array_match = re.search(r'\[.*?\]', response_text, re.DOTALL)
                if array_match:
                    json_str = array_match.group()
                    # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ íŒŒì‹±
                    json_str = json_str.replace('\n', ' ').replace('\r', '')
                    return json.loads(json_str)
                # ì „ì²´ í…ìŠ¤íŠ¸ê°€ JSON ë°°ì—´ì¸ ê²½ìš°
                return json.loads(response_text)
            return self._fallback_extract_insights(content)
        except json.JSONDecodeError as e:
            logger.warning(f"DashboardAgent: ì¸ì‚¬ì´íŠ¸ JSON íŒŒì‹± ì‹¤íŒ¨, í´ë°± ì‚¬ìš©: {e}")
            return self._fallback_extract_insights(content)
        except Exception as e:
            logger.error(f"DashboardAgent: ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return self._fallback_extract_insights(content)
    
    def _fallback_extract_insights(self, content: str) -> List[str]:
        """ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ í´ë°±: ë¶„ì„ ë‚´ìš©ì—ì„œ ì£¼ìš” í¬ì¸íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        # "ì¸ì‚¬ì´íŠ¸" ì„¹ì…˜ ì°¾ê¸°
        if "ğŸ’¡ ì¸ì‚¬ì´íŠ¸" in content or "### ğŸ’¡" in content:
            lines = content.split('\n')
            in_insight_section = False
            for line in lines:
                if "ğŸ’¡" in line and ("ì¸ì‚¬ì´íŠ¸" in line or "Insight" in line):
                    in_insight_section = True
                    continue
                if in_insight_section:
                    if line.startswith('#') or line.startswith('ğŸ¯'):
                        break
                    line = line.strip()
                    if line.startswith('-') or line.startswith('â€¢'):
                        insight = line.lstrip('-â€¢').strip()
                        insight = insight.replace('**', '').strip()
                        if insight and len(insight) > 10:
                            insights.append(insight)
                            if len(insights) >= 3:
                                break
        
        # ì°¾ì§€ ëª»í•œ ê²½ìš° ìš”ì•½ ì„¹ì…˜ì—ì„œ ì¶”ì¶œ
        if not insights:
            if "ğŸ“Š ë¶„ì„ ìš”ì•½" in content or "### ğŸ“Š" in content:
                lines = content.split('\n')
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('#') and len(line) > 20:
                        line = line.replace('**', '').strip()
                        if not line.startswith('-') and not line.startswith('â€¢'):
                            insights.append(line[:100])
                            break
        
        return insights if insights else ["ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."]
    
    async def _generate_title(self, analysis_type: str, query: str) -> str:
        """ë¶„ì„ ì œëª©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        type_info = self.ANALYSIS_TYPES.get(analysis_type, self.ANALYSIS_TYPES["custom"])
        
        prompt = f"""ë‹¤ìŒ ë¶„ì„ ìš”ì²­ì— ëŒ€í•œ ì§§ê³  ëª…í™•í•œ ì œëª©ì„ ìƒì„±í•˜ì„¸ìš”.

ë¶„ì„ ìœ í˜•: {type_info['name']}
ì‚¬ìš©ì ìš”ì²­: {query}

ì œëª© ê·œì¹™:
- 15ì ì´ë‚´
- í•œêµ­ì–´ë¡œ ì‘ì„±
- ì´ëª¨ì§€ í¬í•¨ ê°€ëŠ¥

JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
{{"title": "ìƒì„±ëœ ì œëª©"}}
"""
        
        try:
            response = self.llm_model_json.generate_content(
                prompt,
                request_options={"timeout": 15}
            )
            
            response_text = self._extract_llm_response(response)
            if response_text:
                result = json.loads(response_text)
                return result.get("title", type_info['name'])
            return type_info['name']
        except Exception:
            return type_info['name']
    
    # ============================================================
    # Chart Generation (Multiple Charts)
    # ============================================================
    
    async def _generate_charts(
        self,
        analysis_type: str,
        raw_data: Dict[str, Any],
        analysis_result: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Plotlyë¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        ë¶„ì„ ìœ í˜•ê³¼ ê°€ìš© ë°ì´í„°ì— ë”°ë¼ ì ì ˆí•œ ì°¨íŠ¸ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        charts = []
        
        try:
            if analysis_type == "interest_trend":
                # ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ: ê´€ì‹¬ì‚¬ TOP 10 + í‚¤ì›Œë“œ ë¹ˆë„ ì°¨íŠ¸
                chart = self._create_interest_trend_chart(raw_data)
                if chart and chart.get("type") != "empty":
                    charts.append(chart)
                
                # í‚¤ì›Œë“œ ë¹ˆë„ ì°¨íŠ¸ ì¶”ê°€
                if raw_data.get("keyword_frequency"):
                    keyword_chart = self._create_category_chart(raw_data)
                    if keyword_chart and keyword_chart.get("type") != "empty":
                        charts.append(keyword_chart)
                        
            elif analysis_type == "activity_pattern":
                # í™œë™ íŒ¨í„´: í™œë™ í˜„í™© + ê¸°ê°„ ë¹„êµ (ê°€ëŠ¥í•œ ê²½ìš°)
                chart = self._create_activity_chart(raw_data)
                if chart and chart.get("type") != "empty":
                    charts.append(chart)
                
                # 7ì¼ vs 30ì¼ ë¹„êµ ê°€ëŠ¥í•˜ë©´ ì¶”ê°€
                if raw_data.get("activity_7d") and raw_data.get("activity_30d"):
                    comparison_chart = self._create_comparison_chart(raw_data)
                    if comparison_chart and comparison_chart.get("type") != "empty":
                        charts.append(comparison_chart)
                        
            elif analysis_type == "period_comparison":
                # ê¸°ê°„ë³„ ë¹„êµ: ë¹„êµ ì°¨íŠ¸ + í™œë™ ì°¨íŠ¸
                chart = self._create_comparison_chart(raw_data)
                if chart and chart.get("type") != "empty":
                    charts.append(chart)
                
                # ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ ì¶”ê°€
                if raw_data.get("interests"):
                    trend_chart = self._create_interest_trend_chart(raw_data)
                    if trend_chart and trend_chart.get("type") != "empty":
                        charts.append(trend_chart)
                        
            elif analysis_type == "recommendation_stats":
                # ì¶”ì²œ í†µê³„: íŒŒì´ ì°¨íŠ¸ + ê´€ì‹¬ì‚¬ ì°¨íŠ¸
                chart = self._create_recommendation_chart(raw_data)
                if chart and chart.get("type") != "empty":
                    charts.append(chart)
                
                # ê´€ì‹¬ì‚¬ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if raw_data.get("interests"):
                    interest_chart = self._create_interest_trend_chart(raw_data)
                    if interest_chart and interest_chart.get("type") != "empty":
                        charts.append(interest_chart)
                        
            elif analysis_type == "category_analysis":
                # ì¹´í…Œê³ ë¦¬ ë¶„ì„: í‚¤ì›Œë“œ ë¹ˆë„ + ê´€ì‹¬ì‚¬
                chart = self._create_category_chart(raw_data)
                if chart and chart.get("type") != "empty":
                    charts.append(chart)
                
                if raw_data.get("interests"):
                    interest_chart = self._create_interest_trend_chart(raw_data)
                    if interest_chart and interest_chart.get("type") != "empty":
                        charts.append(interest_chart)
                        
            else:
                # custom: ëª¨ë“  ê°€ìš© ë°ì´í„°ì— ëŒ€í•´ ì°¨íŠ¸ ìƒì„±
                charts = self._create_all_available_charts(raw_data)
            
            return charts
            
        except Exception as e:
            logger.error(f"DashboardAgent: ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return []
    
    def _create_all_available_charts(self, raw_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ê°€ìš©í•œ ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        charts = []
        
        # ê´€ì‹¬ì‚¬ ë°ì´í„°
        if raw_data.get("interests"):
            chart = self._create_interest_trend_chart(raw_data)
            if chart and chart.get("type") != "empty":
                charts.append(chart)
        
        # í™œë™ ë°ì´í„°
        if raw_data.get("activity_summary"):
            chart = self._create_activity_chart(raw_data)
            if chart and chart.get("type") != "empty":
                charts.append(chart)
        
        # ê¸°ê°„ë³„ ë¹„êµ
        if raw_data.get("activity_7d") and raw_data.get("activity_30d"):
            chart = self._create_comparison_chart(raw_data)
            if chart and chart.get("type") != "empty":
                charts.append(chart)
        
        # ì¶”ì²œ ë°ì´í„°
        if raw_data.get("recommendations"):
            chart = self._create_recommendation_chart(raw_data)
            if chart and chart.get("type") != "empty":
                charts.append(chart)
        
        # í‚¤ì›Œë“œ ë¹ˆë„
        if raw_data.get("keyword_frequency"):
            chart = self._create_category_chart(raw_data)
            if chart and chart.get("type") != "empty":
                charts.append(chart)
        
        return charts
    
    def _create_interest_trend_chart(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """ê´€ì‹¬ì‚¬ íŠ¸ë Œë“œ ì°¨íŠ¸ ìƒì„±"""
        interests = raw_data.get("interests", [])[:10]
        
        if not interests:
            return {"type": "empty", "message": "ê´€ì‹¬ì‚¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        keywords = [i.get("keyword", "")[:15] for i in interests]
        scores = [i.get("score", 0) for i in interests]
        
        fig = go.Figure(data=[
            go.Bar(
                x=scores,
                y=keywords,
                orientation='h',
                marker=dict(
                    color=scores,
                    colorscale='Blues',
                    showscale=False
                ),
                text=[f'{s:.2f}' for s in scores],
                textposition='outside'
            )
        ])
        
        fig.update_layout(
            title="ê´€ì‹¬ì‚¬ TOP 10",
            xaxis_title="ê´€ì‹¬ë„ ì ìˆ˜",
            yaxis_title="",
            height=400,
            margin=dict(l=120, r=40, t=60, b=40),
            yaxis=dict(autorange="reversed"),
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        
        return {
            "type": "bar",
            "plotly_json": fig.to_json(),
            "title": "ê´€ì‹¬ì‚¬ TOP 10"
        }
    
    def _create_activity_chart(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """í™œë™ íŒ¨í„´ ì°¨íŠ¸ ìƒì„±"""
        activity = raw_data.get("activity_summary", {})
        
        categories = ['ì±„íŒ…', 'ì›¹ ë°©ë¬¸', 'íŒŒì¼ ì²˜ë¦¬']
        values = [
            activity.get('chat_messages', 0),
            activity.get('browser_visits', 0),
            activity.get('files_processed', 0)
        ]
        
        fig = go.Figure(data=[
            go.Bar(
                x=categories,
                y=values,
                marker_color=['#3B82F6', '#10B981', '#F59E0B'],
                text=values,
                textposition='outside'
            )
        ])
        
        fig.update_layout(
            title=f"ìµœê·¼ {activity.get('period_days', 7)}ì¼ í™œë™",
            xaxis_title="í™œë™ ìœ í˜•",
            yaxis_title="ê±´ìˆ˜",
            height=350,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        
        return {
            "type": "bar",
            "plotly_json": fig.to_json(),
            "title": "í™œë™ í˜„í™©"
        }
    
    def _create_comparison_chart(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ê°„ë³„ ë¹„êµ ì°¨íŠ¸ ìƒì„±"""
        a7 = raw_data.get("activity_7d", {})
        a30 = raw_data.get("activity_30d", {})
        
        categories = ['ì±„íŒ…', 'ì›¹ ë°©ë¬¸', 'íŒŒì¼ ì²˜ë¦¬']
        values_7d = [
            a7.get('chat_messages', 0),
            a7.get('browser_visits', 0),
            a7.get('files_processed', 0)
        ]
        values_30d = [
            a30.get('chat_messages', 0),
            a30.get('browser_visits', 0),
            a30.get('files_processed', 0)
        ]
        
        fig = go.Figure(data=[
            go.Bar(name='ìµœê·¼ 7ì¼', x=categories, y=values_7d, marker_color='#3B82F6'),
            go.Bar(name='ìµœê·¼ 30ì¼', x=categories, y=values_30d, marker_color='#93C5FD')
        ])
        
        fig.update_layout(
            title="ê¸°ê°„ë³„ í™œë™ ë¹„êµ",
            xaxis_title="í™œë™ ìœ í˜•",
            yaxis_title="ê±´ìˆ˜",
            barmode='group',
            height=350,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        
        return {
            "type": "grouped_bar",
            "plotly_json": fig.to_json(),
            "title": "ê¸°ê°„ë³„ ë¹„êµ"
        }
    
    def _create_recommendation_chart(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì¶”ì²œ í†µê³„ ì°¨íŠ¸ ìƒì„±"""
        recs = raw_data.get("recommendations", [])
        
        if not recs:
            return {"type": "empty", "message": "ì¶”ì²œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        accepted = sum(1 for r in recs if r.get('status') == 'accepted')
        rejected = sum(1 for r in recs if r.get('status') == 'rejected')
        pending = sum(1 for r in recs if r.get('status') == 'pending')
        shown = sum(1 for r in recs if r.get('status') == 'shown')
        
        labels = ['ìˆ˜ë½', 'ê±°ì ˆ', 'ëŒ€ê¸°ì¤‘', 'í‘œì‹œë¨']
        values = [accepted, rejected, pending, shown]
        colors = ['#10B981', '#EF4444', '#F59E0B', '#6B7280']
        
        fig = go.Figure(data=[
            go.Pie(
                labels=labels,
                values=values,
                hole=0.4,
                marker_colors=colors,
                textinfo='label+percent',
                textposition='outside'
            )
        ])
        
        fig.update_layout(
            title="ì¶”ì²œ ì‘ë‹µ í˜„í™©",
            height=350,
            showlegend=True,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        
        return {
            "type": "pie",
            "plotly_json": fig.to_json(),
            "title": "ì¶”ì²œ í†µê³„"
        }
    
    def _create_category_chart(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì¹´í…Œê³ ë¦¬ë³„ ì°¨íŠ¸ ìƒì„±"""
        keyword_freq = raw_data.get("keyword_frequency", [])[:10]
        
        if not keyword_freq:
            return {"type": "empty", "message": "í‚¤ì›Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
        
        keywords = [k.get("keyword", "")[:12] for k in keyword_freq]
        counts = [k.get("count", 0) for k in keyword_freq]
        
        fig = go.Figure(data=[
            go.Bar(
                x=keywords,
                y=counts,
                marker_color='#8B5CF6',
                text=counts,
                textposition='outside'
            )
        ])
        
        fig.update_layout(
            title="í‚¤ì›Œë“œ ë¹ˆë„ TOP 10",
            xaxis_title="í‚¤ì›Œë“œ",
            yaxis_title="ë¹ˆë„",
            height=350,
            xaxis_tickangle=-45,
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)'
        )
        
        return {
            "type": "bar",
            "plotly_json": fig.to_json(),
            "title": "í‚¤ì›Œë“œ ë¹ˆë„"
        }
    
    def _create_combined_chart(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì¢…í•© ì°¨íŠ¸ ìƒì„± (ê°€ì¥ ì í•©í•œ ì°¨íŠ¸ ìë™ ì„ íƒ) - í•˜ìœ„ í˜¸í™˜ì„±ìš©"""
        # ê´€ì‹¬ì‚¬ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê´€ì‹¬ì‚¬ ì°¨íŠ¸
        if raw_data.get("interests"):
            return self._create_interest_trend_chart(raw_data)
        # í™œë™ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í™œë™ ì°¨íŠ¸
        elif raw_data.get("activity_summary"):
            return self._create_activity_chart(raw_data)
        # ì¶”ì²œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì¶”ì²œ ì°¨íŠ¸
        elif raw_data.get("recommendations"):
            return self._create_recommendation_chart(raw_data)
        else:
            return {"type": "empty", "message": "ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
    
    # ============================================================
    # Utility Methods
    # ============================================================
    
    def _extract_llm_response(self, response) -> Optional[str]:
        """Gemini ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            try:
                text = getattr(response, "text", None)
                if text and text.strip():
                    return text.strip()
            except Exception:
                pass
            
            candidates = getattr(response, "candidates", None) or []
            if not candidates:
                return None
            
            candidate = candidates[0]
            content_parts = getattr(getattr(candidate, "content", None), "parts", None) or []
            
            extracted_chunks = []
            for part in content_parts:
                text_chunk = getattr(part, "text", None)
                if text_chunk:
                    extracted_chunks.append(text_chunk)
            
            if extracted_chunks:
                return "\n".join(extracted_chunks).strip()
            
            return None
            
        except Exception as e:
            logger.error(f"DashboardAgent: LLM ì‘ë‹µ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
