import numpy as np
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from collections import Counter
import logging

from ..base_agent import BaseAgent, AgentResponse
from database.sqlite_meta import SQLiteMeta  # ë³€ê²½ë¨: SQLAlchemy ëŒ€ì‹  SQLiteMeta ì‚¬ìš©

logger = logging.getLogger(__name__)

class RecommendationAgent(BaseAgent):
    """ì¶”ì²œ ë° ì œì•ˆ ê´€ë ¨ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        super().__init__(
            agent_type="recommendation",
            description="ì¶”ì²œ, ì œì•ˆ, ì¶”ì²œí•´ì¤˜ ë“±ì˜ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."
        )
        self.sqlite_meta = SQLiteMeta()  # SQLite ë©”íƒ€ë°ì´í„° ì ‘ê·¼
    
    def process(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒíƒœë¥¼ ë°›ì•„ì„œ ì²˜ë¦¬í•˜ê³  ìˆ˜ì •ëœ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        question = state.get("question", "")
        user_id = state.get("user_id")
        
        if not question:
            return {**state, "answer": "ì§ˆë¬¸ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "evidence": []}
        
        try:
            # ì‚¬ìš©ì ì„¤ë¬¸ì§€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            survey_data = self._get_user_survey_data(user_id)
            
            # ì„¤ë¬¸ì§€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸í™”ëœ ì¶”ì²œ ìƒì„±
            response_content = self._generate_personalized_recommendation(question, survey_data)
            
            return {
                **state,
                "answer": response_content,
                "evidence": [],
                "agent_type": "recommendation",
                "metadata": {
                    "query": question,
                    "user_id": user_id,
                    "agent_type": "recommendation",
                    "survey_data_used": survey_data is not None
                }
            }
        except Exception as e:
            return {
                **state,
                "answer": f"ì¶”ì²œ ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "evidence": [],
                "agent_type": "recommendation"
            }
    
    def _get_user_survey_data(self, user_id: Optional[int]) -> Optional[Dict[str, Any]]:
        """ì‚¬ìš©ìì˜ ì„¤ë¬¸ì§€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        if not user_id:
            return None
        
        try:
            return self.sqlite_meta.get_user_survey_response(user_id)
        except Exception as e:
            print(f"ì„¤ë¬¸ì§€ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def _generate_personalized_recommendation(self, question: str, survey_data: Optional[Dict[str, Any]]) -> str:
        """ì„¤ë¬¸ì§€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸í™”ëœ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not survey_data:
            return f"ì¶”ì²œ ì—ì´ì „íŠ¸ê°€ '{question}' ìš”ì²­ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. ê°œì¸í™”ëœ ì¶”ì²œì„ ìœ„í•´ ì´ˆê¸° ì„¤ë¬¸ì§€ë¥¼ ì™„ë£Œí•´ì£¼ì„¸ìš”."
        
        # ì„¤ë¬¸ì§€ ë°ì´í„°ì—ì„œ ì •ë³´ ì¶”ì¶œ
        job_field = survey_data.get('job_field', '')
        job_field_other = survey_data.get('job_field_other', '')
        interests = survey_data.get('interests', [])
        help_preferences = survey_data.get('help_preferences', [])
        custom_keywords = survey_data.get('custom_keywords', '')
        
        # ì§ì—… ë¶„ì•¼ì— ë”°ë¥¸ ë§ì¶¤í˜• ì¶”ì²œ
        job_recommendations = self._get_job_based_recommendations(job_field, job_field_other)
        
        # ê´€ì‹¬ì‚¬ì— ë”°ë¥¸ ì¶”ì²œ
        interest_recommendations = self._get_interest_based_recommendations(interests)
        
        # ë„ì›€ ë°›ê³  ì‹¶ì€ ì˜ì—­ì— ë”°ë¥¸ ì¶”ì²œ
        help_recommendations = self._get_help_based_recommendations(help_preferences)
        
        # ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œ í™œìš©
        keyword_recommendations = self._get_keyword_based_recommendations(custom_keywords)
        
        # ëª¨ë“  ì¶”ì²œì„ ì¢…í•©í•˜ì—¬ ì‘ë‹µ ìƒì„±
        response_parts = []
        
        if job_recommendations:
            response_parts.append(f"ğŸ“‹ {job_field} ë¶„ì•¼ ê´€ë ¨: {job_recommendations}")
        
        if interest_recommendations:
            response_parts.append(f"ğŸ¯ ê´€ì‹¬ì‚¬ ê¸°ë°˜: {interest_recommendations}")
        
        if help_recommendations:
            response_parts.append(f"ğŸ’¡ ë„ì›€ ì˜ì—­: {help_recommendations}")
        
        if keyword_recommendations:
            response_parts.append(f"ğŸ” ë§ì¶¤ í‚¤ì›Œë“œ: {keyword_recommendations}")
        
        if not response_parts:
            return f"'{question}'ì— ëŒ€í•œ ê°œì¸í™”ëœ ì¶”ì²œì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤. ì„¤ë¬¸ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì œì•ˆì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        return f"'{question}'ì— ëŒ€í•œ ê°œì¸í™”ëœ ì¶”ì²œì…ë‹ˆë‹¤:\n\n" + "\n\n".join(response_parts)
    
    def _get_job_based_recommendations(self, job_field: str, job_field_other: str) -> str:
        """ì§ì—… ë¶„ì•¼ì— ë”°ë¥¸ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤."""
        job_recommendations = {
            "student": "í•™ìŠµ ìë£Œ, ì—°êµ¬ ë…¼ë¬¸, í•™ìˆ  ìë£Œë¥¼ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "developer": "ìµœì‹  ê¸°ìˆ  íŠ¸ë Œë“œ, ê°œë°œ ë„êµ¬, í”„ë¡œê·¸ë˜ë° ìë£Œë¥¼ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "designer": "ë””ìì¸ íŠ¸ë Œë“œ, ì°½ì‘ ì˜ê°, ë””ìì¸ ë„êµ¬ë¥¼ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "planner": "ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ, ë§ˆì¼€íŒ… ìë£Œ, ê¸°íš ë„êµ¬ë¥¼ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "researcher": "ì—°êµ¬ ìë£Œ, í•™ìˆ  ë…¼ë¬¸, ì‹¤í—˜ ë°ì´í„°ë¥¼ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "other": f"'{job_field_other}' ë¶„ì•¼ì— íŠ¹í™”ëœ ìë£Œë¥¼ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        }
        
        return job_recommendations.get(job_field, "ì „ë¬¸ ë¶„ì•¼ì— ë§ëŠ” ìë£Œë¥¼ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    async def run_periodic_analysis(self, user_id: int, recommendation_type: str = 'scheduled') -> (bool, str):
        """
        ì§€ë‚œ 1ì£¼ì¼ê°„ì˜ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤.
        :return: (ì„±ê³µ ì—¬ë¶€, ë©”ì‹œì§€) íŠœí”Œ
        """
        logger.info(f"ì‚¬ìš©ì {user_id}ì— ëŒ€í•œ ì£¼ê¸°ì  ë¶„ì„ ì‹œì‘ (íƒ€ì…: {recommendation_type})...")
        
        try:
            # 1. ì§€ë‚œ 1ì£¼ì¼ ë°ì´í„° ì¡°íšŒ
            one_week_ago = int((datetime.now() - timedelta(days=7)).timestamp())
            files = self.sqlite_meta.get_collected_files_since(user_id, one_week_ago)
            history = self.sqlite_meta.get_collected_browser_history_since(user_id, one_week_ago)
            data_source = "ìµœê·¼ í™œë™"

            # 1ì°¨ í´ë°±: ì „ì²´ ê¸°ê°„ ë°ì´í„° ì¡°íšŒ
            if not files and not history:
                logger.info(f"User {user_id}: ì§€ë‚œ 1ì£¼ì¼ê°„ ë°ì´í„°ê°€ ì—†ì–´ ì „ì²´ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
                files = self.sqlite_meta.get_collected_files(user_id)
                history = self.sqlite_meta.get_collected_browser_history(user_id)
                data_source = "ì „ì²´ í™œë™"

            # 2. ë°ì´í„°ì—ì„œ í‚¤ì›Œë“œ/ì£¼ì œ ì¶”ì¶œ
            keywords = []
            
            # íŒŒì¼ ì´ë¦„ ë° ì¹´í…Œê³ ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            if files:
                for f in files:
                    keywords.extend(self._extract_keywords_from_text(f.get('file_name', '')))
                    if f.get('file_category'):
                        keywords.append(f['file_category'])

            # ë¸Œë¼ìš°ì € ê¸°ë¡ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            if history:
                for h in history:
                    keywords.extend(self._extract_keywords_from_text(h.get('title', '')))

            # 2ì°¨ í´ë°±: ì„¤ë¬¸ ë°ì´í„° ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
            if not keywords:
                logger.info(f"User {user_id}: í™œë™ ë°ì´í„°ê°€ ì—†ì–´ ì„¤ë¬¸ ë°ì´í„°ë¡œ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤.")
                survey_data = self._get_user_survey_data(user_id)
                if survey_data:
                    data_source = "ì„¤ë¬¸"
                    job_field = survey_data.get('job_field_other', '') or survey_data.get('job_field', '')
                    interests = survey_data.get('interests', [])
                    custom_keywords_str = survey_data.get('custom_keywords', '')

                    if job_field: keywords.append(job_field)
                    keywords.extend(interests)
                    if custom_keywords_str: keywords.extend(self._extract_keywords_from_text(custom_keywords_str))

            if not keywords:
                msg = f"User {user_id}: ë¶„ì„í•  ë°ì´í„°ê°€ ì „í˜€ ì—†ìŠµë‹ˆë‹¤."
                logger.info(msg)
                return False, "ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì¶”ì²œì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
            # 3. ê°€ì¥ í”í•œ í‚¤ì›Œë“œ ì°¾ê¸° (3ê¸€ì ì´ìƒ)
            keyword_counts = Counter(k for k in keywords if k and len(k) > 2)
            most_common = keyword_counts.most_common(3)

            if not most_common:
                msg = f"User {user_id}: ì£¼ìš” í™œë™ ì£¼ì œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                logger.info(msg)
                return False, "ë°ì´í„°ì—ì„œ ì£¼ìš” í™œë™ ì£¼ì œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

            top_keywords = [k[0] for k in most_common]
            
            # 4. ì¶”ì²œ ìƒì„± ë° ì €ì¥
            title = "í™œë™ ìš”ì•½ ë° ì¶”ì²œ"
            content = f"'{data_source}' ë°ì´í„°ë¥¼ ë¶„ì„í•œ ê²°ê³¼, '{', '.join(top_keywords)}' ì£¼ì œì— ë§ì€ ê´€ì‹¬ì„ ë³´ì´ì…¨ìŠµë‹ˆë‹¤. ì´ì™€ ê´€ë ¨í•˜ì—¬ ë” ê¹Šì´ ìˆëŠ” ì •ë³´ë¥¼ ì°¾ì•„ë³´ê±°ë‚˜ ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•´ ë³´ëŠ” ê²ƒì€ ì–´ë– ì‹ ê°€ìš”?"
            
            # TODO: ì¤‘ë³µ ì¶”ì²œ ë°©ì§€ ë¡œì§ ì¶”ê°€
            
            if self.sqlite_meta.insert_recommendation(user_id, title, content, recommendation_type=recommendation_type):
                logger.info(f"âœ… User {user_id}: ìƒˆë¡œìš´ ì£¼ê°„ ì¶”ì²œì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤: {top_keywords}")
                return True, "ìƒˆë¡œìš´ ì¶”ì²œì„ ì„±ê³µì ìœ¼ë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
            else:
                logger.error(f"âŒ User {user_id}: ì¶”ì²œ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return False, "ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ì²œì„ ì €ì¥í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        except Exception as e:
            logger.error(f"User {user_id} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return False, f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    def _extract_keywords_from_text(self, text: str) -> list:
        """í…ìŠ¤íŠ¸ì—ì„œ ê°„ë‹¨í•œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. (ê°œì„ ëœ ë²„ì „)"""
        if not text:
            return []
        
        import re
        
        # í•œê¸€, ì˜ì–´, ìˆ«ìë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì œê±°
        processed_text = re.sub(r'[^ \wê°€-í£]', '', text.lower())
        words = processed_text.split()
        
        # ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ (í™•ì¥)
        stopwords = [
            'and', 'the', 'for', 'with', 'this', 'that', 'from', 'untitled',
            'com', 'https', 'http', 'www', 'kr', 'ac', 'co',
            'ë°', 'ìœ„í•œ', 'í†µí•´', 'ê´€ë ¨', 'ëŒ€í•œ', 'ì…ë‹ˆë‹¤', 'ìœ¼ë¡œ', 'ì—ì„œ'
        ]
        
        # 2ê¸€ì ì´ìƒì´ê³  ë¶ˆìš©ì–´ê°€ ì•„ë‹Œ ë‹¨ì–´ë§Œ ì¶”ì¶œ
        keywords = [word for word in words if len(word) > 1 and word not in stopwords]
        return list(set(keywords))

    def _get_interest_based_recommendations(self, interests: List[str]) -> str:
        """ê´€ì‹¬ì‚¬ì— ë”°ë¥¸ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not interests:
            return ""
        
        interest_mapping = {
            "tech": "ìµœì‹  IT ê¸°ìˆ , í”„ë¡œê·¸ë˜ë°, ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ",
            "finance": "ê²½ì œ ë™í–¥, íˆ¬ì ì •ë³´, ê¸ˆìœµ ë‰´ìŠ¤",
            "ai": "ì¸ê³µì§€ëŠ¥ ì—°êµ¬, ë¨¸ì‹ ëŸ¬ë‹, ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤",
            "design": "ë””ìì¸ íŠ¸ë Œë“œ, ì°½ì‘ ì˜ê°, ì˜ˆìˆ  ì‘í’ˆ",
            "marketing": "ë§ˆì¼€íŒ… ì „ëµ, ë¸Œëœë”©, ê´‘ê³  ìº í˜ì¸",
            "productivity": "ìƒì‚°ì„± ë„êµ¬, ì‹œê°„ ê´€ë¦¬, ìê¸°ê³„ë°œ",
            "health": "ê±´ê°• ì •ë³´, ìš´ë™ ë£¨í‹´, ì›°ë¹™ íŒ",
            "travel": "ì—¬í–‰ ì •ë³´, ë¬¸í™” ì²´í—˜, ê´€ê´‘ì§€"
        }
        
        recommendations = [interest_mapping.get(interest, interest) for interest in interests]
        return f"ê´€ì‹¬ ì£¼ì œ '{', '.join(recommendations)}'ì— ê´€ë ¨ëœ ìë£Œë¥¼ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    def _get_help_based_recommendations(self, help_preferences: List[str]) -> str:
        """ë„ì›€ ë°›ê³  ì‹¶ì€ ì˜ì—­ì— ë”°ë¥¸ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not help_preferences:
            return ""
        
        help_mapping = {
            "work_search": "ì—…ë¬´ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ë° ìš”ì•½ ë„êµ¬",
            "inspiration": "ì°½ì˜ì  ì•„ì´ë””ì–´ì™€ ì˜ê°ì„ ì£¼ëŠ” ìë£Œ",
            "writing": "ê¸€ì“°ê¸° ë³´ì¡° ë„êµ¬ì™€ í…œí”Œë¦¿",
            "learning": "ê°œì¸ í•™ìŠµì„ ìœ„í•œ êµìœ¡ ìë£Œì™€ ê°•ì˜"
        }
        
        recommendations = [help_mapping.get(pref, pref) for pref in help_preferences]
        return f"'{', '.join(recommendations)}' ì˜ì—­ì—ì„œ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    def _get_keyword_based_recommendations(self, custom_keywords: str) -> str:
        """ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œì— ë”°ë¥¸ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not custom_keywords:
            return ""
        
        return f"'{custom_keywords}'ì™€ ê´€ë ¨ëœ ë§ì¶¤í˜• ìë£Œë¥¼ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    async def process_async(self, user_input: str, user_id: Optional[int] = None) -> AgentResponse:
        """ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë©”ì„œë“œ)"""
        try:
            # ê°„ë‹¨í•œ ì¶”ì²œ ê´€ë ¨ ì‘ë‹µ
            response_content = f"ì¶”ì²œ ì—ì´ì „íŠ¸ê°€ '{user_input}' ìš”ì²­ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ëŠ” ê¸°ë³¸ ì‘ë‹µë§Œ ì œê³µí•©ë‹ˆë‹¤."
            
            return AgentResponse(
                success=True,
                content=response_content,
                agent_type=self.agent_type,
                metadata={
                    "query": user_input,
                    "user_id": user_id,
                    "agent_type": "recommendation"
                }
            )
        except Exception as e:
            return AgentResponse(
                success=False,
                content=f"ì¶”ì²œ ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                agent_type=self.agent_type
            )
    
    def _analyze_recommendation_type(self, user_input: str) -> str:
        """ì¶”ì²œ íƒ€ì…ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        input_lower = user_input.lower()
        
        if any(word in input_lower for word in ["ì§€ì‹", "knowledge", "ì •ë³´"]):
            return "knowledge"
        elif any(word in input_lower for word in ["ì½˜í…ì¸ ", "content", "ìë£Œ"]):
            return "content"
        elif any(word in input_lower for word in ["í•™ìŠµ", "learning", "ê²½ë¡œ", "path"]):
            return "learning_path"
        else:
            return "knowledge"
    
    async def _recommend_knowledge(self, user_id: int, user_input: str) -> AgentResponse:
        """ì§€ì‹ ê¸°ë°˜ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # SQLiteì—ì„œ ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ
            collected_files = self.sqlite_meta.get_collected_files(user_id)
            collected_browser = self.sqlite_meta.get_collected_browser_history(user_id)
            collected_apps = self.sqlite_meta.get_collected_apps(user_id)
            
            # ì‚¬ìš©ì ê´€ì‹¬ì‚¬ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
            interests = self._extract_interests_from_data(collected_files, collected_browser, collected_apps)
            
            # ê¸°ë³¸ ì¶”ì²œ ë¡œì§
            recommendations = self._generate_basic_recommendations(interests, user_input)
            
            return AgentResponse(
                success=True,
                content=f"ì¶”ì²œ ê²°ê³¼: {recommendations}",
                agent_type=self.agent_type,
                metadata={"user_id": user_id, "interests": interests}
            )
            
        except Exception as e:
            return AgentResponse(
                success=False,
                content=f"ì§€ì‹ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                agent_type=self.agent_type
            )
    
    async def _recommend_content(self, user_id: int, user_input: str) -> AgentResponse:
        """ì½˜í…ì¸  ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # ì‚¬ìš©ì ê´€ì‹¬ì‚¬ ê¸°ë°˜ìœ¼ë¡œ ì›¹ ê²€ìƒ‰
            interests = await self._get_user_interests(user_id)
            
            if not interests:
                return AgentResponse(
                    success=True,
                    content="ì‚¬ìš©ì ê´€ì‹¬ì‚¬ë¥¼ íŒŒì•…í•  ìˆ˜ ì—†ì–´ ì¶”ì²œì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    agent_type=self.agent_type
                )
            
            # ê´€ì‹¬ì‚¬ë³„ë¡œ ì›¹ ê²€ìƒ‰
            recommendations = []
            for interest in interests[:3]:  # ìƒìœ„ 3ê°œ ê´€ì‹¬ì‚¬ë§Œ ì‚¬ìš©
                search_result = await self.execute_tool(
                    "web_search_tool",
                    query=f"{interest} ê´€ë ¨ ìµœì‹  ì •ë³´",
                    max_results=2
                )
                
                if search_result.success:
                    for item in search_result.data:
                        recommendations.append({
                            "title": item.get("title", ""),
                            "url": item.get("url", ""),
                            "snippet": item.get("snippet", ""),
                            "interest": interest,
                            "type": "web_content"
                        })
            
            return AgentResponse(
                success=True,
                content={
                    "recommendations": recommendations[:10],  # ìµœëŒ€ 10ê°œ
                    "user_interests": interests
                },
                agent_type=self.agent_type,
                tools_used=["web_search_tool"],
                metadata={"recommendation_type": "content"}
            )
            
        except Exception as e:
            return AgentResponse(
                success=False,
                content=f"ì½˜í…ì¸  ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}",
                agent_type=self.agent_type
            )
    
    async def _recommend_learning_path(self, user_id: int, user_input: str) -> AgentResponse:
        """í•™ìŠµ ê²½ë¡œ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # ì‚¬ìš©ì í˜„ì¬ ìˆ˜ì¤€ê³¼ ëª©í‘œ ë¶„ì„
            user_profile = await self._analyze_user_profile(user_id)
            
            # í•™ìŠµ ê²½ë¡œ ìƒì„±
            learning_path = self._generate_learning_path(user_profile, user_input)
            
            return AgentResponse(
                success=True,
                content={
                    "learning_path": learning_path,
                    "user_profile": user_profile
                },
                agent_type=self.agent_type,
                metadata={"recommendation_type": "learning_path"}
            )
            
        except Exception as e:
            return AgentResponse(
                success=False,
                content=f"í•™ìŠµ ê²½ë¡œ ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}",
                agent_type=self.agent_type
            )
    
    def _extract_interests_from_data(self, collected_files: List[Dict[str, Any]], 
                                   collected_browser: List[Dict[str, Any]], 
                                   collected_apps: List[Dict[str, Any]]) -> List[str]:
        """ìˆ˜ì§‘ëœ ë°ì´í„°ì—ì„œ ì‚¬ìš©ì ê´€ì‹¬ì‚¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        interests = []
        
        # íŒŒì¼ëª…ì—ì„œ ê´€ì‹¬ì‚¬ ì¶”ì¶œ
        for file_info in collected_files:
            file_name = file_info.get('file_name', '').lower()
            file_path = file_info.get('file_path', '').lower()
            
            # ì¼ë°˜ì ì¸ ê´€ì‹¬ì‚¬ í‚¤ì›Œë“œ
            interest_keywords = [
                "python", "javascript", "java", "c++", "machine learning", "ai", "data science",
                "web development", "mobile development", "database", "cloud", "devops",
                "í”„ë¡œê·¸ë˜ë°", "ì½”ë”©", "ê°œë°œ", "í•™ìŠµ", "í”„ë¡œì íŠ¸", "ì•Œê³ ë¦¬ì¦˜", "ìë£Œêµ¬ì¡°"
            ]
            
            for keyword in interest_keywords:
                if keyword in file_name or keyword in file_path:
                    interests.append(keyword)
        
        # ë¸Œë¼ìš°ì € íˆìŠ¤í† ë¦¬ì—ì„œ ê´€ì‹¬ì‚¬ ì¶”ì¶œ
        for browser_info in collected_browser:
            url = browser_info.get('url', '').lower()
            title = browser_info.get('title', '').lower()
            
            for keyword in interest_keywords:
                if keyword in url or keyword in title:
                    interests.append(keyword)
        
        # ì•± ì‚¬ìš©ì—ì„œ ê´€ì‹¬ì‚¬ ì¶”ì¶œ
        for app_info in collected_apps:
            app_name = app_info.get('app_name', '').lower()
            window_title = app_info.get('window_title', '').lower()
            
            for keyword in interest_keywords:
                if keyword in app_name or keyword in window_title:
                    interests.append(keyword)
        
        # ì¤‘ë³µ ì œê±° ë° ë¹ˆë„ìˆœ ì •ë ¬
        interest_counts = {}
        for interest in interests:
            interest_counts[interest] = interest_counts.get(interest, 0) + 1
        
        sorted_interests = sorted(interest_counts.items(), key=lambda x: x[1], reverse=True)
        return [interest for interest, count in sorted_interests[:10]]  # ìƒìœ„ 10ê°œ
    
    async def _get_user_interests(self, user_id: int) -> List[str]:
        """ì‚¬ìš©ì ê´€ì‹¬ì‚¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            # SQLiteì—ì„œ ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ
            collected_files = self.sqlite_meta.get_collected_files(user_id)
            collected_browser = self.sqlite_meta.get_collected_browser_history(user_id)
            collected_apps = self.sqlite_meta.get_collected_apps(user_id)
            
            return self._extract_interests_from_data(collected_files, collected_browser, collected_apps)
        except Exception as e:
            print(f"ì‚¬ìš©ì ê´€ì‹¬ì‚¬ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []
    
    def _calculate_relevance_score(self, item: Dict[str, Any], interests: List[str], user_input: str) -> float:
        """ì§€ì‹ í•­ëª©ì˜ ê´€ë ¨ì„± ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        score = 0.0
        
        # ì‚¬ìš©ì ê´€ì‹¬ì‚¬ì™€ì˜ ë§¤ì¹­
        item_content_lower = item.get('content', '').lower()
        item_title_lower = item.get('title', '').lower()
        
        for interest in interests:
            if interest.lower() in item_content_lower:
                score += 2.0
            if interest.lower() in item_title_lower:
                score += 3.0
        
        # ì‚¬ìš©ì ì…ë ¥ê³¼ì˜ ë§¤ì¹­
        user_input_lower = user_input.lower()
        if user_input_lower in item_content_lower:
            score += 1.5
        if user_input_lower in item_title_lower:
            score += 2.0
        
        # íƒœê·¸ ë§¤ì¹­
        tags = item.get('tags', [])
        for tag in tags:
            if tag.lower() in user_input_lower:
                score += 1.0
        
        return score
    
    def _generate_basic_recommendations(self, interests: List[str], user_input: str) -> List[Dict[str, Any]]:
        """ê¸°ë³¸ ì¶”ì²œì„ ìƒì„±í•©ë‹ˆë‹¤."""
        recommendations = []
        
        # ê´€ì‹¬ì‚¬ ê¸°ë°˜ ì¶”ì²œ
        for interest in interests[:5]:  # ìƒìœ„ 5ê°œ ê´€ì‹¬ì‚¬
            recommendations.append({
                "type": "interest_based",
                "title": f"{interest} ê´€ë ¨ í•™ìŠµ ìë£Œ",
                "description": f"{interest}ì— ëŒ€í•œ í•™ìŠµ ìë£Œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.",
                "interest": interest,
                "priority": "high"
            })
        
        # ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ì¶”ì²œ
        if user_input:
            recommendations.append({
                "type": "query_based",
                "title": f"'{user_input}' ê´€ë ¨ ì¶”ì²œ",
                "description": f"ì‚¬ìš©ì ì§ˆë¬¸ '{user_input}'ì— ëŒ€í•œ ê´€ë ¨ ìë£Œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.",
                "query": user_input,
                "priority": "high"
            })
        
        return recommendations
    
    async def _analyze_user_profile(self, user_id: int) -> Dict[str, Any]:
        """ì‚¬ìš©ì í”„ë¡œí•„ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            # SQLiteì—ì„œ ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ
            collected_files = self.sqlite_meta.get_collected_files(user_id)
            collected_browser = self.sqlite_meta.get_collected_browser_history(user_id)
            collected_apps = self.sqlite_meta.get_collected_apps(user_id)
            
            # ê´€ì‹¬ì‚¬ ì¶”ì¶œ
            interests = self._extract_interests_from_data(collected_files, collected_browser, collected_apps)
            
            # ê°„ë‹¨í•œ ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±
            total_interactions = len(collected_files) + len(collected_browser) + len(collected_apps)
            experience_level = self._estimate_experience_level_simple(total_interactions)
            
            return {
                "user_id": user_id,
                "username": f"User_{user_id}",
                "total_interactions": total_interactions,
                "agent_usage": {"general": total_interactions},
                "interests": interests,
                "experience_level": experience_level
            }
        except Exception as e:
            return {
                "user_id": user_id,
                "username": "Unknown",
                "total_interactions": 0,
                "agent_usage": {},
                "interests": [],
                "experience_level": "beginner"
            }
    
    def _estimate_experience_level_simple(self, total_interactions: int) -> str:
        """ì‚¬ìš©ìì˜ ê²½í—˜ ìˆ˜ì¤€ì„ ì¶”ì •í•©ë‹ˆë‹¤."""
        if total_interactions < 10:
            return "beginner"
        elif total_interactions < 50:
            return "intermediate"
        else:
            return "advanced"
    
    def _generate_learning_path(self, user_profile: Dict[str, Any], user_input: str) -> List[Dict[str, Any]]:
        """í•™ìŠµ ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        experience_level = user_profile.get("experience_level", "beginner")
        interests = user_profile.get("interests", [])
        
        # ê¸°ë³¸ í•™ìŠµ ê²½ë¡œ í…œí”Œë¦¿
        learning_paths = {
            "beginner": [
                {
                    "step": 1,
                    "title": "ê¸°ì´ˆ ê°œë… í•™ìŠµ",
                    "description": "í”„ë¡œê·¸ë˜ë°ì˜ ê¸°ë³¸ ê°œë…ì„ ì´í•´í•©ë‹ˆë‹¤.",
                    "estimated_time": "2-3ì£¼",
                    "resources": ["ì˜¨ë¼ì¸ íŠœí† ë¦¬ì–¼", "ê¸°ì´ˆ êµì¬"]
                },
                {
                    "step": 2,
                    "title": "ì‹¤ìŠµ í”„ë¡œì íŠ¸",
                    "description": "ê°„ë‹¨í•œ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ì‹¤ìŠµí•©ë‹ˆë‹¤.",
                    "estimated_time": "1-2ì£¼",
                    "resources": ["ë¯¸ë‹ˆ í”„ë¡œì íŠ¸", "ì½”ë”© ì—°ìŠµ"]
                }
            ],
            "intermediate": [
                {
                    "step": 1,
                    "title": "ì‹¬í™” ê°œë… í•™ìŠµ",
                    "description": "ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ê°œë…ì„ í•™ìŠµí•©ë‹ˆë‹¤.",
                    "estimated_time": "3-4ì£¼",
                    "resources": ["ê³ ê¸‰ êµì¬", "ì˜¨ë¼ì¸ ê°•ì˜"]
                },
                {
                    "step": 2,
                    "title": "ì‹¤ë¬´ í”„ë¡œì íŠ¸",
                    "description": "ì‹¤ë¬´ ìˆ˜ì¤€ì˜ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.",
                    "estimated_time": "4-6ì£¼",
                    "resources": ["ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸", "íŒ€ í”„ë¡œì íŠ¸"]
                }
            ],
            "advanced": [
                {
                    "step": 1,
                    "title": "ì „ë¬¸ ë¶„ì•¼ ì‹¬í™”",
                    "description": "íŠ¹ì • ë¶„ì•¼ì˜ ì „ë¬¸ ì§€ì‹ì„ ìŠµë“í•©ë‹ˆë‹¤.",
                    "estimated_time": "6-8ì£¼",
                    "resources": ["ì „ë¬¸ ì„œì ", "ì»¨í¼ëŸ°ìŠ¤ ì°¸ì„"]
                },
                {
                    "step": 2,
                    "title": "ë¦¬ë”ì‹­ ë° ë©˜í† ë§",
                    "description": "ë‹¤ë¥¸ ê°œë°œìë¥¼ ê°€ë¥´ì¹˜ê³  ë¦¬ë“œí•©ë‹ˆë‹¤.",
                    "estimated_time": "ì§€ì†ì ",
                    "resources": ["ë©˜í† ë§ í”„ë¡œê·¸ë¨", "ê¸°ìˆ  ë¸”ë¡œê·¸ ìš´ì˜"]
                }
            ]
        }
        
        base_path = learning_paths.get(experience_level, learning_paths["beginner"])
        
        # ê´€ì‹¬ì‚¬ì— ë§ê²Œ ì»¤ìŠ¤í„°ë§ˆì´ì§•
        customized_path = []
        for step in base_path:
            customized_step = step.copy()
            if interests:
                customized_step["description"] += f" (ê´€ì‹¬ ë¶„ì•¼: {', '.join(interests[:3])})"
            customized_path.append(customized_step)
        
        return customized_path 