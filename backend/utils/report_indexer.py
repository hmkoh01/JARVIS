"""
ë³´ê³ ì„œ ì¸ë±ì‹± ìœ í‹¸ë¦¬í‹°

ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ SQLiteì™€ Qdrantì— ì €ì¥í•©ë‹ˆë‹¤.
ì±„íŒ…ì—ì„œ ë³´ê³ ì„œ ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
"""

import hashlib
import logging
from pathlib import Path
from typing import Dict, Any, Optional, List

logger = logging.getLogger(__name__)


def index_report_file(
    file_path: str,
    user_id: int,
    keyword: str,
    repository=None,
    embedder=None
) -> bool:
    """
    ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ SQLiteì™€ Qdrantì— ì¸ë±ì‹±í•©ë‹ˆë‹¤.
    
    Args:
        file_path: ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ (PDF ë˜ëŠ” Markdown)
        user_id: ì‚¬ìš©ì ID
        keyword: ë³´ê³ ì„œ ì£¼ì œ í‚¤ì›Œë“œ
        repository: Repository ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©)
        embedder: BGEM3Embedder ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©)
    
    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        from database.document_parser import DocumentParser
        from database.sqlite import SQLite
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not Path(file_path).exists():
            logger.error(f"ë³´ê³ ì„œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return False
        
        # doc_id ìƒì„±
        doc_id = f"report_{hashlib.md5(file_path.encode()).hexdigest()}"
        
        # 1. SQLiteì— íŒŒì¼ ì •ë³´ ì €ì¥
        sqlite = SQLite()
        sqlite.upsert_file(
            doc_id=doc_id,
            user_id=user_id,
            file_path=file_path
        )
        logger.info(f"ğŸ“„ SQLiteì— ë³´ê³ ì„œ íŒŒì¼ ì •ë³´ ì €ì¥: {doc_id}")
        
        # 2. ë¬¸ì„œ íŒŒì‹± ë° ì²­í¬ ë¶„í• 
        parser = DocumentParser()
        chunk_infos = parser.parse_and_chunk(file_path)
        
        if not chunk_infos:
            logger.warning(f"ë³´ê³ ì„œ íŒŒì‹± ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return True  # íŒŒì¼ ì •ë³´ëŠ” ì €ì¥ë¨
        
        logger.info(f"ğŸ“„ ë³´ê³ ì„œ íŒŒì‹± ì™„ë£Œ: {len(chunk_infos)}ê°œ ì²­í¬")
        
        # 3. Repositoryì™€ Embedder ê°€ì ¸ì˜¤ê¸°
        if repository is None or embedder is None:
            try:
                # ë°©ë²• 1: main ëª¨ë“ˆì—ì„œ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                import main
                repository = repository or getattr(main, 'global_repository', None)
                embedder = embedder or getattr(main, 'global_embedder', None)
            except Exception as e:
                logger.warning(f"main ëª¨ë“ˆì—ì„œ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            
            # ë°©ë²• 2: ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ê°€ Noneì´ë©´ ìƒˆë¡œ ì´ˆê¸°í™”
            if repository is None or embedder is None:
                logger.info("ì „ì—­ Repository/Embedderê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
                try:
                    from database.repository import Repository as RepoClass
                    from agents.chatbot_agent.rag.models.bge_m3_embedder import BGEM3Embedder
                    
                    if repository is None:
                        repository = RepoClass()
                        logger.info("âœ… Repository ìƒˆë¡œ ì´ˆê¸°í™” ì™„ë£Œ")
                    if embedder is None:
                        embedder = BGEM3Embedder()
                        logger.info("âœ… BGEM3Embedder ìƒˆë¡œ ì´ˆê¸°í™” ì™„ë£Œ")
                except Exception as init_error:
                    logger.error(f"Repository/Embedder ì´ˆê¸°í™” ì‹¤íŒ¨: {init_error}")
        
        if repository is None or embedder is None:
            logger.error("Repository ë˜ëŠ” Embedderê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        # 4. ì²­í¬ ë©”íƒ€ë°ì´í„° ì¤€ë¹„
        texts = []
        metas = []
        file_name = Path(file_path).name
        
        for chunk in chunk_infos:
            texts.append(chunk['text'])
            metas.append({
                'user_id': user_id,
                'source': 'report',  # ë³´ê³ ì„œ ì¶œì²˜ êµ¬ë¶„
                'path': file_path,
                'doc_id': doc_id,
                'chunk_id': chunk['chunk_id'],
                'snippet': chunk.get('snippet', chunk['text'][:200]),
                'content': chunk['text'],
                'keyword': keyword,  # ë³´ê³ ì„œ ì£¼ì œ í‚¤ì›Œë“œ
                'file_name': file_name
            })
        
        # 5. ì„ë² ë”© ìƒì„± ë° Qdrant ì—…ë¡œë“œ
        logger.info(f"ğŸ§  ë³´ê³ ì„œ {len(texts)}ê°œ ì²­í¬ ì„ë² ë”© ìƒì„± ì¤‘...")
        
        embeddings = embedder.encode_documents(texts, batch_size=32)
        dense_vectors = embeddings['dense_vecs'].tolist()
        sparse_vectors = [
            embedder.convert_sparse_to_qdrant_format(lw)
            for lw in embeddings['lexical_weights']
        ]
        
        if repository.qdrant.upsert_vectors(metas, dense_vectors, sparse_vectors):
            logger.info(f"âœ… Qdrantì— ë³´ê³ ì„œ ì²­í¬ {len(texts)}ê°œ ì¸ë±ì‹± ì™„ë£Œ")
        else:
            logger.error("âŒ Qdrant ë³´ê³ ì„œ ì¸ë±ì‹± ì‹¤íŒ¨")
            return False
        
        # 6. í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì €ì¥ (ì„ íƒì )
        try:
            from utils.keyword_extractor import get_keyword_extractor
            extractor = get_keyword_extractor()
            
            if extractor:
                # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                full_text = " ".join(texts)
                keywords = extractor.extract(full_text, top_n=10)
                
                if keywords:
                    for kw, score in keywords:
                        sqlite.insert_content_keyword(
                            user_id=user_id,
                            source_type='report',
                            source_id=doc_id,
                            keyword=kw,
                            original_text=f"ë³´ê³ ì„œ: {keyword}"
                        )
                    logger.info(f"ğŸ“ ë³´ê³ ì„œ í‚¤ì›Œë“œ {len(keywords)}ê°œ ì €ì¥")
        except Exception as e:
            logger.warning(f"ë³´ê³ ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")
        
        return True
        
    except Exception as e:
        logger.exception(f"ë³´ê³ ì„œ ì¸ë±ì‹± ì˜¤ë¥˜: {e}")
        return False


async def index_report_file_async(
    file_path: str,
    user_id: int,
    keyword: str,
    repository=None,
    embedder=None
) -> bool:
    """
    ë¹„ë™ê¸°ë¡œ ë³´ê³ ì„œ íŒŒì¼ì„ ì¸ë±ì‹±í•©ë‹ˆë‹¤.
    (ë™ê¸° í•¨ìˆ˜ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
    """
    import asyncio
    import concurrent.futures
    
    loop = asyncio.get_event_loop()
    
    with concurrent.futures.ThreadPoolExecutor() as executor:
        result = await loop.run_in_executor(
            executor,
            lambda: index_report_file(
                file_path=file_path,
                user_id=user_id,
                keyword=keyword,
                repository=repository,
                embedder=embedder
            )
        )
    
    return result

